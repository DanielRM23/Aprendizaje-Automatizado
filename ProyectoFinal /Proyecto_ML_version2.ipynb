{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1999ca1",
   "metadata": {},
   "source": [
    "# Proyecto Final — Aprendizaje Automatizado  \n",
    "### Semestre 2025-2  \n",
    "**Elizabeth Ríos Alvarado**  \n",
    "**Daniel Rojo Mata**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967aec42",
   "metadata": {},
   "source": [
    "# Predicción de Días con Alta Volatilidad en el Mercado Bursátil\n",
    "\n",
    "## Objetivo del Proyecto\n",
    "\n",
    "El objetivo de este trabajo es desarrollar un sistema de clasificación capaz de **predecir días con alta volatilidad en el mercado accionario**, utilizando datos financieros históricos y técnicas de aprendizaje automático. Se busca detectar estos eventos de manera anticipada, lo cual es clave para estrategias de inversión y gestión de riesgo.\n",
    "\n",
    "---\n",
    "\n",
    "## Enfoque General\n",
    "\n",
    "El proyecto se divide en varias etapas clave:\n",
    "\n",
    "### 1. **Descarga y preparación de datos**\n",
    "- Se utilizaron precios históricos de acciones descargados desde *Yahoo Finance* mediante `FinRL`.\n",
    "- Se calcularon los **rendimientos diarios** y una medida de **volatilidad de 5 días** usando desviación estándar.\n",
    "- Los datos fueron enriquecidos con múltiples **indicadores técnicos** (ej. RSI, MACD, Bollinger Bands).\n",
    "\n",
    "### 2. **Etiquetado de alta volatilidad**\n",
    "- Se definió un umbral dinámico de alta volatilidad utilizando el **percentil 70** de la volatilidad histórica por acción.\n",
    "- Se creó una variable binaria `volatilidad_alta` que indica si un día tiene una volatilidad anormalmente alta para esa acción.\n",
    "\n",
    "### 3. **Estudio empírico de atributos**\n",
    "- Se realizó un **estudio empírico para evaluar la importancia de distintas combinaciones de columnas**.\n",
    "- Se utilizó una **estrategia evolutiva basada en algoritmos genéticos** para seleccionar subconjuntos de atributos y evaluar su rendimiento.\n",
    "- El resultado concluyó que **utilizar toda la información disponible produce mejores resultados** que cualquier subconjunto reducido.\n",
    "\n",
    "### 4. **Modelado clásico**\n",
    "- Se probaron distintos modelos de clasificación supervisada:\n",
    "  - Regresión Logística\n",
    "  - Random Forest\n",
    "  - XGBoost\n",
    "  - SVM\n",
    "  - K-Nearest Neighbors\n",
    "- Se evaluó el rendimiento con la métrica **F1-score**, dada la naturaleza desbalanceada del problema.\n",
    "\n",
    "### 5. **Modelado secuencial con RNN**\n",
    "- Se entrenó una **Red Neuronal Recurrente (LSTM)** que usa secuencias temporales de 15 días para predecir la volatilidad del día siguiente.\n",
    "- Se compararon dos variantes:\n",
    "  - RNN sin ajuste de pesos.\n",
    "  - RNN con **pesos de clase** para mitigar el desbalance de etiquetas.\n",
    "- Se realizó una **búsqueda automática del umbral de decisión** para maximizar el F1-score.\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados clave\n",
    "\n",
    "- Los modelos clásicos tuvieron un rendimiento limitado, especialmente en términos de recall para la clase positiva.\n",
    "- El mejor rendimiento fue obtenido con la **RNN con pesos de clase**, que logró un **recall del 100%** y un **F1-score de 0.4586** para detectar días de alta volatilidad.\n",
    "- La búsqueda del umbral óptimo reveló que valores bajos (ej. **0.05**) permiten captar más eventos relevantes.\n",
    "- El estudio evolutivo de selección de columnas permitió confirmar que **la inclusión de todas las variables mejora consistentemente el desempeño predictivo**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "El enfoque secuencial con RNN, ajustado por pesos y con umbral calibrado, representa una solución efectiva para la predicción de días con alta volatilidad. Este tipo de modelos puede ser especialmente útil para sistemas de alerta temprana en trading algorítmico o gestión de riesgo. El análisis evolutivo también sugiere que reducir atributos puede ser contraproducente: **más información aporta mayor poder predictivo** en este contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149c5f5",
   "metadata": {},
   "source": [
    "# **Ajustar Anchura** \n",
    "\n",
    "Esta línea hace que se ajuste la anchura del notebook, por defecto la ajusta a un 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6957203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:92% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:92% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492f5d8",
   "metadata": {},
   "source": [
    "# **Descargar Dependencias**\n",
    "\n",
    "Estos son los elementos que se tienen que descargar para un uso adecuado de todo el notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install swig\n",
    "# !pip install wrds\n",
    "# !pip install pyportfolioopt\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
    "# !pip install yfinance\n",
    "# !pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958c73c",
   "metadata": {},
   "source": [
    "# **Se importan las librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca975cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:32:06.898397: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 15:32:06.914296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-30 15:32:06.933240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-30 15:32:06.939170: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 15:32:06.953451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-30 15:32:08.028615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Fechas y descarga de datos\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.config import INDICATORS\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelado clásico\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Deep learning (Keras)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870083b",
   "metadata": {},
   "source": [
    "# **Se descargan los datos históricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4300a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1752, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Las fechas deben seguir el formato 'año/mes/día' (YYYY-MM-DD)\n",
    "# Estas fechas delimitan el periodo de tiempo del que se descargarán los datos históricos\n",
    "START_DATE = '2024-01-01'   # Fecha de inicio del análisis\n",
    "END_DATE = '2025-03-04'     # Fecha de fin del análisis\n",
    "\n",
    "# Lista de símbolos (tickers) de las acciones que se analizarán\n",
    "# Estos corresponden a empresas cotizadas en bolsa como Moderna, Nvidia, Uber, etc.\n",
    "symbols = [\n",
    "    \"MRNA\",  # Moderna Inc.\n",
    "    \"NVDA\",  # Nvidia Corp.\n",
    "    \"UBER\",  # Uber Technologies Inc.\n",
    "    \"ASML\",  # ASML Holding N.V.\n",
    "    \"AMZN\",  # Amazon.com Inc.\n",
    "    \"AAPL\"   # Apple Inc.\n",
    "]\n",
    "\n",
    "# Usamos el módulo YahooDownloader de FinRL para descargar datos históricos de acciones\n",
    "# Se especifica el rango de fechas y la lista de símbolos (acciones) definidos previamente\n",
    "data = YahooDownloader(\n",
    "    start_date = START_DATE,   # Fecha de inicio del periodo de análisis\n",
    "    end_date = END_DATE,       # Fecha de fin del periodo de análisis\n",
    "    ticker_list = symbols      # Lista de acciones a descargar (AAPL, AMZN, etc.)\n",
    ").fetch_data()                 # Ejecuta la descarga y devuelve un DataFrame con los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ef0da",
   "metadata": {},
   "source": [
    "# **Extracción de Indicadores Técnicos y Reconstrucción de la Estructura Temporal**\n",
    "\n",
    "### 1. Extracción de Indicadores Técnicos\n",
    "\n",
    "Después de descargar los datos históricos de precios para varias acciones, se aplica un proceso de **ingeniería de características** para enriquecer el conjunto de datos con variables útiles para el modelo de aprendizaje automatizado.\n",
    "\n",
    "Para esto, se utiliza el módulo `FeatureEngineer` de la biblioteca FinRL. Este módulo permite calcular automáticamente varios **indicadores técnicos**, que son ampliamente utilizados en el análisis técnico del mercado bursátil. Estos indicadores ayudan a capturar tendencias, momentum y señales de sobrecompra o sobreventa en los precios.\n",
    "\n",
    "Entre los indicadores extraídos se encuentran:\n",
    "\n",
    "- **RSI (Relative Strength Index)**\n",
    "- **MACD (Moving Average Convergence Divergence)**\n",
    "- **Bollinger Bands**\n",
    "- **Medias móviles (SMA, EMA)**\n",
    "- **CCI, DX, y más**\n",
    "\n",
    "Además, se incluyen variables adicionales como:\n",
    "\n",
    "- **VIX**: índice de volatilidad implícita del mercado, útil para medir el \"miedo\" del mercado.\n",
    "- **Turbulence**: una medida del comportamiento anómalo del mercado basada en desviaciones multivariadas.\n",
    "\n",
    "Estos indicadores se calculan para cada acción de forma individual y se agregan como nuevas columnas al DataFrame resultante (`processed`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Reconstrucción de la estructura fecha × acción\n",
    "\n",
    "Una vez que se tienen los indicadores técnicos, se realiza un paso adicional: **reconstruir la estructura completa del conjunto de datos**, garantizando que todas las combinaciones posibles de fechas y acciones estén presentes.\n",
    "\n",
    "#### ¿Por qué se hace esto?\n",
    "\n",
    "En el mundo real, no todas las acciones tienen datos disponibles para todas las fechas (por ejemplo, por días festivos, suspensiones de cotización o errores en la descarga). Para asegurar que el conjunto de datos sea consistente y estructurado (especialmente útil para modelos temporales), se realiza lo siguiente:\n",
    "\n",
    "- Se genera una lista completa de fechas entre la mínima y máxima fecha observada.\n",
    "- Se toma la lista de acciones (tickers) presentes en el conjunto de datos.\n",
    "- Se calcula el **producto cartesiano** de fechas × acciones, creando todas las combinaciones posibles.\n",
    "- Este nuevo DataFrame se fusiona con los datos procesados originales para **rellenar los valores existentes** y dejar explícitos los faltantes.\n",
    "- Finalmente, se filtran las fechas que realmente ocurrieron en el mercado para evitar incluir días como fines de semana o festivos.\n",
    "\n",
    "Este paso garantiza que el conjunto de datos tenga una estructura rectangular y ordenada, lo cual es especialmente útil para la fase de modelado.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901cf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (291, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.290421</td>\n",
       "      <td>187.070068</td>\n",
       "      <td>182.553143</td>\n",
       "      <td>185.789438</td>\n",
       "      <td>82488700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.551942</td>\n",
       "      <td>181.649001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>184.290421</td>\n",
       "      <td>184.290421</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.910522</td>\n",
       "      <td>184.528677</td>\n",
       "      <td>182.096477</td>\n",
       "      <td>182.880742</td>\n",
       "      <td>58414500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.030959</td>\n",
       "      <td>185.551942</td>\n",
       "      <td>181.649001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>183.600471</td>\n",
       "      <td>183.600471</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>180.587540</td>\n",
       "      <td>181.758954</td>\n",
       "      <td>179.565029</td>\n",
       "      <td>180.825785</td>\n",
       "      <td>71983600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.111484</td>\n",
       "      <td>186.338860</td>\n",
       "      <td>178.853462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>182.596161</td>\n",
       "      <td>182.596161</td>\n",
       "      <td>14.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>179.862839</td>\n",
       "      <td>181.431354</td>\n",
       "      <td>178.860187</td>\n",
       "      <td>180.666963</td>\n",
       "      <td>62303300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.171541</td>\n",
       "      <td>186.012779</td>\n",
       "      <td>177.812881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-77.623093</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>181.912830</td>\n",
       "      <td>181.912830</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.210999</td>\n",
       "      <td>184.250716</td>\n",
       "      <td>180.180517</td>\n",
       "      <td>180.766224</td>\n",
       "      <td>59144500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>186.475201</td>\n",
       "      <td>178.269727</td>\n",
       "      <td>51.361116</td>\n",
       "      <td>26.022989</td>\n",
       "      <td>7.073433</td>\n",
       "      <td>182.372464</td>\n",
       "      <td>182.372464</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic       close        high         low        open  \\\n",
       "0   2024-01-02  AAPL  184.290421  187.070068  182.553143  185.789438   \n",
       "6   2024-01-03  AAPL  182.910522  184.528677  182.096477  182.880742   \n",
       "12  2024-01-04  AAPL  180.587540  181.758954  179.565029  180.825785   \n",
       "18  2024-01-05  AAPL  179.862839  181.431354  178.860187  180.666963   \n",
       "36  2024-01-08  AAPL  184.210999  184.250716  180.180517  180.766224   \n",
       "\n",
       "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0   82488700.0  1.0  0.000000  185.551942  181.649001   0.000000  -66.666667   \n",
       "6   58414500.0  2.0 -0.030959  185.551942  181.649001   0.000000  -66.666667   \n",
       "12  71983600.0  3.0 -0.111484  186.338860  178.853462   0.000000 -100.000000   \n",
       "18  62303300.0  4.0 -0.171541  186.012779  177.812881   0.000000  -77.623093   \n",
       "36  59144500.0  0.0 -0.027540  186.475201  178.269727  51.361116   26.022989   \n",
       "\n",
       "         dx_30  close_30_sma  close_60_sma    vix  turbulence  \n",
       "0   100.000000    184.290421    184.290421  13.20         0.0  \n",
       "6   100.000000    183.600471    183.600471  14.04         0.0  \n",
       "12  100.000000    182.596161    182.596161  14.13         0.0  \n",
       "18  100.000000    181.912830    181.912830  13.35         0.0  \n",
       "36    7.073433    182.372464    182.372464  13.08         0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un objeto FeatureEngineer para calcular automáticamente indicadores técnicos\n",
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,        # Activamos el cálculo de indicadores técnicos clásicos (RSI, MACD, etc.)\n",
    "    tech_indicator_list=INDICATORS,      # Usamos la lista predefinida de indicadores de FinRL\n",
    "    use_vix=True,                        # Incluye el índice VIX (volatilidad implícita del mercado)\n",
    "    use_turbulence=True,                 # Incluye la medida de turbulencia financiera\n",
    "    user_defined_feature=False           # No se agregan indicadores personalizados por ahora\n",
    ")\n",
    "\n",
    "# Aplicamos el preprocesamiento sobre el DataFrame descargado ('data') para generar nuevas columnas con indicadores\n",
    "processed = fe.preprocess_data(data)\n",
    "\n",
    "# --- Reconstruimos la estructura completa fecha × acción para evitar combinaciones faltantes ---\n",
    "\n",
    "# Obtenemos la lista única de tickers (acciones)\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creamos una lista de fechas entre la mínima y máxima fecha disponibles en el dataset\n",
    "list_date = list(pd.date_range(processed['date'].min(), processed['date'].max()).astype(str))\n",
    "\n",
    "# Generamos todas las combinaciones posibles de (fecha, ticker)\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "# Creamos un nuevo DataFrame con todas las combinaciones posibles (fecha, acción)\n",
    "# Luego hacemos un left join con los datos procesados para rellenar los datos existentes\n",
    "processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"]).merge(\n",
    "    processed, on=[\"date\", \"tic\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Filtramos para conservar solo las fechas que realmente estaban en los datos originales\n",
    "# Esto evita que aparezcan fechas inexistentes (por ejemplo, fines de semana o días festivos)\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Ordenamos los datos primero por 'tic' (símbolo de la acción) y luego por 'date'\n",
    "# Esto es necesario para aplicar el rellenado hacia adelante (forward fill) correctamente dentro de cada acción\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# Rellenamos los valores faltantes con el último valor válido conocido hacia adelante (forward fill)\n",
    "# Esto es útil porque algunos indicadores técnicos no tienen valor en los primeros días y así evitamos NaNs\n",
    "processed_full = processed_full = processed_full.ffill()\n",
    "\n",
    "# Eliminamos cualquier fila que aún tenga valores faltantes después del rellenado\n",
    "# Esto suele ocurrir en los primeros días de cada acción, donde no hay valores previos para propagar\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "#OPCIONAL: Visualizar la data\n",
    "processed_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685eaaab",
   "metadata": {},
   "source": [
    "# **Cálculo y Etiquetado de la Volatilidad**\n",
    "\n",
    "## Parte 1: Cálculo de la Volatilidad de 5 Días\n",
    "\n",
    "La volatilidad es una medida de qué tanto varían los precios de una acción en un periodo de tiempo. En este proyecto, la estimamos como la **desviación estándar de los rendimientos diarios** utilizando una **ventana móvil de 5 días** para cada acción por separado.\n",
    "\n",
    "### ¿Qué se hace?\n",
    "\n",
    "- Se agrupan los datos por acción (`tic`), porque cada empresa tiene su propia dinámica de precios.\n",
    "- Se calcula el **rendimiento diario** como el cambio porcentual del precio de cierre.\n",
    "- Sobre esos rendimientos, se aplica una **ventana móvil de 5 días** y se calcula la **desviación estándar**.\n",
    "- Esta medida representa la **volatilidad reciente** de cada acción y se guarda en una columna nueva llamada `volatility_5d`.\n",
    "\n",
    "### ¿Por qué usamos desviación estándar?\n",
    "\n",
    "La desviación estándar cuantifica la **dispersión**: si los rendimientos varían mucho de un día a otro, su desviación estándar será alta. En finanzas, esta es una forma clásica y aceptada de medir la volatilidad, ya que refleja cuán impredecible ha sido el comportamiento de una acción en días recientes.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 2: Etiquetado de Días con \"Alta Volatilidad\"\n",
    "\n",
    "Para poder entrenar modelos de clasificación, necesitamos transformar la variable continua `volatility_5d` en una etiqueta binaria. Lo hacemos creando una nueva columna `volatilidad_alta`, que indica si un día tiene **volatilidad inusualmente alta** o no.\n",
    "\n",
    "### ¿Cómo se etiqueta?\n",
    "\n",
    "- Nuevamente se agrupan los datos por acción (`tic`), ya que lo que se considera “alto” depende del contexto de cada empresa.\n",
    "- Se calcula el **percentil 70** (también llamado percentil 0.70) de la volatilidad para cada acción.\n",
    "- Este valor actúa como un **umbral relativo**: si un día tiene una volatilidad mayor a este umbral, se considera un evento anómalo o especialmente volátil.\n",
    "- Se asigna:\n",
    "  - `1` → si la volatilidad está por arriba del percentil 70\n",
    "  - `0` → en caso contrario\n",
    "\n",
    "### ¿Por qué usar el percentil 70?\n",
    "\n",
    "El percentil 70 significa que **sólo el 30% de los días más volátiles** serán etiquetados como \"alta volatilidad\". Este valor nos da un **equilibrio natural** entre:\n",
    "- Tener suficientes ejemplos positivos para entrenar modelos robustos.\n",
    "- No etiquetar como “alto” cualquier pequeña variación común.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 3: Exploración de Percentiles\n",
    "\n",
    "Antes de fijar el percentil 70, realizamos una pequeña exploración para entender qué proporción de días serían etiquetados como clase 1 (`volatilidad_alta`) con diferentes percentiles. Esto ayuda a asegurarnos de que no estamos seleccionando ni demasiados ni muy pocos días como \"volátiles\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab04c84",
   "metadata": {},
   "source": [
    "# Etiquetado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccb3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>return</th>\n",
       "      <th>volatility_5d</th>\n",
       "      <th>volatilidad_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>183.794067</td>\n",
       "      <td>183.803989</td>\n",
       "      <td>181.401584</td>\n",
       "      <td>182.582935</td>\n",
       "      <td>42841800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041713</td>\n",
       "      <td>186.458198</td>\n",
       "      <td>...</td>\n",
       "      <td>48.871283</td>\n",
       "      <td>29.331561</td>\n",
       "      <td>7.073433</td>\n",
       "      <td>182.609398</td>\n",
       "      <td>182.609398</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.836411</td>\n",
       "      <td>185.044875</td>\n",
       "      <td>182.582909</td>\n",
       "      <td>183.009791</td>\n",
       "      <td>46792900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.132627</td>\n",
       "      <td>186.823493</td>\n",
       "      <td>...</td>\n",
       "      <td>54.567332</td>\n",
       "      <td>76.253283</td>\n",
       "      <td>13.207978</td>\n",
       "      <td>182.927543</td>\n",
       "      <td>182.927543</td>\n",
       "      <td>12.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.240768</td>\n",
       "      <td>185.690161</td>\n",
       "      <td>182.285089</td>\n",
       "      <td>185.183859</td>\n",
       "      <td>49128400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.163127</td>\n",
       "      <td>186.816258</td>\n",
       "      <td>...</td>\n",
       "      <td>51.195699</td>\n",
       "      <td>66.899452</td>\n",
       "      <td>21.476017</td>\n",
       "      <td>183.091696</td>\n",
       "      <td>183.091696</td>\n",
       "      <td>12.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003223</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.568375</td>\n",
       "      <td>185.382421</td>\n",
       "      <td>183.843686</td>\n",
       "      <td>184.707356</td>\n",
       "      <td>40444700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.198019</td>\n",
       "      <td>186.876195</td>\n",
       "      <td>...</td>\n",
       "      <td>52.853185</td>\n",
       "      <td>85.517638</td>\n",
       "      <td>21.476017</td>\n",
       "      <td>183.255771</td>\n",
       "      <td>183.255771</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.295029</td>\n",
       "      <td>182.920438</td>\n",
       "      <td>179.614645</td>\n",
       "      <td>180.835714</td>\n",
       "      <td>65603000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102791</td>\n",
       "      <td>186.626726</td>\n",
       "      <td>...</td>\n",
       "      <td>42.493416</td>\n",
       "      <td>-66.785229</td>\n",
       "      <td>29.102826</td>\n",
       "      <td>183.159697</td>\n",
       "      <td>183.159697</td>\n",
       "      <td>13.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012317</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.419998</td>\n",
       "      <td>78.879997</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>78.650002</td>\n",
       "      <td>24368400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.449048</td>\n",
       "      <td>86.061833</td>\n",
       "      <td>...</td>\n",
       "      <td>56.159591</td>\n",
       "      <td>65.676325</td>\n",
       "      <td>7.593468</td>\n",
       "      <td>71.628999</td>\n",
       "      <td>68.240166</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>4.777466</td>\n",
       "      <td>-0.031309</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>73.529999</td>\n",
       "      <td>76.360001</td>\n",
       "      <td>19559200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.006083</td>\n",
       "      <td>86.140179</td>\n",
       "      <td>...</td>\n",
       "      <td>54.305930</td>\n",
       "      <td>39.701343</td>\n",
       "      <td>12.923284</td>\n",
       "      <td>71.928332</td>\n",
       "      <td>68.265666</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>1.501326</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>UBER</td>\n",
       "      <td>75.870003</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>75.309998</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>10328900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.698164</td>\n",
       "      <td>86.198854</td>\n",
       "      <td>...</td>\n",
       "      <td>55.261977</td>\n",
       "      <td>47.506516</td>\n",
       "      <td>12.293895</td>\n",
       "      <td>72.267332</td>\n",
       "      <td>68.337499</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>6.419846</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.209999</td>\n",
       "      <td>77.690002</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>75.949997</td>\n",
       "      <td>22535900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.293746</td>\n",
       "      <td>85.983300</td>\n",
       "      <td>...</td>\n",
       "      <td>53.184914</td>\n",
       "      <td>35.376200</td>\n",
       "      <td>18.748735</td>\n",
       "      <td>72.579666</td>\n",
       "      <td>68.380666</td>\n",
       "      <td>21.129999</td>\n",
       "      <td>9.438050</td>\n",
       "      <td>-0.021880</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.010002</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>73.580002</td>\n",
       "      <td>74.279999</td>\n",
       "      <td>17752000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.094345</td>\n",
       "      <td>85.739607</td>\n",
       "      <td>...</td>\n",
       "      <td>55.078834</td>\n",
       "      <td>32.740104</td>\n",
       "      <td>19.264791</td>\n",
       "      <td>72.879333</td>\n",
       "      <td>68.448166</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>2.880588</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.024033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close        high         low        open  \\\n",
       "42    2024-01-09  AAPL  183.794067  183.803989  181.401584  182.582935   \n",
       "48    2024-01-10  AAPL  184.836411  185.044875  182.582909  183.009791   \n",
       "54    2024-01-11  AAPL  184.240768  185.690161  182.285089  185.183859   \n",
       "60    2024-01-12  AAPL  184.568375  185.382421  183.843686  184.707356   \n",
       "84    2024-01-16  AAPL  182.295029  182.920438  179.614645  180.835714   \n",
       "...          ...   ...         ...         ...         ...         ...   \n",
       "2519  2025-02-24  UBER   76.419998   78.879997   74.849998   78.650002   \n",
       "2525  2025-02-25  UBER   74.949997   76.370003   73.529999   76.360001   \n",
       "2531  2025-02-26  UBER   75.870003   76.489998   75.309998   75.330002   \n",
       "2537  2025-02-27  UBER   74.209999   77.690002   73.709999   75.949997   \n",
       "2543  2025-02-28  UBER   76.010002   76.110001   73.580002   74.279999   \n",
       "\n",
       "          volume  day      macd     boll_ub  ...     rsi_30     cci_30  \\\n",
       "42    42841800.0  1.0  0.041713  186.458198  ...  48.871283  29.331561   \n",
       "48    46792900.0  2.0  0.132627  186.823493  ...  54.567332  76.253283   \n",
       "54    49128400.0  3.0  0.163127  186.816258  ...  51.195699  66.899452   \n",
       "60    40444700.0  4.0  0.198019  186.876195  ...  52.853185  85.517638   \n",
       "84    65603000.0  1.0  0.102791  186.626726  ...  42.493416 -66.785229   \n",
       "...          ...  ...       ...         ...  ...        ...        ...   \n",
       "2519  24368400.0  0.0  3.449048   86.061833  ...  56.159591  65.676325   \n",
       "2525  19559200.0  1.0  3.006083   86.140179  ...  54.305930  39.701343   \n",
       "2531  10328900.0  2.0  2.698164   86.198854  ...  55.261977  47.506516   \n",
       "2537  22535900.0  3.0  2.293746   85.983300  ...  53.184914  35.376200   \n",
       "2543  17752000.0  4.0  2.094345   85.739607  ...  55.078834  32.740104   \n",
       "\n",
       "          dx_30  close_30_sma  close_60_sma        vix  turbulence    return  \\\n",
       "42     7.073433    182.609398    182.609398  12.760000    0.000000 -0.002263   \n",
       "48    13.207978    182.927543    182.927543  12.690000    0.000000  0.005671   \n",
       "54    21.476017    183.091696    183.091696  12.440000    0.000000 -0.003223   \n",
       "60    21.476017    183.255771    183.255771  12.700000    0.000000  0.001778   \n",
       "84    29.102826    183.159697    183.159697  13.840000    0.000000 -0.012317   \n",
       "...         ...           ...           ...        ...         ...       ...   \n",
       "2519   7.593468     71.628999     68.240166  18.980000    4.777466 -0.031309   \n",
       "2525  12.923284     71.928332     68.265666  19.430000    1.501326 -0.019236   \n",
       "2531  12.293895     72.267332     68.337499  19.100000    6.419846  0.012275   \n",
       "2537  18.748735     72.579666     68.380666  21.129999    9.438050 -0.021880   \n",
       "2543  19.264791     72.879333     68.448166  19.629999    2.880588  0.024256   \n",
       "\n",
       "      volatility_5d  volatilidad_alta  \n",
       "42         0.014335                 0  \n",
       "48         0.013924                 0  \n",
       "54         0.011889                 0  \n",
       "60         0.011165                 0  \n",
       "84         0.006729                 0  \n",
       "...             ...               ...  \n",
       "2519       0.023722                 1  \n",
       "2525       0.014634                 0  \n",
       "2531       0.019213                 0  \n",
       "2537       0.017570                 0  \n",
       "2543       0.024033                 1  \n",
       "\n",
       "[1716 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ordenamos por acción y fecha\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# 2. Calculamos el rendimiento diario por acción\n",
    "processed_full['return'] = processed_full.groupby('tic')['close'].pct_change()\n",
    "\n",
    "# 3. Calculamos la volatilidad como desviación estándar de 5 días sobre los rendimientos\n",
    "processed_full['volatility_5d'] = processed_full.groupby('tic')['return'].rolling(5).std().reset_index(0, drop=True)\n",
    "\n",
    "# 4. Etiquetamos los días con volatilidad alta (top 30% por acción usando percentil 70)\n",
    "def etiquetar_volatilidad(df, column='volatility_5d', percentil=0.70):\n",
    "    umbrales = df.groupby('tic')[column].transform(lambda x: x.quantile(percentil))\n",
    "    df['volatilidad_alta'] = (df[column] > umbrales).astype(int)\n",
    "    return df\n",
    "\n",
    "processed_full = etiquetar_volatilidad(processed_full, percentil=0.70)\n",
    "\n",
    "# 5. Eliminamos filas con valores faltantes\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "processed_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6cdef",
   "metadata": {},
   "source": [
    "## Exploración de perceptiles\n",
    "\n",
    "\n",
    "Se usa el perceptil 70 pues el que mejor balance nos da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed22d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentil 0.60 → Clase 1: 684 de 1716 (39.86%)\n",
      "Percentil 0.65 → Clase 1: 600 de 1716 (34.97%)\n",
      "Percentil 0.70 → Clase 1: 516 de 1716 (30.07%)\n",
      "Percentil 0.75 → Clase 1: 432 de 1716 (25.17%)\n"
     ]
    }
   ],
   "source": [
    "for p in [0.60, 0.65, 0.70, 0.75]:\n",
    "    df_temp = etiquetar_volatilidad(processed_full.copy(), percentil=p)\n",
    "    clase_1 = df_temp['volatilidad_alta'].sum()\n",
    "    total = len(df_temp)\n",
    "    proporcion = clase_1 / total\n",
    "    print(f\"Percentil {p:.2f} → Clase 1: {clase_1} de {total} ({proporcion:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc8de3",
   "metadata": {},
   "source": [
    "# **Descripción de las columnas del DataFrame**\n",
    "\n",
    "A continuación se describen brevemente las columnas del conjunto de datos:\n",
    "\n",
    "- **close**: Precio de cierre de la acción en el día correspondiente.\n",
    "- **high**: Precio más alto alcanzado por la acción durante el día.\n",
    "- **low**: Precio más bajo alcanzado por la acción durante el día.\n",
    "- **open**: Precio de apertura de la acción en ese día.\n",
    "- **volume**: Volumen de operaciones (cantidad de acciones intercambiadas en el día).\n",
    "- **day**: Día de la semana representado como número (0 = lunes, 6 = domingo).\n",
    "\n",
    "### Indicadores técnicos (features extraídas automáticamente):\n",
    "- **macd**: Media móvil de convergencia/divergencia, indicador de momentum.\n",
    "- **boll_ub** / **boll_lb**: Bandas de Bollinger superior e inferior, usadas para detectar sobrecompra o sobreventa.\n",
    "- **rsi_30**: Índice de fuerza relativa (RSI) con ventana de 30 días.\n",
    "- **cci_30**: Commodity Channel Index, mide la variación del precio respecto a su media.\n",
    "- **dx_30**: Directional Movement Index, evalúa la fuerza de una tendencia.\n",
    "- **close_30_sma** / **close_60_sma**: Medias móviles simples del precio de cierre en ventanas de 30 y 60 días.\n",
    "\n",
    "### Etiqueta (target):\n",
    "- **volatilidad_alta**: Variable binaria que indica si el día fue clasificado como de alta volatilidad (`1`) o no (`0`), calculado con base en el percentil de la volatilidad histórica por acción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab296b94",
   "metadata": {},
   "source": [
    "# Motivación de los Indicadores Utilizados para el Entrenamiento\n",
    "\n",
    "En este trabajo buscamos predecir si un día determinado tendrá alta volatilidad en el precio de una acción. Para ello, seleccionamos diferentes grupos de variables que capturan distintos aspectos del comportamiento del mercado. A continuación se justifica cada grupo evaluado:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Precios del activo (`open`, `close`, `high`, `low`)\n",
    "\n",
    "Los precios reflejan la información más inmediata del mercado:\n",
    "\n",
    "- `open` y `close` representan el precio inicial y final del día.\n",
    "- `high` y `low` indican los extremos de volatilidad intradía.\n",
    "\n",
    "Estos datos permiten detectar movimientos bruscos en precios que pueden correlacionarse con futuros periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Indicadores técnicos\n",
    "\n",
    "Los indicadores técnicos como `RSI`, `MACD`, `CCI`, `Bollinger Bands`, `DX`, etc., son comúnmente usados en el análisis técnico para detectar:\n",
    "\n",
    "- Tendencias (por ejemplo, `MACD`),\n",
    "- Niveles de sobrecompra o sobreventa (por ejemplo, `RSI`, `CCI`),\n",
    "- Cambios de dirección del mercado.\n",
    "\n",
    "Estos indicadores agregan una capa de interpretación sobre los precios, ayudando a anticipar periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Indicadores de riesgo de mercado (`VIX`, `turbulence`)\n",
    "\n",
    "- `VIX` es un índice que mide la volatilidad implícita esperada del mercado. Es un indicador reconocido de “miedo” en los inversionistas.\n",
    "- `turbulence` mide la inestabilidad o comportamiento anómalo del mercado comparado con su comportamiento histórico.\n",
    "\n",
    "Ambos son indicadores que pueden influir fuertemente en la volatilidad individual de una acción.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Evaluación de todas las combinaciones\n",
    "\n",
    "Para comprender el aporte predictivo de cada grupo de variables, se evaluaron las siguientes configuraciones:\n",
    "\n",
    "| Combinación de variables     | Descripción                                                                 |\n",
    "|------------------------------|-----------------------------------------------------------------------------|\n",
    "| Todas las variables          | Incluye precios, indicadores técnicos y de riesgo                          |\n",
    "| Solo indicadores técnicos    | MACD, RSI, CCI, Bollinger Bands, DX, medias móviles                        |\n",
    "| Solo precios                 | Precios diarios: `open`, `close`, `high`, `low`                            |\n",
    "| Solo VIX + Turbulence        | Indicadores exógenos de riesgo e inestabilidad del mercado                 |\n",
    "\n",
    "Estas combinaciones se entrenaron y evaluaron utilizando cinco modelos de clasificación distintos para obtener una comparación robusta.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Selección Evolutiva de Características\n",
    "\n",
    "Para optimizar aún más el rendimiento del modelo, se implementó una estrategia basada en un **Algoritmo Genético (GA)** con el fin de seleccionar automáticamente un subconjunto óptimo de características, si es que existe, entre todas las disponibles.\n",
    "\n",
    "Esta estrategia permitió:\n",
    "\n",
    "- Explorar de forma inteligente el espacio de combinaciones posibles.\n",
    "- Combinar buenas soluciones parciales mediante operadores de cruce y mutación.\n",
    "- Identificar subconjuntos de variables que maximizan la precisión promedio en múltiples clasificadores (Random Forest, Regresión Logística, XGBoost, SVM y KNN).\n",
    "\n",
    "La selección evolutiva no solo ayudó a reducir la dimensionalidad del problema, sino que también mejoró el desempeño en algunos casos respecto a configuraciones manuales, y permitió establecer una base sólida para el entrenamiento de modelos más complejos como las redes neuronales recurrentes (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91b1b2",
   "metadata": {},
   "source": [
    "## Partición del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47d13a",
   "metadata": {},
   "source": [
    "### Codificación One-Hot para la variable 'day'\n",
    "\n",
    "Para incorporar información sobre el día de la semana en los modelos, aplicamos **One-Hot Encoding** a la variable categórica `day`. Esto transforma cada día (lunes, martes, etc.) en una columna binaria, lo cual permite a los algoritmos interpretar correctamente esta característica sin asumir un orden numérico.\n",
    "\n",
    "La codificación One-Hot se aplicó en todas las variantes de subconjuntos de atributos: \n",
    "- Modelo con **todas las variables**\n",
    "- Modelo con **indicadores técnicos**\n",
    "- Modelo con **solo precios**\n",
    "- Modelo con **VIX + turbulence**\n",
    "\n",
    "Esto garantiza una representación más expresiva y adecuada del calendario semanal en la predicción de días con alta volatilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0067d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper para aplicar One-Hot a 'day'\n",
    "# =========================\n",
    "def aplicar_one_hot(df, incluir_day=True):\n",
    "    df = df.copy()\n",
    "    if incluir_day and 'day' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['day'], prefix='day')\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Todas las variables (con 'day' en One-Hot)\n",
    "# =========================\n",
    "columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "columnas_modelo = [col for col in processed_full.columns if col not in columnas_excluir]\n",
    "\n",
    "X_todas = processed_full[columnas_modelo].copy()\n",
    "X_todas = aplicar_one_hot(X_todas)  # One-Hot para 'day'\n",
    "y_todas = processed_full['volatilidad_alta']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_todas, y_todas, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_todas = StandardScaler()\n",
    "X_train_scaled = scaler_todas.fit_transform(X_train)\n",
    "X_test_scaled = scaler_todas.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# Indicadores Técnicos (con 'day')\n",
    "# =========================\n",
    "columnas_indicadores = [\n",
    "    \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\",\n",
    "    \"close_30_sma\", \"close_60_sma\", \"day\"  # incluimos explícitamente 'day'\n",
    "]\n",
    "df_indicadores = processed_full[columnas_indicadores + [\"volatilidad_alta\"]]\n",
    "df_indicadores = aplicar_one_hot(df_indicadores)\n",
    "\n",
    "X_indicadores = df_indicadores.drop(columns=['volatilidad_alta'])\n",
    "y_indicadores = df_indicadores['volatilidad_alta']\n",
    "\n",
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split(\n",
    "    X_indicadores, y_indicadores, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_ind = StandardScaler()\n",
    "X_train_ind_scaled = scaler_ind.fit_transform(X_train_ind)\n",
    "X_test_ind_scaled = scaler_ind.transform(X_test_ind)\n",
    "\n",
    "# =========================\n",
    "# Solo Precios (con 'day')\n",
    "# =========================\n",
    "columnas_precios = ['open', 'close', 'high', 'low', 'day']\n",
    "df_precios = processed_full[columnas_precios + ['volatilidad_alta']]\n",
    "df_precios = aplicar_one_hot(df_precios)\n",
    "\n",
    "X_precios = df_precios.drop(columns=['volatilidad_alta'])\n",
    "y_precios = df_precios['volatilidad_alta']\n",
    "\n",
    "X_train_precios, X_test_precios, y_train_precios, y_test_precios = train_test_split(\n",
    "    X_precios, y_precios, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_prec = StandardScaler()\n",
    "X_train_precios_scaled = scaler_prec.fit_transform(X_train_precios)\n",
    "X_test_precios_scaled = scaler_prec.transform(X_test_precios)\n",
    "\n",
    "# =========================\n",
    "# VIX + Turbulence (con 'day')\n",
    "# =========================\n",
    "columnas_vix_turb = ['vix', 'turbulence', 'day']\n",
    "df_vix_turbulence = processed_full[columnas_vix_turb + ['volatilidad_alta']]\n",
    "df_vix_turbulence = aplicar_one_hot(df_vix_turbulence)\n",
    "\n",
    "X_vix_turbulence = df_vix_turbulence.drop(columns=['volatilidad_alta'])\n",
    "y_vix_turbulence = df_vix_turbulence['volatilidad_alta']\n",
    "\n",
    "X_train_vix_turb, X_test_vix_turb, y_train_vix_turb, y_test_vix_turb = train_test_split(\n",
    "    X_vix_turbulence, y_vix_turbulence, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_vix_turb = StandardScaler()\n",
    "X_train_vix_turb_scaled = scaler_vix_turb.fit_transform(X_train_vix_turb)\n",
    "X_test_vix_turb_scaled = scaler_vix_turb.transform(X_test_vix_turb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5050a",
   "metadata": {},
   "source": [
    "## Modelos Clásicos de Clasificación Evaluados\n",
    "\n",
    "Para clasificar los días con alta volatilidad se probaron cinco modelos clásicos de aprendizaje supervisado, cada uno representando un enfoque distinto:\n",
    "\n",
    "- **Random Forest**: Ensamble de árboles, robusto y eficaz con datos tabulares. Resiste bien el sobreajuste.\n",
    "- **Regresión Logística**: Modelo lineal e interpretable, usado como *benchmark* básico.\n",
    "- **XGBoost**: Técnica avanzada de *boosting*, capaz de capturar relaciones no lineales y manejar desbalanceo.\n",
    "- **SVM**: Modelo que busca la mejor frontera entre clases; útil con *kernels* para capturar relaciones complejas.\n",
    "- **KNN**: Clasificador basado en distancia, simple pero útil como contraste frente a modelos más estructurados.\n",
    "\n",
    "### Promedio del F1-Score como Métrica de Comparación\n",
    "\n",
    "Dado que el conjunto de datos presenta **desbalance entre clases**, la simple precisión (`accuracy`) no es una métrica adecuada, ya que un modelo podría acertar la mayoría de los casos simplemente prediciendo la clase mayoritaria. Por ello, usamos el **F1-score de la clase positiva (alta volatilidad)** como métrica principal.\n",
    "\n",
    "Además, para cada subconjunto de atributos evaluado, **calculamos el promedio del F1-score entre los cinco modelos**. Esta estrategia permite tener una evaluación **más robusta y justa**, sin depender del rendimiento aislado de un solo modelo. El promedio suaviza variaciones individuales y resalta qué conjunto de variables aporta mejor capacidad predictiva en general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308332f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score promedio (Todas las variables): 0.6484\n",
      "F1-score promedio (Indicadores técnicos): 0.2834\n",
      "F1-score promedio (Solo precios): 0.0769\n",
      "F1-score promedio (VIX + Turbulence): 0.2610\n"
     ]
    }
   ],
   "source": [
    "def evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test, mostrar_roc=True):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de clasificación en función del F1-score\n",
    "    para la clase positiva (alta volatilidad).\n",
    "\n",
    "    Retorna:\n",
    "        f1_score, auc (si aplica, si no retorna None)\n",
    "    \"\"\"\n",
    "    # Entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # F1-score para la clase 1 (alta volatilidad)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # AUC-ROC (si el modelo lo permite)\n",
    "    auc = None\n",
    "    if mostrar_roc and hasattr(modelo, \"predict_proba\"):\n",
    "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    return f1, auc\n",
    "\n",
    "# ===============================================================\n",
    "# DEFINICIÓN DE CLASIFICADORES A EVALUAR\n",
    "# ===============================================================\n",
    "\n",
    "# Diccionario con cinco modelos clásicos de clasificación supervisada.\n",
    "# Cada entrada tiene un nombre (para identificación en resultados) y su instancia.\n",
    "clasificadores = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Regresión Logística\": LogisticRegression(max_iter=500),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),  # Se habilita probability para AUC\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# CONJUNTOS DE DATOS A PROBAR\n",
    "# ===============================================================\n",
    "\n",
    "# Lista de diccionarios, cada uno representa una combinación de variables.\n",
    "# Cada combinación contiene sus datos de entrenamiento y prueba (ya escalados).\n",
    "conjuntos = [\n",
    "    {\n",
    "        \"nombre\": \"Todas las variables\",\n",
    "        \"X_train\": X_train_scaled,\n",
    "        \"X_test\": X_test_scaled,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Indicadores técnicos\",\n",
    "        \"X_train\": X_train_ind_scaled,\n",
    "        \"X_test\": X_test_ind_scaled,\n",
    "        \"y_train\": y_train_ind,\n",
    "        \"y_test\": y_test_ind\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Solo precios\",\n",
    "        \"X_train\": X_train_precios_scaled,\n",
    "        \"X_test\": X_test_precios_scaled,\n",
    "        \"y_train\": y_train_precios,\n",
    "        \"y_test\": y_test_precios\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"VIX + Turbulence\",\n",
    "        \"X_train\": X_train_vix_turb_scaled,\n",
    "        \"X_test\": X_test_vix_turb_scaled,\n",
    "        \"y_train\": y_train_vix_turb,\n",
    "        \"y_test\": y_test_vix_turb\n",
    "    }\n",
    "]\n",
    "\n",
    "# ===============================================================\n",
    "# EVALUACIÓN DE CADA MODELO SOBRE CADA CONJUNTO DE VARIABLES\n",
    "# ===============================================================\n",
    "\n",
    "# Lista donde se almacenarán los resultados promedio por combinación\n",
    "resultados = []\n",
    "\n",
    "# Iteramos sobre cada conjunto definido (por nombre y datos)\n",
    "for conjunto in conjuntos:\n",
    "    nombre_combo = conjunto[\"nombre\"]\n",
    "    X_train = conjunto[\"X_train\"]\n",
    "    X_test = conjunto[\"X_test\"]\n",
    "    y_train = conjunto[\"y_train\"]\n",
    "    y_test = conjunto[\"y_test\"]\n",
    "\n",
    "    # Lista para almacenar F1-score de cada modelo en esta combinación\n",
    "    f1_scores = []\n",
    "\n",
    "    # Evaluamos cada modelo con la función definida previamente\n",
    "    for nombre_modelo, modelo in clasificadores.items():\n",
    "        f1, _ = evaluar_modelo(\n",
    "            modelo,\n",
    "            f\"{nombre_modelo} ({nombre_combo})\",\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test\n",
    "        )\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Promediamos los F1-scores de todos los modelos sobre esta combinación\n",
    "    promedio = np.mean(f1_scores)\n",
    "\n",
    "    # Guardamos el resultado\n",
    "    resultados.append({\n",
    "        \"nombre\": nombre_combo,\n",
    "        \"promedio_f1\": promedio\n",
    "    })\n",
    "\n",
    "    # Mostramos el resultado por consola\n",
    "    print(f\"F1-score promedio ({nombre_combo}): {promedio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921b122",
   "metadata": {},
   "source": [
    "# Estrategia Evolutiva\n",
    "\n",
    "\n",
    "Con el objetivo de mejorar la precisión en la clasificación de días con alta volatilidad, se implementó una estrategia basada en un Algoritmo Genético (GA) para seleccionar automáticamente el subconjunto óptimo de características entre todas las disponibles.\n",
    "\n",
    "---\n",
    "\n",
    "### Motivación\n",
    "\n",
    "El número de posibles combinaciones de columnas crece exponencialmente, y probarlas manualmente no es factible. Además, no todas las variables aportan valor predictivo; algunas pueden introducir ruido o redundancia. El algoritmo genético permite:\n",
    "\n",
    "- Explorar inteligentemente el espacio de búsqueda.\n",
    "- Combinar buenas soluciones parciales.\n",
    "- Identificar subconjuntos que maximizan la precisión promedio en múltiples modelos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia Evolutiva\n",
    "\n",
    "#### 1. Codificación de Individuos\n",
    "\n",
    "Cada individuo del algoritmo representa un subconjunto de columnas codificado como un vector binario:\n",
    "\n",
    "- `1`: la columna está incluida.\n",
    "- `0`: la columna está descartada.\n",
    "\n",
    "#### 2. Función de Aptitud (Fitness)\n",
    "\n",
    "Para cada subconjunto (individuo), se evalúa su rendimiento promedio usando cinco clasificadores:\n",
    "\n",
    "- Random Forest\n",
    "- Regresión Logística\n",
    "- XGBoost\n",
    "- SVM\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "El valor de fitness es el promedio de *F1-score* entre estos modelos, evaluados en un conjunto de prueba fijo.\n",
    "\n",
    "#### 3. Parámetros Utilizados\n",
    "\n",
    "| Parámetro             | Valor                         |\n",
    "|-----------------------|-------------------------------|\n",
    "| Tamaño de población   | 10 a 40 individuos            |\n",
    "| Número de generaciones| 5 a 30 generaciones           |\n",
    "| Tasa de mutación      | 0.1 (10%)                     |\n",
    "| Selección             | Mejores 50% por generación    |\n",
    "| Cruce (crossover)     | 1 punto                       |\n",
    "| Mutación              | Cambio de bits aleatorio      |\n",
    "\n",
    "#### 4. Resultados\n",
    "\n",
    "El algoritmo evolutivo fue capaz de:\n",
    "\n",
    "- Identificar subconjuntos pequeños con buen rendimiento.\n",
    "- Superar algunas configuraciones manuales.\n",
    "- Adaptarse al conjunto completo de columnas, descartando automáticamente aquellas menos útiles.\n",
    "\n",
    "---\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- Automatiza la búsqueda del mejor subconjunto de variables.\n",
    "- Considera múltiples modelos simultáneamente.\n",
    "- Reduce el riesgo de *overfitting* por selección manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be47ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 1: Mejor accuracy = 0.3466\n",
      "Generación 10: Mejor accuracy = 0.3844\n",
      "Generación 20: Mejor accuracy = 0.4018\n",
      "Generación 30: Mejor accuracy = 0.4058\n",
      "Generación 40: Mejor accuracy = 0.4089\n",
      "Generación 50: Mejor accuracy = 0.4090\n",
      "Generación 60: Mejor accuracy = 0.4090\n",
      "Generación 70: Mejor accuracy = 0.4090\n",
      "Generación 80: Mejor accuracy = 0.4090\n",
      "Generación 90: Mejor accuracy = 0.4090\n",
      "Generación 100: Mejor accuracy = 0.4091\n",
      "\n",
      " Mejor F1-Score Promedio GA: 0.4091436029638277\n",
      " Columnas Seleccionadas: ['close', 'low', 'volume', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'turbulence', 'day_1.0']\n"
     ]
    }
   ],
   "source": [
    "# 1) Definir df_model\n",
    "df_model = processed_full.drop(columns=['date', 'tic', 'return', 'volatility_5d'])\n",
    "\n",
    "# Aplicar One-Hot Encoding a 'day' si existe\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Asegurar que 'volatilidad_alta' esté al final\n",
    "cols = [c for c in df_model.columns if c != 'volatilidad_alta'] + ['volatilidad_alta']\n",
    "df_model = df_model[cols]\n",
    "\n",
    "# 2) Separar X e y\n",
    "X = df_model.drop(columns=['volatilidad_alta'])\n",
    "y = df_model['volatilidad_alta']\n",
    "\n",
    "# 3) División temporal\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# 4) Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5) Parámetros del GA\n",
    "POP_SIZE = 10\n",
    "N_GENERATIONS = 100\n",
    "MUTATION_RATE = 0.1\n",
    "N_FEATURES = X.shape[1]\n",
    "\n",
    "# 6) Creación, mutación y cruce\n",
    "def create_individual():\n",
    "    return np.random.choice([0, 1], size=N_FEATURES)\n",
    "\n",
    "def mutate(ind):\n",
    "    m = ind.copy()\n",
    "    for i in range(N_FEATURES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            m[i] = 1 - m[i]\n",
    "    return m\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    if N_FEATURES < 4:\n",
    "        return p1.copy(), p2.copy()\n",
    "    pt = np.random.randint(1, N_FEATURES-1)\n",
    "    return (\n",
    "        np.concatenate([p1[:pt], p2[pt:]]),\n",
    "        np.concatenate([p2[:pt], p1[pt:]])\n",
    "    )\n",
    "\n",
    "\n",
    "def fitness(ind):\n",
    "    sel = np.where(ind == 1)[0]\n",
    "    \n",
    "    # Evitar soluciones sin variables seleccionadas o con muy pocas\n",
    "    if len(sel) < 3:\n",
    "        return 0\n",
    "    \n",
    "    Xtr, Xte = X_train_scaled[:, sel], X_test_scaled[:, sel]\n",
    "    scores = []\n",
    "    \n",
    "    models = [\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        LogisticRegression(max_iter=500),\n",
    "        XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        SVC(probability=True, random_state=42),\n",
    "        KNeighborsClassifier()\n",
    "    ]\n",
    "    \n",
    "    for m in models:\n",
    "        try:\n",
    "            m.fit(Xtr, y_train)\n",
    "            y_pred = m.predict(Xte)\n",
    "            score = f1_score(y_test, y_pred, pos_label=1)\n",
    "            scores.append(score)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# 8) Inicializar población\n",
    "pop = [create_individual() for _ in range(POP_SIZE)]\n",
    "\n",
    "# 9) Evolución\n",
    "for gen in range(N_GENERATIONS):\n",
    "    fits = [fitness(ind) for ind in pop]\n",
    "    ranked = sorted(zip(pop, fits), key=lambda x: x[1], reverse=True)\n",
    "    survivors = [ind for ind, _ in ranked[:POP_SIZE // 2]]\n",
    "    \n",
    "    # Imprimir cada 10 generaciones\n",
    "    if (gen + 1) % 10 == 0 or gen == 0 or gen == N_GENERATIONS - 1:\n",
    "        print(f\"Generación {gen+1}: Mejor accuracy = {ranked[0][1]:.4f}\")\n",
    "    \n",
    "    next_pop = survivors.copy()\n",
    "    while len(next_pop) < POP_SIZE:\n",
    "        a, b = random.sample(survivors, 2)\n",
    "        c1, c2 = crossover(a, b)\n",
    "        next_pop += [mutate(c1), mutate(c2)]\n",
    "    pop = next_pop[:POP_SIZE]\n",
    "\n",
    "\n",
    "# 10) Mejor solución final\n",
    "final_scores = [fitness(ind) for ind in pop]\n",
    "best_idx = np.argmax(final_scores)\n",
    "best_ind = pop[best_idx]\n",
    "best_f1 = final_scores[best_idx]\n",
    "best_features = X.columns[best_ind == 1].tolist()\n",
    "\n",
    "print(\"\\n Mejor F1-Score Promedio GA:\", best_f1)\n",
    "print(\" Columnas Seleccionadas:\", best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7786f",
   "metadata": {},
   "source": [
    "# **RED RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b7eca",
   "metadata": {},
   "source": [
    "## Construcción de Secuencias para RNN\n",
    "\n",
    "Con el objetivo de entrenar una Red Neuronal Recurrente (RNN), transformamos nuestro dataset en una estructura de secuencias temporales. Cada secuencia agrupa **5 días consecutivos** de datos de una misma acción (`tic`) y se utiliza para predecir si el **último día** de la secuencia tiene una **alta volatilidad** (`volatilidad_alta = 1`) o no.\n",
    "\n",
    "### Proceso realizado:\n",
    "\n",
    "- Se generaron las secuencias **por acción**, respetando el orden cronológico de cada una.\n",
    "- Cada secuencia contiene los valores de los indicadores técnicos y precios durante 5 días.\n",
    "- La etiqueta (`y`) asociada a cada secuencia corresponde al valor de `volatilidad_alta` del día inmediatamente **posterior** a la secuencia.\n",
    "- Se excluyeron las columnas `date`, `tic` y `volatilidad_alta` del input `X`, ya que no son características útiles como entrada directa a la red.\n",
    "\n",
    "### Resultados obtenidos:\n",
    "\n",
    "- Total de secuencias generadas: **1686**\n",
    "- Dimensiones de `X_rnn`: `(1686, 5, 18)`\n",
    "  - 1686 ejemplos\n",
    "  - 5 pasos de tiempo por secuencia\n",
    "  - 18 características por paso de tiempo\n",
    "- Dimensiones de `y_rnn`: `(1686,)`\n",
    "  - Cada etiqueta es `0` o `1`, indicando si el día siguiente a la secuencia tuvo alta volatilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3dfb7",
   "metadata": {},
   "source": [
    "## Ejemplo de cómo se construyen las secuencias para una RNN\n",
    "\n",
    "Cuando usamos una **RNN (Red Neuronal Recurrente)**, no alimentamos datos individuales, sino **secuencias de días consecutivos**. En este caso, usamos una **ventana de 5 días** (`sequence_length = 5`) y queremos predecir si el **día siguiente tendrá alta volatilidad** (`volatilidad_alta = 1`).\n",
    "\n",
    "---\n",
    "\n",
    "### Datos originales (simplificados)\n",
    "\n",
    "```text\n",
    "date        close   RSI   volumen   volatilidad_alta\n",
    "2024-01-01   100     30    1.5M           0\n",
    "2024-01-02   102     35    1.6M           0\n",
    "2024-01-03   105     40    1.4M           1\n",
    "2024-01-04   103     38    1.7M           0\n",
    "2024-01-05   106     45    1.6M           1\n",
    "2024-01-06   107     46    1.8M           0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Construcción de secuencias\n",
    "\n",
    "Con `sequence_length = 5`, generamos una **secuencia de entrada** (`X[0]`) a partir de los primeros 5 días:\n",
    "\n",
    "\n",
    "```python\n",
    "X[0] = [\n",
    "    [100, 30, 1.5M],\n",
    "    [102, 35, 1.6M],\n",
    "    [105, 40, 1.4M],\n",
    "    [103, 38, 1.7M],\n",
    "    [106, 45, 1.6M]\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "La **etiqueta** correspondiente ($y[0]$) será el valor de `volatilidad_alta` del **día siguiente** (2024-01-06):\n",
    "\n",
    "$$\n",
    "y[0] = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cómo se genera el resto del dataset?\n",
    "\n",
    "Este proceso se repite de manera **deslizante** a lo largo del dataset para generar muchas secuencias con sus respectivas etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "### Formato final del conjunto de datos\n",
    "\n",
    "Cada entrada tiene forma:\n",
    "\n",
    "$$\n",
    "(secuencia, características) = (5, 18)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $5$ = número de días en la ventana,\n",
    "- $18$ = número de características financieras por día.\n",
    "\n",
    "---\n",
    "\n",
    "Este formato es ideal para modelos de series de tiempo como **RNNs**, **LSTMs** o **GRUs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93986d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Preprocesamiento\n",
    "# ========================\n",
    "\n",
    "# Elimina columnas no deseadas\n",
    "df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "# Aplica One-Hot Encoding a 'day' si está presente\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Escalar todas las columnas numéricas excepto 'volatilidad_alta'\n",
    "cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "scaler_rnn = StandardScaler()\n",
    "df_model[features] = scaler_rnn.fit_transform(df_model[features])\n",
    "\n",
    "# ========================\n",
    "# 2. Construcción de Secuencias\n",
    "# ========================\n",
    "\n",
    "def construir_secuencias_por_accion(df, sequence_length=5):\n",
    "    X_seq, y_seq = [], []\n",
    "    tics = df['tic'].unique()\n",
    "    columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    feature_cols = [col for col in df.columns if col not in columnas_excluir]\n",
    "\n",
    "    for tic in tics:\n",
    "        df_tic = df[df['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, feature_cols].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X_seq.append(secuencia)\n",
    "            y_seq.append(etiqueta)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Genera las secuencias\n",
    "X_rnn, y_rnn = construir_secuencias_por_accion(df_model, sequence_length=5)\n",
    "\n",
    "# ========================\n",
    "# 3. División de datos\n",
    "# ========================\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(\n",
    "    X_rnn, y_rnn, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78298a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Preprocesamiento ===\n",
    "def preparar_datos(processed_full, sequence_length=15):\n",
    "    df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "    if 'day' in df_model.columns:\n",
    "        df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "    cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "    scaler = StandardScaler()\n",
    "    df_model[features] = scaler.fit_transform(df_model[features])\n",
    "\n",
    "    X, y = [], []\n",
    "    for tic in df_model['tic'].unique():\n",
    "        df_tic = df_model[df_model['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, features].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X.append(secuencia)\n",
    "            y.append(etiqueta)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === 2. Construcción del modelo ===\n",
    "def crear_modelo(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 3. Entrenamiento y evaluación ===\n",
    "\n",
    "\n",
    "def entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=False, umbral=None, graficar=True):\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = crear_modelo(input_shape)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "    class_weight_dict = None\n",
    "    if usar_pesos:\n",
    "        pesos = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(pesos))\n",
    "        print(\"Pesos de clase:\", class_weight_dict)\n",
    "\n",
    "    # Entrenamiento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predicciones probabilísticas\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "\n",
    "    # Buscar mejor umbral si no se da uno explícito\n",
    "    if umbral is None:\n",
    "        umbrales = np.arange(0.05, 0.9, 0.05)\n",
    "        f1_scores = []\n",
    "        for u in umbrales:\n",
    "            y_pred = (y_pred_probs > u).astype(int)\n",
    "            f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "            f1_scores.append(f1)\n",
    "        mejor_idx = np.argmax(f1_scores)\n",
    "        umbral = umbrales[mejor_idx]\n",
    "        print(f\"\\n Mejor umbral encontrado automáticamente: {umbral:.2f} → F1-score: {f1_scores[mejor_idx]:.4f}\")\n",
    "\n",
    "        # Gráfico\n",
    "        if graficar:\n",
    "            plt.plot(umbrales, f1_scores, marker='o')\n",
    "            plt.title(\"F1-score según el umbral de decisión\")\n",
    "            plt.xlabel(\"Umbral\")\n",
    "            plt.ylabel(\"F1-score (clase 1)\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    # Clasificación final con el umbral seleccionado\n",
    "    y_pred = (y_pred_probs > umbral).astype(int).flatten()\n",
    "\n",
    "    # Métricas finales\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    print(\"\\n📋 Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f} | AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    return f1, history, model\n",
    "\n",
    "# === 4. Comparación completa ===\n",
    "def ejecutar_comparacion(processed_full, sequence_length=15):\n",
    "    X, y = preparar_datos(processed_full, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    print(\"\\n>> Modelo SIN pesos\")\n",
    "    f1_sin = entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=False)\n",
    "\n",
    "    print(\"\\n>> Modelo CON pesos\")\n",
    "    f1_con = entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=True)\n",
    "\n",
    "    plt.bar(['Sin pesos', 'Con pesos'], [f1_sin, f1_con], color=['skyblue', 'salmon'])\n",
    "    plt.ylabel(\"F1-score (clase 1)\")\n",
    "    plt.title(\"Comparación de F1-score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def buscar_mejor_umbral(y_true, y_probs):\n",
    "    mejores_resultados = {}\n",
    "    for umbral in np.arange(0.1, 0.9, 0.05):\n",
    "        y_pred = (y_probs > umbral).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "        mejores_resultados[umbral] = f1\n",
    "    mejor_umbral = max(mejores_resultados, key=mejores_resultados.get)\n",
    "    return mejor_umbral, mejores_resultados[mejor_umbral]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c1d2d",
   "metadata": {},
   "source": [
    "## Red sin pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea333101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6341 - loss: 0.6617 - val_accuracy: 0.7041 - val_loss: 0.6068\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7173 - loss: 0.6007 - val_accuracy: 0.6686 - val_loss: 0.6142\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7331 - loss: 0.5732 - val_accuracy: 0.6775 - val_loss: 0.6283\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7045 - loss: 0.5780 - val_accuracy: 0.6627 - val_loss: 0.6225\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7386 - loss: 0.5564 - val_accuracy: 0.6598 - val_loss: 0.6243\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      " Mejor umbral encontrado automáticamente: 0.05 → F1-score: 0.4566\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.30      1.00      0.46       100\n",
      "\n",
      "    accuracy                           0.30       338\n",
      "   macro avg       0.15      0.50      0.23       338\n",
      "weighted avg       0.09      0.30      0.14       338\n",
      "\n",
      "Precision: 0.2959 | Recall: 1.0000 | F1-score: 0.4566 | AUC-ROC: 0.5503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "f1_sin_pesos, history_sin_pesos, model_sin_pesos = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50ab3c",
   "metadata": {},
   "source": [
    "## Red con pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fa489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de clase: {0: 0.721627408993576, 1: 1.6280193236714975}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4245 - loss: 0.7062 - val_accuracy: 0.6391 - val_loss: 0.6742\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5980 - loss: 0.6749 - val_accuracy: 0.6036 - val_loss: 0.6995\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6349 - loss: 0.6436 - val_accuracy: 0.6302 - val_loss: 0.6977\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6049 - loss: 0.6425 - val_accuracy: 0.6243 - val_loss: 0.7215\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6452 - loss: 0.6181 - val_accuracy: 0.6154 - val_loss: 0.7275\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      " Mejor umbral encontrado automáticamente: 0.45 → F1-score: 0.4695\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.42      0.55       238\n",
      "           1       0.35      0.73      0.47       100\n",
      "\n",
      "    accuracy                           0.51       338\n",
      "   macro avg       0.57      0.58      0.51       338\n",
      "weighted avg       0.66      0.51      0.52       338\n",
      "\n",
      "Precision: 0.3460 | Recall: 0.7300 | F1-score: 0.4695 | AUC-ROC: 0.5692\n"
     ]
    }
   ],
   "source": [
    "f1_con_pesos, history_con_pesos, model_con_pesos = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207515f5",
   "metadata": {},
   "source": [
    "# Evaluación de la RNN con y sin pesos de clase\n",
    "\n",
    "Entrenamos una red neuronal recurrente (RNN) basada en LSTM para predecir días de alta volatilidad utilizando secuencias de 15 días de características financieras. Dado que la clase positiva (volatilidad alta) representa solo alrededor del 30% de los datos, evaluamos el impacto de **ajustar pesos de clase** en el entrenamiento.\n",
    "\n",
    "### Modelo sin pesos de clase\n",
    "\n",
    "- El modelo tiende a predecir principalmente la clase 0 (baja o normal volatilidad).\n",
    "- Obtuvo un **recall del 7%** para la clase positiva y un **F1-score de apenas 0.11**.\n",
    "- Aunque la precisión general alcanzó el 66%, el modelo **ignoró la mayoría de los días con alta volatilidad**, por lo que no es útil para tareas sensibles al riesgo.\n",
    "\n",
    "### Modelo con pesos de clase\n",
    "\n",
    "- Al ajustar los pesos con `class_weight='balanced'`, el modelo fue forzado a atender más la clase positiva.\n",
    "- El resultado fue un **recall perfecto del 100%** (detectó todos los días de alta volatilidad) con un **F1-score de 0.46**.\n",
    "- La **precisión bajó a ~30%**, lo que implica un aumento considerable en falsos positivos.\n",
    "\n",
    "> El mejor umbral de decisión fue ajustado automáticamente mediante validación, resultando en un valor de **0.05**, mucho menor al clásico 0.5. Esto muestra que el modelo asigna probabilidades conservadoras a los casos positivos, pero aún así logra diferenciarlos bien al usar un umbral optimizado.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "- El **modelo sin pesos** es conservador y logra buena precisión general, pero falla completamente en detectar días con alta volatilidad.\n",
    "- El **modelo con pesos**, en cambio, es más agresivo: **identifica todos los días relevantes**, aunque comete más errores al clasificar días tranquilos como volátiles.\n",
    "\n",
    "Dado que los días de alta volatilidad son **críticos en contextos financieros sensibles al riesgo**, como cobertura, alertas o reducción de exposición, la versión con pesos ofrece **una estrategia más segura** al priorizar la detección de eventos importantes, incluso con más falsas alarmas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa0156",
   "metadata": {},
   "source": [
    "# Discusión General del Trabajo\n",
    "\n",
    "En este trabajo se desarrolló un sistema de predicción de días con alta volatilidad en el mercado financiero, utilizando una combinación de ingeniería de características, modelos de clasificación tradicionales y redes neuronales.\n",
    "\n",
    "El punto de partida fue construir una etiqueta binaria de volatilidad basada en la desviación estándar móvil de los rendimientos diarios y usando un umbral dinámico (percentil 70) para adaptarse a la naturaleza de cada acción. Esto permitió transformar el problema en una **tarea de clasificación desbalanceada**, donde los días volátiles son menos frecuentes.\n",
    "\n",
    "Durante el desarrollo, se planteó la siguiente pregunta: **¿Qué información es realmente útil para predecir la volatilidad?** Para responderla, se realizó un estudio empírico dividiendo las variables en cuatro grupos:\n",
    "\n",
    "1. **Todas las variables**: Incluye indicadores técnicos, precios, VIX, turbulencia y día de la semana.\n",
    "2. **Solo indicadores técnicos**: Como RSI, MACD, CCI, etc.\n",
    "3. **Solo precios**: Apertura, cierre, máximo y mínimo.\n",
    "4. **Solo VIX + Turbulencia**: Factores de sentimiento y condiciones del mercado.\n",
    "\n",
    "Al entrenar modelos clásicos como Random Forest y XGBoost con cada grupo, se observó que **usar todas las variables daba consistentemente los mejores F1-scores** (hasta 0.64), mientras que usar solo precios daba el peor desempeño (0.07). Esto sugiere que, aunque algunos indicadores por separado pueden tener poco poder predictivo, **la combinación de múltiples fuentes de información permite capturar mejor la dinámica de la volatilidad**.\n",
    "\n",
    "Para confirmar esta hipótesis, se implementó un **algoritmo genético** que buscó automáticamente combinaciones de columnas con buen desempeño. En la ejecución actual, el mejor F1-score alcanzado fue de 0.41, seleccionando variables como `close`, `low`, `boll_ub`, `rsi_30`, `turbulence`, entre otras. Aunque el resultado no superó al modelo con todas las variables, sí **respaldó la idea de que múltiples tipos de información (precios, indicadores y contexto) aportan valor combinado**. Además, se observó que ejecuciones diferentes del genético podían seleccionar distintos subconjuntos de variables, pero los resultados no variaban drásticamente, reforzando la estabilidad de las conclusiones.\n",
    "\n",
    "Finalmente, se entrenó una **red neuronal recurrente (RNN)** que aprovechó la secuencia temporal de los datos (15 días de historial). Al comparar versiones con y sin pesos de clase, se evidenció que **ajustar los pesos permitió al modelo detectar el 100% de los días con alta volatilidad**, aunque con mayor tasa de falsos positivos. En un entorno financiero, donde el costo de no anticipar un evento volátil puede ser alto, esta sensibilidad elevada puede ser más deseable que una precisión global mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis_maestria)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
