{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5149c5f5",
   "metadata": {},
   "source": [
    "# **Ajustar Anchura** \n",
    "\n",
    "Esta línea hace que se ajuste la anchura del notebook, por defecto la ajusta a un 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6957203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:92% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:92% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492f5d8",
   "metadata": {},
   "source": [
    "# **Descargar Dependencias**\n",
    "\n",
    "Estos son los elementos que se tienen que descargar para un uso adecuado de todo el notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install swig\n",
    "# !pip install wrds\n",
    "# !pip install pyportfolioopt\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
    "# !pip install yfinance\n",
    "# !pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958c73c",
   "metadata": {},
   "source": [
    "# **Se importan las librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca975cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl import config_tickers\n",
    "from finrl.config import INDICATORS\n",
    "\n",
    "import itertools\n",
    "\n",
    "# 2. Separar en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870083b",
   "metadata": {},
   "source": [
    "# **Se descargan los datos históricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4300a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1752, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Las fechas deben seguir el formato 'año/mes/día' (YYYY-MM-DD)\n",
    "# Estas fechas delimitan el periodo de tiempo del que se descargarán los datos históricos\n",
    "START_DATE = '2024-01-01'   # Fecha de inicio del análisis\n",
    "END_DATE = '2025-03-04'     # Fecha de fin del análisis\n",
    "\n",
    "# Lista de símbolos (tickers) de las acciones que se analizarán\n",
    "# Estos corresponden a empresas cotizadas en bolsa como Moderna, Nvidia, Uber, etc.\n",
    "symbols = [\n",
    "    \"MRNA\",  # Moderna Inc.\n",
    "    \"NVDA\",  # Nvidia Corp.\n",
    "    \"UBER\",  # Uber Technologies Inc.\n",
    "    \"ASML\",  # ASML Holding N.V.\n",
    "    \"AMZN\",  # Amazon.com Inc.\n",
    "    \"AAPL\"   # Apple Inc.\n",
    "]\n",
    "\n",
    "# Usamos el módulo YahooDownloader de FinRL para descargar datos históricos de acciones\n",
    "# Se especifica el rango de fechas y la lista de símbolos (acciones) definidos previamente\n",
    "data = YahooDownloader(\n",
    "    start_date = START_DATE,   # Fecha de inicio del periodo de análisis\n",
    "    end_date = END_DATE,       # Fecha de fin del periodo de análisis\n",
    "    ticker_list = symbols      # Lista de acciones a descargar (AAPL, AMZN, etc.)\n",
    ").fetch_data()                 # Ejecuta la descarga y devuelve un DataFrame con los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ef0da",
   "metadata": {},
   "source": [
    "# **Extracción de Indicadores Técnicos y Reconstrucción de la Estructura Temporal**\n",
    "\n",
    "### 1. Extracción de Indicadores Técnicos\n",
    "\n",
    "Después de descargar los datos históricos de precios para varias acciones, se aplica un proceso de **ingeniería de características** para enriquecer el conjunto de datos con variables útiles para el modelo de aprendizaje automatizado.\n",
    "\n",
    "Para esto, se utiliza el módulo `FeatureEngineer` de la biblioteca FinRL. Este módulo permite calcular automáticamente varios **indicadores técnicos**, que son ampliamente utilizados en el análisis técnico del mercado bursátil. Estos indicadores ayudan a capturar tendencias, momentum y señales de sobrecompra o sobreventa en los precios.\n",
    "\n",
    "Entre los indicadores extraídos se encuentran:\n",
    "\n",
    "- **RSI (Relative Strength Index)**\n",
    "- **MACD (Moving Average Convergence Divergence)**\n",
    "- **Bollinger Bands**\n",
    "- **Medias móviles (SMA, EMA)**\n",
    "- **CCI, DX, y más**\n",
    "\n",
    "Además, se incluyen variables adicionales como:\n",
    "\n",
    "- **VIX**: índice de volatilidad implícita del mercado, útil para medir el \"miedo\" del mercado.\n",
    "- **Turbulence**: una medida del comportamiento anómalo del mercado basada en desviaciones multivariadas.\n",
    "\n",
    "Estos indicadores se calculan para cada acción de forma individual y se agregan como nuevas columnas al DataFrame resultante (`processed`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Reconstrucción de la estructura fecha × acción\n",
    "\n",
    "Una vez que se tienen los indicadores técnicos, se realiza un paso adicional: **reconstruir la estructura completa del conjunto de datos**, garantizando que todas las combinaciones posibles de fechas y acciones estén presentes.\n",
    "\n",
    "#### ¿Por qué se hace esto?\n",
    "\n",
    "En el mundo real, no todas las acciones tienen datos disponibles para todas las fechas (por ejemplo, por días festivos, suspensiones de cotización o errores en la descarga). Para asegurar que el conjunto de datos sea consistente y estructurado (especialmente útil para modelos temporales), se realiza lo siguiente:\n",
    "\n",
    "- Se genera una lista completa de fechas entre la mínima y máxima fecha observada.\n",
    "- Se toma la lista de acciones (tickers) presentes en el conjunto de datos.\n",
    "- Se calcula el **producto cartesiano** de fechas × acciones, creando todas las combinaciones posibles.\n",
    "- Este nuevo DataFrame se fusiona con los datos procesados originales para **rellenar los valores existentes** y dejar explícitos los faltantes.\n",
    "- Finalmente, se filtran las fechas que realmente ocurrieron en el mercado para evitar incluir días como fines de semana o festivos.\n",
    "\n",
    "Este paso garantiza que el conjunto de datos tenga una estructura rectangular y ordenada, lo cual es especialmente útil para la fase de modelado.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901cf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (291, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.290405</td>\n",
       "      <td>187.070052</td>\n",
       "      <td>182.553128</td>\n",
       "      <td>185.789422</td>\n",
       "      <td>82488700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.551913</td>\n",
       "      <td>181.649015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>184.290405</td>\n",
       "      <td>184.290405</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.910522</td>\n",
       "      <td>184.528677</td>\n",
       "      <td>182.096477</td>\n",
       "      <td>182.880742</td>\n",
       "      <td>58414500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.030959</td>\n",
       "      <td>185.551913</td>\n",
       "      <td>181.649015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>183.600464</td>\n",
       "      <td>183.600464</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>180.587555</td>\n",
       "      <td>181.758969</td>\n",
       "      <td>179.565044</td>\n",
       "      <td>180.825800</td>\n",
       "      <td>71983600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.111483</td>\n",
       "      <td>186.338830</td>\n",
       "      <td>178.853492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>182.596161</td>\n",
       "      <td>182.596161</td>\n",
       "      <td>14.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>179.862839</td>\n",
       "      <td>181.431354</td>\n",
       "      <td>178.860187</td>\n",
       "      <td>180.666963</td>\n",
       "      <td>62303300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.171540</td>\n",
       "      <td>186.012761</td>\n",
       "      <td>177.812900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-77.623425</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>181.912830</td>\n",
       "      <td>181.912830</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.210999</td>\n",
       "      <td>184.250716</td>\n",
       "      <td>180.180517</td>\n",
       "      <td>180.766224</td>\n",
       "      <td>59144500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>186.475187</td>\n",
       "      <td>178.269741</td>\n",
       "      <td>51.361197</td>\n",
       "      <td>26.023092</td>\n",
       "      <td>7.073258</td>\n",
       "      <td>182.372464</td>\n",
       "      <td>182.372464</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic       close        high         low        open  \\\n",
       "0   2024-01-02  AAPL  184.290405  187.070052  182.553128  185.789422   \n",
       "6   2024-01-03  AAPL  182.910522  184.528677  182.096477  182.880742   \n",
       "12  2024-01-04  AAPL  180.587555  181.758969  179.565044  180.825800   \n",
       "18  2024-01-05  AAPL  179.862839  181.431354  178.860187  180.666963   \n",
       "36  2024-01-08  AAPL  184.210999  184.250716  180.180517  180.766224   \n",
       "\n",
       "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0   82488700.0  1.0  0.000000  185.551913  181.649015   0.000000  -66.666667   \n",
       "6   58414500.0  2.0 -0.030959  185.551913  181.649015   0.000000  -66.666667   \n",
       "12  71983600.0  3.0 -0.111483  186.338830  178.853492   0.000000 -100.000000   \n",
       "18  62303300.0  4.0 -0.171540  186.012761  177.812900   0.000000  -77.623425   \n",
       "36  59144500.0  0.0 -0.027540  186.475187  178.269741  51.361197   26.023092   \n",
       "\n",
       "         dx_30  close_30_sma  close_60_sma    vix  turbulence  \n",
       "0   100.000000    184.290405    184.290405  13.20         0.0  \n",
       "6   100.000000    183.600464    183.600464  14.04         0.0  \n",
       "12  100.000000    182.596161    182.596161  14.13         0.0  \n",
       "18  100.000000    181.912830    181.912830  13.35         0.0  \n",
       "36    7.073258    182.372464    182.372464  13.08         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un objeto FeatureEngineer para calcular automáticamente indicadores técnicos\n",
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,        # Activamos el cálculo de indicadores técnicos clásicos (RSI, MACD, etc.)\n",
    "    tech_indicator_list=INDICATORS,      # Usamos la lista predefinida de indicadores de FinRL\n",
    "    use_vix=True,                        # Incluye el índice VIX (volatilidad implícita del mercado)\n",
    "    use_turbulence=True,                 # Incluye la medida de turbulencia financiera\n",
    "    user_defined_feature=False           # No se agregan indicadores personalizados por ahora\n",
    ")\n",
    "\n",
    "# Aplicamos el preprocesamiento sobre el DataFrame descargado ('data') para generar nuevas columnas con indicadores\n",
    "processed = fe.preprocess_data(data)\n",
    "\n",
    "# --- Reconstruimos la estructura completa fecha × acción para evitar combinaciones faltantes ---\n",
    "\n",
    "# Obtenemos la lista única de tickers (acciones)\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creamos una lista de fechas entre la mínima y máxima fecha disponibles en el dataset\n",
    "list_date = list(pd.date_range(processed['date'].min(), processed['date'].max()).astype(str))\n",
    "\n",
    "# Generamos todas las combinaciones posibles de (fecha, ticker)\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "# Creamos un nuevo DataFrame con todas las combinaciones posibles (fecha, acción)\n",
    "# Luego hacemos un left join con los datos procesados para rellenar los datos existentes\n",
    "processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"]).merge(\n",
    "    processed, on=[\"date\", \"tic\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Filtramos para conservar solo las fechas que realmente estaban en los datos originales\n",
    "# Esto evita que aparezcan fechas inexistentes (por ejemplo, fines de semana o días festivos)\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Ordenamos los datos primero por 'tic' (símbolo de la acción) y luego por 'date'\n",
    "# Esto es necesario para aplicar el rellenado hacia adelante (forward fill) correctamente dentro de cada acción\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# Rellenamos los valores faltantes con el último valor válido conocido hacia adelante (forward fill)\n",
    "# Esto es útil porque algunos indicadores técnicos no tienen valor en los primeros días y así evitamos NaNs\n",
    "processed_full = processed_full = processed_full.ffill()\n",
    "\n",
    "# Eliminamos cualquier fila que aún tenga valores faltantes después del rellenado\n",
    "# Esto suele ocurrir en los primeros días de cada acción, donde no hay valores previos para propagar\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "\n",
    "#OPCIONAL: Visualizar la data\n",
    "processed_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685eaaab",
   "metadata": {},
   "source": [
    "# **Cálculo y Etiquetado de la Volatilidad**\n",
    "\n",
    "### Parte 1: Cálculo de la Volatilidad de 5 Días\n",
    "\n",
    "La volatilidad es una medida de qué tanto varían los precios de una acción en un periodo de tiempo. En este caso, la calculamos como la **desviación estándar de los rendimientos diarios** en una ventana móvil de 5 días.\n",
    "\n",
    "#### ¿Qué se hace?\n",
    "\n",
    "- Se agrupan los datos por acción (`tic`), ya que la volatilidad debe calcularse de forma independiente para cada activo.\n",
    "- Se aplica una **ventana móvil de 5 días** sobre la columna `return`, que representa el rendimiento diario.\n",
    "- Dentro de esa ventana, se calcula la **desviación estándar**, lo cual nos da una estimación local de la volatilidad.\n",
    "- El resultado se asigna como una nueva columna llamada `volatility_5d`.\n",
    "\n",
    "#### ¿Por qué usar desviación estándar?\n",
    "\n",
    "La desviación estándar es una medida clásica de **dispersión estadística**. Cuando los rendimientos de una acción fluctúan mucho en pocos días, la desviación estándar será alta. Por eso, se utiliza como una buena aproximación de la volatilidad en análisis financiero.\n",
    "\n",
    "---\n",
    "\n",
    "### Parte 2: Etiquetado de Días con \"Alta Volatilidad\"\n",
    "\n",
    "Para usar modelos de clasificación, necesitamos transformar la volatilidad continua en una variable binaria. Lo hacemos creando una etiqueta que indique si un día tiene o no **alta volatilidad**.\n",
    "\n",
    "#### ¿Qué se hace?\n",
    "\n",
    "- Se agrupan los datos por acción (`tic`), ya que cada acción puede tener un nivel típico de volatilidad distinto.\n",
    "- Se calcula el **percentil 75** (también llamado cuartil superior) de la columna `volatility_5d` para cada acción.\n",
    "- Este valor actúa como un **umbral dinámico**: representa qué tan volátil debe ser un día para ser considerado \"alto\" en el contexto de esa acción.\n",
    "- Para cada fila, se compara la volatilidad observada con ese umbral:\n",
    "  - Si la volatilidad es mayor al percentil 75 → se etiqueta como `1` (alta volatilidad).\n",
    "  - Si es menor o igual → se etiqueta como `0` (baja o normal volatilidad).\n",
    "- El resultado se almacena en una nueva columna llamada `volatilidad_alta`.\n",
    "\n",
    "---\n",
    "\n",
    "#### ¿Qué es el percentil 75 y por qué se usa?\n",
    "\n",
    "El percentil 75 es el valor por debajo del cual se encuentra el 75% de los datos. En este caso, representa un umbral de volatilidad \"alta\" relativo al comportamiento típico de cada acción. Si la volatilidad de un día supera este valor, se considera un evento inusualmente volátil. Esta estrategia permite adaptar el criterio de alta volatilidad a cada acción, en lugar de usar un valor fijo para todas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccb3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>return</th>\n",
       "      <th>volatility_5d</th>\n",
       "      <th>volatilidad_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>183.794052</td>\n",
       "      <td>183.803974</td>\n",
       "      <td>181.401569</td>\n",
       "      <td>182.582920</td>\n",
       "      <td>42841800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041713</td>\n",
       "      <td>186.458180</td>\n",
       "      <td>...</td>\n",
       "      <td>48.871269</td>\n",
       "      <td>29.331090</td>\n",
       "      <td>7.073258</td>\n",
       "      <td>182.609395</td>\n",
       "      <td>182.609395</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.836441</td>\n",
       "      <td>185.044906</td>\n",
       "      <td>182.582939</td>\n",
       "      <td>183.009821</td>\n",
       "      <td>46792900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>186.823494</td>\n",
       "      <td>...</td>\n",
       "      <td>54.567540</td>\n",
       "      <td>76.254893</td>\n",
       "      <td>13.208758</td>\n",
       "      <td>182.927545</td>\n",
       "      <td>182.927545</td>\n",
       "      <td>12.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.240784</td>\n",
       "      <td>185.690176</td>\n",
       "      <td>182.285104</td>\n",
       "      <td>185.183874</td>\n",
       "      <td>49128400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.163129</td>\n",
       "      <td>186.816263</td>\n",
       "      <td>...</td>\n",
       "      <td>51.195830</td>\n",
       "      <td>66.900169</td>\n",
       "      <td>21.476506</td>\n",
       "      <td>183.091700</td>\n",
       "      <td>183.091700</td>\n",
       "      <td>12.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003223</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.568375</td>\n",
       "      <td>185.382421</td>\n",
       "      <td>183.843686</td>\n",
       "      <td>184.707356</td>\n",
       "      <td>40444700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>186.876198</td>\n",
       "      <td>...</td>\n",
       "      <td>52.853227</td>\n",
       "      <td>85.517246</td>\n",
       "      <td>21.476506</td>\n",
       "      <td>183.255775</td>\n",
       "      <td>183.255775</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.295029</td>\n",
       "      <td>182.920438</td>\n",
       "      <td>179.614645</td>\n",
       "      <td>180.835714</td>\n",
       "      <td>65603000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102792</td>\n",
       "      <td>186.626730</td>\n",
       "      <td>...</td>\n",
       "      <td>42.493488</td>\n",
       "      <td>-66.785421</td>\n",
       "      <td>29.102461</td>\n",
       "      <td>183.159700</td>\n",
       "      <td>183.159700</td>\n",
       "      <td>13.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012317</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.419998</td>\n",
       "      <td>78.879997</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>78.650002</td>\n",
       "      <td>24368400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.449048</td>\n",
       "      <td>86.061833</td>\n",
       "      <td>...</td>\n",
       "      <td>56.159591</td>\n",
       "      <td>65.676325</td>\n",
       "      <td>7.593468</td>\n",
       "      <td>71.628999</td>\n",
       "      <td>68.240166</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>4.777463</td>\n",
       "      <td>-0.031309</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>73.529999</td>\n",
       "      <td>76.360001</td>\n",
       "      <td>19559200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.006083</td>\n",
       "      <td>86.140179</td>\n",
       "      <td>...</td>\n",
       "      <td>54.305930</td>\n",
       "      <td>39.701343</td>\n",
       "      <td>12.923284</td>\n",
       "      <td>71.928332</td>\n",
       "      <td>68.265666</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>1.501329</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>UBER</td>\n",
       "      <td>75.870003</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>75.309998</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>10328900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.698164</td>\n",
       "      <td>86.198854</td>\n",
       "      <td>...</td>\n",
       "      <td>55.261977</td>\n",
       "      <td>47.506516</td>\n",
       "      <td>12.293895</td>\n",
       "      <td>72.267332</td>\n",
       "      <td>68.337499</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>6.419838</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.209999</td>\n",
       "      <td>77.690002</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>75.949997</td>\n",
       "      <td>22535900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.293746</td>\n",
       "      <td>85.983300</td>\n",
       "      <td>...</td>\n",
       "      <td>53.184914</td>\n",
       "      <td>35.376200</td>\n",
       "      <td>18.748735</td>\n",
       "      <td>72.579666</td>\n",
       "      <td>68.380666</td>\n",
       "      <td>21.129999</td>\n",
       "      <td>9.438051</td>\n",
       "      <td>-0.021880</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.010002</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>73.580002</td>\n",
       "      <td>74.279999</td>\n",
       "      <td>17752000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.094345</td>\n",
       "      <td>85.739607</td>\n",
       "      <td>...</td>\n",
       "      <td>55.078834</td>\n",
       "      <td>32.740104</td>\n",
       "      <td>19.264791</td>\n",
       "      <td>72.879333</td>\n",
       "      <td>68.448166</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>2.880587</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.024033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close        high         low        open  \\\n",
       "42    2024-01-09  AAPL  183.794052  183.803974  181.401569  182.582920   \n",
       "48    2024-01-10  AAPL  184.836441  185.044906  182.582939  183.009821   \n",
       "54    2024-01-11  AAPL  184.240784  185.690176  182.285104  185.183874   \n",
       "60    2024-01-12  AAPL  184.568375  185.382421  183.843686  184.707356   \n",
       "84    2024-01-16  AAPL  182.295029  182.920438  179.614645  180.835714   \n",
       "...          ...   ...         ...         ...         ...         ...   \n",
       "2519  2025-02-24  UBER   76.419998   78.879997   74.849998   78.650002   \n",
       "2525  2025-02-25  UBER   74.949997   76.370003   73.529999   76.360001   \n",
       "2531  2025-02-26  UBER   75.870003   76.489998   75.309998   75.330002   \n",
       "2537  2025-02-27  UBER   74.209999   77.690002   73.709999   75.949997   \n",
       "2543  2025-02-28  UBER   76.010002   76.110001   73.580002   74.279999   \n",
       "\n",
       "          volume  day      macd     boll_ub  ...     rsi_30     cci_30  \\\n",
       "42    42841800.0  1.0  0.041713  186.458180  ...  48.871269  29.331090   \n",
       "48    46792900.0  2.0  0.132629  186.823494  ...  54.567540  76.254893   \n",
       "54    49128400.0  3.0  0.163129  186.816263  ...  51.195830  66.900169   \n",
       "60    40444700.0  4.0  0.198020  186.876198  ...  52.853227  85.517246   \n",
       "84    65603000.0  1.0  0.102792  186.626730  ...  42.493488 -66.785421   \n",
       "...          ...  ...       ...         ...  ...        ...        ...   \n",
       "2519  24368400.0  0.0  3.449048   86.061833  ...  56.159591  65.676325   \n",
       "2525  19559200.0  1.0  3.006083   86.140179  ...  54.305930  39.701343   \n",
       "2531  10328900.0  2.0  2.698164   86.198854  ...  55.261977  47.506516   \n",
       "2537  22535900.0  3.0  2.293746   85.983300  ...  53.184914  35.376200   \n",
       "2543  17752000.0  4.0  2.094345   85.739607  ...  55.078834  32.740104   \n",
       "\n",
       "          dx_30  close_30_sma  close_60_sma        vix  turbulence    return  \\\n",
       "42     7.073258    182.609395    182.609395  12.760000    0.000000 -0.002263   \n",
       "48    13.208758    182.927545    182.927545  12.690000    0.000000  0.005672   \n",
       "54    21.476506    183.091700    183.091700  12.440000    0.000000 -0.003223   \n",
       "60    21.476506    183.255775    183.255775  12.700000    0.000000  0.001778   \n",
       "84    29.102461    183.159700    183.159700  13.840000    0.000000 -0.012317   \n",
       "...         ...           ...           ...        ...         ...       ...   \n",
       "2519   7.593468     71.628999     68.240166  18.980000    4.777463 -0.031309   \n",
       "2525  12.923284     71.928332     68.265666  19.430000    1.501329 -0.019236   \n",
       "2531  12.293895     72.267332     68.337499  19.100000    6.419838  0.012275   \n",
       "2537  18.748735     72.579666     68.380666  21.129999    9.438051 -0.021880   \n",
       "2543  19.264791     72.879333     68.448166  19.629999    2.880587  0.024256   \n",
       "\n",
       "      volatility_5d  volatilidad_alta  \n",
       "42         0.014335                 0  \n",
       "48         0.013924                 0  \n",
       "54         0.011889                 0  \n",
       "60         0.011165                 0  \n",
       "84         0.006729                 0  \n",
       "...             ...               ...  \n",
       "2519       0.023722                 1  \n",
       "2525       0.014634                 0  \n",
       "2531       0.019213                 0  \n",
       "2537       0.017570                 0  \n",
       "2543       0.024033                 1  \n",
       "\n",
       "[1716 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ordenamos por acción y fecha\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# 2. Calculamos el rendimiento diario por acción\n",
    "processed_full['return'] = processed_full.groupby('tic')['close'].pct_change()\n",
    "\n",
    "# 3. Calculamos la volatilidad como desviación estándar de 5 días sobre los rendimientos\n",
    "processed_full['volatility_5d'] = processed_full.groupby('tic')['return'].rolling(5).std().reset_index(0, drop=True)\n",
    "\n",
    "# 4. Etiquetamos los días con volatilidad alta (top 30% por acción usando percentil 70)\n",
    "def etiquetar_volatilidad(df, column='volatility_5d', percentil=0.65):\n",
    "    umbrales = df.groupby('tic')[column].transform(lambda x: x.quantile(percentil))\n",
    "    df['volatilidad_alta'] = (df[column] > umbrales).astype(int)\n",
    "    return df\n",
    "\n",
    "processed_full = etiquetar_volatilidad(processed_full, percentil=0.70)\n",
    "\n",
    "# 5. Eliminamos filas con valores faltantes\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "processed_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc8de3",
   "metadata": {},
   "source": [
    "# **Descripción de las columnas del dataset final (`data_para_modelo.csv`)**\n",
    "\n",
    "A continuación se describen brevemente las columnas del conjunto de datos que se utilizará para entrenar los modelos de clasificación:\n",
    "\n",
    "- **close**: Precio de cierre de la acción en el día correspondiente.\n",
    "- **high**: Precio más alto alcanzado por la acción durante el día.\n",
    "- **low**: Precio más bajo alcanzado por la acción durante el día.\n",
    "- **open**: Precio de apertura de la acción en ese día.\n",
    "- **volume**: Volumen de operaciones (cantidad de acciones intercambiadas en el día).\n",
    "- **day**: Día de la semana representado como número (0 = lunes, 6 = domingo).\n",
    "\n",
    "### Indicadores técnicos (features extraídas automáticamente):\n",
    "- **macd**: Media móvil de convergencia/divergencia, indicador de momentum.\n",
    "- **boll_ub** / **boll_lb**: Bandas de Bollinger superior e inferior, usadas para detectar sobrecompra o sobreventa.\n",
    "- **rsi_30**: Índice de fuerza relativa (RSI) con ventana de 30 días.\n",
    "- **cci_30**: Commodity Channel Index, mide la variación del precio respecto a su media.\n",
    "- **dx_30**: Directional Movement Index, evalúa la fuerza de una tendencia.\n",
    "- **close_30_sma** / **close_60_sma**: Medias móviles simples del precio de cierre en ventanas de 30 y 60 días.\n",
    "\n",
    "### Etiqueta (target):\n",
    "- **volatilidad_alta**: Variable binaria que indica si el día fue clasificado como de alta volatilidad (`1`) o no (`0`), calculado con base en el percentil 75 de la volatilidad histórica por acción.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5050a",
   "metadata": {},
   "source": [
    "# Modelos Clásicos de Clasificación Evaluados\n",
    "\n",
    "Para clasificar los días con alta volatilidad se probaron cinco modelos clásicos de aprendizaje supervisado, cada uno representando un enfoque distinto:\n",
    "\n",
    "- **Random Forest**: Ensamble de árboles, robusto y eficaz con datos tabulares. Resiste bien el sobreajuste.\n",
    "\n",
    "- **Regresión Logística**: Modelo lineal e interpretable, usado como *benchmark* básico.\n",
    "\n",
    "- **XGBoost**: Técnica avanzada de *boosting*, capaz de capturar relaciones no lineales y manejar desbalanceo.\n",
    "\n",
    "- **SVM**: Modelo que busca la mejor frontera entre clases; útil con *kernels* para capturar relaciones complejas.\n",
    "\n",
    "- **KNN**: Clasificador basado en distancia, simple pero útil como contraste frente a modelos más estructurados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308332f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test, mostrar_roc=True):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de clasificación.\n",
    "\n",
    "    Retorna:\n",
    "        accuracy, f1_score, auc (si aplica, si no retorna None)\n",
    "    \"\"\"\n",
    "    # Entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # F1-score para la clase 1 (alta volatilidad)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # AUC (solo si el modelo tiene predict_proba y se solicita)\n",
    "    auc = None\n",
    "    if mostrar_roc and hasattr(modelo, \"predict_proba\"):\n",
    "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    return acc, f1, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390e329",
   "metadata": {},
   "source": [
    "# Motivación de los Indicadores Utilizados para el Entrenamiento\n",
    "\n",
    "En este trabajo buscamos predecir si un día determinado tendrá alta volatilidad en el precio de una acción. Para ello, seleccionamos diferentes grupos de variables que capturan distintos aspectos del comportamiento del mercado. A continuación se justifica cada grupo evaluado:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Precios del activo (`open`, `close`, `high`, `low`)\n",
    "\n",
    "Los precios reflejan la información más inmediata del mercado:\n",
    "\n",
    "- `open` y `close` representan el precio inicial y final del día.\n",
    "- `high` y `low` indican los extremos de volatilidad intradía.\n",
    "\n",
    "Estos datos permiten detectar movimientos bruscos en precios que pueden correlacionarse con futuros periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Indicadores técnicos\n",
    "\n",
    "Los indicadores técnicos como `RSI`, `MACD`, `CCI`, `Bollinger Bands`, `DX`, etc., son comúnmente usados en el análisis técnico para detectar:\n",
    "\n",
    "- Tendencias (por ejemplo, `MACD`),\n",
    "- Niveles de sobrecompra o sobreventa (por ejemplo, `RSI`, `CCI`),\n",
    "- Cambios de dirección del mercado.\n",
    "\n",
    "Estos indicadores agregan una capa de interpretación sobre los precios, ayudando a anticipar periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Indicadores de riesgo de mercado (`VIX`, `turbulence`)\n",
    "\n",
    "- `VIX` es un índice que mide la volatilidad implícita esperada del mercado. Es un indicador reconocido de “miedo” en los inversionistas.\n",
    "- `turbulence` mide la inestabilidad o comportamiento anómalo del mercado comparado con su comportamiento histórico.\n",
    "\n",
    "Ambos son indicadores exógenos que pueden influir fuertemente en la volatilidad individual de una acción.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Evaluación de todas las combinaciones\n",
    "\n",
    "Para comprender el aporte predictivo de cada grupo de variables, se evaluaron las siguientes configuraciones:\n",
    "\n",
    "| Combinación de variables     | Descripción                                                                 |\n",
    "|------------------------------|-----------------------------------------------------------------------------|\n",
    "| Todas las variables          | Incluye precios, indicadores técnicos y de riesgo                          |\n",
    "| Solo indicadores técnicos    | MACD, RSI, CCI, Bollinger Bands, DX, medias móviles                        |\n",
    "| Solo precios                 | Precios diarios: `open`, `close`, `high`, `low`                            |\n",
    "| Solo VIX + Turbulence        | Indicadores exógenos de riesgo e inestabilidad del mercado                 |\n",
    "\n",
    "Estas combinaciones se entrenaron y evaluaron utilizando cinco modelos de clasificación distintos para obtener una comparación robusta.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Selección Evolutiva de Características\n",
    "\n",
    "Para optimizar aún más el rendimiento del modelo, se implementó una estrategia basada en un **Algoritmo Genético (GA)** con el fin de seleccionar automáticamente un subconjunto óptimo de características entre todas las disponibles.\n",
    "\n",
    "Esta estrategia permitió:\n",
    "\n",
    "- Explorar de forma inteligente el espacio de combinaciones posibles.\n",
    "- Combinar buenas soluciones parciales mediante operadores de cruce y mutación.\n",
    "- Identificar subconjuntos de variables que maximizan la precisión promedio en múltiples clasificadores (Random Forest, Regresión Logística, XGBoost, SVM y KNN).\n",
    "\n",
    "La selección evolutiva no solo ayudó a reducir la dimensionalidad del problema, sino que también mejoró el desempeño en algunos casos respecto a configuraciones manuales, y permitió establecer una base sólida para el entrenamiento de modelos más complejos como las redes neuronales recurrentes (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4909692",
   "metadata": {},
   "source": [
    "### Partición del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d4af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =========================\n",
    "# Helper para aplicar One-Hot a 'day'\n",
    "# =========================\n",
    "def aplicar_one_hot(df, incluir_day=True):\n",
    "    df = df.copy()\n",
    "    if incluir_day and 'day' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['day'], prefix='day')\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Todas las variables (con 'day' en One-Hot)\n",
    "# =========================\n",
    "columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "columnas_modelo = [col for col in processed_full.columns if col not in columnas_excluir]\n",
    "\n",
    "X_todas = processed_full[columnas_modelo].copy()\n",
    "X_todas = aplicar_one_hot(X_todas)  # One-Hot para 'day'\n",
    "y_todas = processed_full['volatilidad_alta']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_todas, y_todas, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_todas = StandardScaler()\n",
    "X_train_scaled = scaler_todas.fit_transform(X_train)\n",
    "X_test_scaled = scaler_todas.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# Indicadores Técnicos (con 'day')\n",
    "# =========================\n",
    "columnas_indicadores = [\n",
    "    \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\",\n",
    "    \"close_30_sma\", \"close_60_sma\", \"day\"  # incluimos explícitamente 'day'\n",
    "]\n",
    "df_indicadores = processed_full[columnas_indicadores + [\"volatilidad_alta\"]]\n",
    "df_indicadores = aplicar_one_hot(df_indicadores)\n",
    "\n",
    "X_indicadores = df_indicadores.drop(columns=['volatilidad_alta'])\n",
    "y_indicadores = df_indicadores['volatilidad_alta']\n",
    "\n",
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split(\n",
    "    X_indicadores, y_indicadores, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_ind = StandardScaler()\n",
    "X_train_ind_scaled = scaler_ind.fit_transform(X_train_ind)\n",
    "X_test_ind_scaled = scaler_ind.transform(X_test_ind)\n",
    "\n",
    "# =========================\n",
    "# Solo Precios (con 'day')\n",
    "# =========================\n",
    "columnas_precios = ['open', 'close', 'high', 'low', 'day']\n",
    "df_precios = processed_full[columnas_precios + ['volatilidad_alta']]\n",
    "df_precios = aplicar_one_hot(df_precios)\n",
    "\n",
    "X_precios = df_precios.drop(columns=['volatilidad_alta'])\n",
    "y_precios = df_precios['volatilidad_alta']\n",
    "\n",
    "X_train_precios, X_test_precios, y_train_precios, y_test_precios = train_test_split(\n",
    "    X_precios, y_precios, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_prec = StandardScaler()\n",
    "X_train_precios_scaled = scaler_prec.fit_transform(X_train_precios)\n",
    "X_test_precios_scaled = scaler_prec.transform(X_test_precios)\n",
    "\n",
    "# =========================\n",
    "# VIX + Turbulence (con 'day')\n",
    "# =========================\n",
    "columnas_vix_turb = ['vix', 'turbulence', 'day']\n",
    "df_vix_turbulence = processed_full[columnas_vix_turb + ['volatilidad_alta']]\n",
    "df_vix_turbulence = aplicar_one_hot(df_vix_turbulence)\n",
    "\n",
    "X_vix_turbulence = df_vix_turbulence.drop(columns=['volatilidad_alta'])\n",
    "y_vix_turbulence = df_vix_turbulence['volatilidad_alta']\n",
    "\n",
    "X_train_vix_turb, X_test_vix_turb, y_train_vix_turb, y_test_vix_turb = train_test_split(\n",
    "    X_vix_turbulence, y_vix_turbulence, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_vix_turb = StandardScaler()\n",
    "X_train_vix_turb_scaled = scaler_vix_turb.fit_transform(X_train_vix_turb)\n",
    "X_test_vix_turb_scaled = scaler_vix_turb.transform(X_test_vix_turb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af5a2c",
   "metadata": {},
   "source": [
    "### Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ab3fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión promedio (Todas las variables): 0.8436\n",
      "Precisión promedio (Indicadores técnicos): 0.7099\n",
      "Precisión promedio (Solo precios): 0.7006\n",
      "Precisión promedio (VIX + Turbulence): 0.6953\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# DEFINICIÓN DE CLASIFICADORES A EVALUAR\n",
    "# ===============================================================\n",
    "\n",
    "# Diccionario con cinco modelos clásicos de clasificación supervisada.\n",
    "# Cada entrada tiene un nombre (para identificación en resultados) y su instancia.\n",
    "clasificadores = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Regresión Logística\": LogisticRegression(max_iter=500),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),  # Se habilita probability para AUC\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# CONJUNTOS DE DATOS A PROBAR\n",
    "# ===============================================================\n",
    "\n",
    "# Lista de diccionarios, cada uno representa una combinación de variables.\n",
    "# Cada combinación contiene sus datos de entrenamiento y prueba (ya escalados).\n",
    "conjuntos = [\n",
    "    {\n",
    "        \"nombre\": \"Todas las variables\",\n",
    "        \"X_train\": X_train_scaled,\n",
    "        \"X_test\": X_test_scaled,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Indicadores técnicos\",\n",
    "        \"X_train\": X_train_ind_scaled,\n",
    "        \"X_test\": X_test_ind_scaled,\n",
    "        \"y_train\": y_train_ind,\n",
    "        \"y_test\": y_test_ind\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Solo precios\",\n",
    "        \"X_train\": X_train_precios_scaled,\n",
    "        \"X_test\": X_test_precios_scaled,\n",
    "        \"y_train\": y_train_precios,\n",
    "        \"y_test\": y_test_precios\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"VIX + Turbulence\",\n",
    "        \"X_train\": X_train_vix_turb_scaled,\n",
    "        \"X_test\": X_test_vix_turb_scaled,\n",
    "        \"y_train\": y_train_vix_turb,\n",
    "        \"y_test\": y_test_vix_turb\n",
    "    }\n",
    "]\n",
    "\n",
    "# ===============================================================\n",
    "# EVALUACIÓN DE CADA MODELO SOBRE CADA CONJUNTO DE VARIABLES\n",
    "# ===============================================================\n",
    "\n",
    "# Lista donde se almacenarán los resultados promedio por combinación\n",
    "resultados = []\n",
    "\n",
    "# Iteramos sobre cada conjunto definido (por nombre y datos)\n",
    "for conjunto in conjuntos:\n",
    "    nombre_combo = conjunto[\"nombre\"]\n",
    "    X_train = conjunto[\"X_train\"]\n",
    "    X_test = conjunto[\"X_test\"]\n",
    "    y_train = conjunto[\"y_train\"]\n",
    "    y_test = conjunto[\"y_test\"]\n",
    "\n",
    "    # Lista para almacenar accuracy de cada modelo en esta combinación\n",
    "    accuracies = []\n",
    "\n",
    "    # Evaluamos cada modelo con la función definida previamente\n",
    "    for nombre_modelo, modelo in clasificadores.items():\n",
    "        acc, _, _ = evaluar_modelo(\n",
    "            modelo,\n",
    "            f\"{nombre_modelo} ({nombre_combo})\",\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test\n",
    "        )\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    # Promediamos las precisiones de todos los modelos sobre esta combinación\n",
    "    promedio = np.mean(accuracies)\n",
    "\n",
    "    # Guardamos el resultado\n",
    "    resultados.append({\n",
    "        \"nombre\": nombre_combo,\n",
    "        \"promedio\": promedio\n",
    "    })\n",
    "\n",
    "    # Mostramos el resultado por consola\n",
    "    print(f\"Precisión promedio ({nombre_combo}): {promedio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feda46",
   "metadata": {},
   "source": [
    "# Estrategia Evolutiva\n",
    "\n",
    "\n",
    "Con el objetivo de mejorar la precisión en la clasificación de días con alta volatilidad, se implementó una estrategia basada en un Algoritmo Genético (GA) para seleccionar automáticamente el subconjunto óptimo de características entre todas las disponibles.\n",
    "\n",
    "---\n",
    "\n",
    "### Motivación\n",
    "\n",
    "El número de posibles combinaciones de columnas crece exponencialmente, y probarlas manualmente no es factible. Además, no todas las variables aportan valor predictivo; algunas pueden introducir ruido o redundancia. El algoritmo genético permite:\n",
    "\n",
    "- Explorar inteligentemente el espacio de búsqueda.\n",
    "- Combinar buenas soluciones parciales.\n",
    "- Identificar subconjuntos que maximizan la precisión promedio en múltiples modelos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia Evolutiva\n",
    "\n",
    "#### 1. Codificación de Individuos\n",
    "\n",
    "Cada individuo del algoritmo representa un subconjunto de columnas codificado como un vector binario:\n",
    "\n",
    "- `1`: la columna está incluida.\n",
    "- `0`: la columna está descartada.\n",
    "\n",
    "#### 2. Función de Aptitud (Fitness)\n",
    "\n",
    "Para cada subconjunto (individuo), se evalúa su rendimiento promedio usando cinco clasificadores:\n",
    "\n",
    "- Random Forest\n",
    "- Regresión Logística\n",
    "- XGBoost\n",
    "- SVM\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "El valor de fitness es el promedio de *accuracy* entre estos modelos, evaluados en un conjunto de prueba fijo.\n",
    "\n",
    "#### 3. Parámetros Utilizados\n",
    "\n",
    "| Parámetro             | Valor                         |\n",
    "|-----------------------|-------------------------------|\n",
    "| Tamaño de población   | 10 a 40 individuos            |\n",
    "| Número de generaciones| 5 a 30 generaciones           |\n",
    "| Tasa de mutación      | 0.1 (10%)                     |\n",
    "| Selección             | Mejores 50% por generación    |\n",
    "| Cruce (crossover)     | 1 punto                       |\n",
    "| Mutación              | Cambio de bits aleatorio      |\n",
    "\n",
    "#### 4. Resultados\n",
    "\n",
    "El algoritmo evolutivo fue capaz de:\n",
    "\n",
    "- Identificar subconjuntos pequeños con buen rendimiento.\n",
    "- Superar algunas configuraciones manuales.\n",
    "- Adaptarse al conjunto completo de columnas, descartando automáticamente aquellas menos útiles.\n",
    "\n",
    "---\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- Automatiza la búsqueda del mejor subconjunto de variables.\n",
    "- Considera múltiples modelos simultáneamente.\n",
    "- Reduce el riesgo de *overfitting* por selección manual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Definir df_model\n",
    "df_model = processed_full.drop(columns=['date', 'tic', 'return', 'volatility_5d'])\n",
    "\n",
    "# Aplicar One-Hot Encoding a 'day' si existe\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Asegurar que 'volatilidad_alta' esté al final\n",
    "cols = [c for c in df_model.columns if c != 'volatilidad_alta'] + ['volatilidad_alta']\n",
    "df_model = df_model[cols]\n",
    "\n",
    "# 2) Separar X e y\n",
    "X = df_model.drop(columns=['volatilidad_alta'])\n",
    "y = df_model['volatilidad_alta']\n",
    "\n",
    "# 3) División temporal\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# 4) Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5) Parámetros del GA\n",
    "POP_SIZE = 10\n",
    "N_GENERATIONS = 30\n",
    "MUTATION_RATE = 0.1\n",
    "N_FEATURES = X.shape[1]\n",
    "\n",
    "# 6) Creación, mutación y cruce\n",
    "def create_individual():\n",
    "    return np.random.choice([0, 1], size=N_FEATURES)\n",
    "\n",
    "def mutate(ind):\n",
    "    m = ind.copy()\n",
    "    for i in range(N_FEATURES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            m[i] = 1 - m[i]\n",
    "    return m\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    if N_FEATURES < 3:\n",
    "        return p1.copy(), p2.copy()\n",
    "    pt = np.random.randint(1, N_FEATURES-1)\n",
    "    return (\n",
    "        np.concatenate([p1[:pt], p2[pt:]]),\n",
    "        np.concatenate([p2[:pt], p1[pt:]])\n",
    "    )\n",
    "\n",
    "# 7) Función de fitness\n",
    "def fitness(ind):\n",
    "    sel = np.where(ind == 1)[0]\n",
    "    if len(sel) == 0:\n",
    "        return 0\n",
    "    Xtr, Xte = X_train_scaled[:, sel], X_test_scaled[:, sel]\n",
    "    models = [\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        LogisticRegression(max_iter=500),\n",
    "        XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        SVC(probability=True, random_state=42),\n",
    "        KNeighborsClassifier()\n",
    "    ]\n",
    "    scores = []\n",
    "    for m in models:\n",
    "        try:\n",
    "            m.fit(Xtr, y_train)\n",
    "            scores.append(m.score(Xte, y_test))\n",
    "        except:\n",
    "            scores.append(0)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# 8) Inicializar población\n",
    "pop = [create_individual() for _ in range(POP_SIZE)]\n",
    "\n",
    "# 9) Evolución\n",
    "for gen in range(N_GENERATIONS):\n",
    "    fits = [fitness(ind) for ind in pop]\n",
    "    ranked = sorted(zip(pop, fits), key=lambda x: x[1], reverse=True)\n",
    "    survivors = [ind for ind, _ in ranked[:POP_SIZE // 2]]\n",
    "    \n",
    "    # Imprimir cada 10 generaciones\n",
    "    if (gen + 1) % 10 == 0 or gen == 0 or gen == N_GENERATIONS - 1:\n",
    "        print(f\"Generación {gen+1}: Mejor accuracy = {ranked[0][1]:.4f}\")\n",
    "    \n",
    "    next_pop = survivors.copy()\n",
    "    while len(next_pop) < POP_SIZE:\n",
    "        a, b = random.sample(survivors, 2)\n",
    "        c1, c2 = crossover(a, b)\n",
    "        next_pop += [mutate(c1), mutate(c2)]\n",
    "    pop = next_pop[:POP_SIZE]\n",
    "\n",
    "\n",
    "# 10) Mejor solución final\n",
    "final_scores = [fitness(ind) for ind in pop]\n",
    "best_idx = np.argmax(final_scores)\n",
    "best_ind = pop[best_idx]\n",
    "best_acc = final_scores[best_idx]\n",
    "best_features = X.columns[best_ind == 1].tolist()\n",
    "\n",
    "print(\"\\n Mejor Accuracy Promedio GA:\", best_acc)\n",
    "print(\" Columnas Seleccionadas:\", best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255546f",
   "metadata": {},
   "source": [
    "# **RED RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c882e",
   "metadata": {},
   "source": [
    "## Construcción de Secuencias para RNN\n",
    "\n",
    "Con el objetivo de entrenar una Red Neuronal Recurrente (RNN), transformamos nuestro dataset en una estructura de secuencias temporales. Cada secuencia agrupa **5 días consecutivos** de datos de una misma acción (`tic`) y se utiliza para predecir si el **último día** de la secuencia tiene una **alta volatilidad** (`volatilidad_alta = 1`) o no.\n",
    "\n",
    "### Proceso realizado:\n",
    "\n",
    "- Se generaron las secuencias **por acción**, respetando el orden cronológico de cada una.\n",
    "- Cada secuencia contiene los valores de los indicadores técnicos y precios durante 5 días.\n",
    "- La etiqueta (`y`) asociada a cada secuencia corresponde al valor de `volatilidad_alta` del día inmediatamente **posterior** a la secuencia.\n",
    "- Se excluyeron las columnas `date`, `tic` y `volatilidad_alta` del input `X`, ya que no son características útiles como entrada directa a la red.\n",
    "\n",
    "### Resultados obtenidos:\n",
    "\n",
    "- Total de secuencias generadas: **1686**\n",
    "- Dimensiones de `X_rnn`: `(1686, 5, 18)`\n",
    "  - 1686 ejemplos\n",
    "  - 5 pasos de tiempo por secuencia\n",
    "  - 18 características por paso de tiempo\n",
    "- Dimensiones de `y_rnn`: `(1686,)`\n",
    "  - Cada etiqueta es `0` o `1`, indicando si el día siguiente a la secuencia tuvo alta volatilidad.\n",
    "\n",
    "Este formato es el ideal para alimentar una arquitectura LSTM, GRU o RNN simple en frameworks como PyTorch o TensorFlow/Keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea20004",
   "metadata": {},
   "source": [
    "## Ejemplo de cómo se construyen las secuencias para una RNN\n",
    "\n",
    "Cuando usamos una **RNN (Red Neuronal Recurrente)**, no alimentamos datos individuales, sino **secuencias de días consecutivos**. En este caso, usamos una **ventana de 5 días** (`sequence_length = 5`) y queremos predecir si el **día siguiente tendrá alta volatilidad** (`volatilidad_alta = 1`).\n",
    "\n",
    "---\n",
    "\n",
    "### Datos originales (simplificados)\n",
    "\n",
    "```text\n",
    "date        close   RSI   volumen   volatilidad_alta\n",
    "2024-01-01   100     30    1.5M           0\n",
    "2024-01-02   102     35    1.6M           0\n",
    "2024-01-03   105     40    1.4M           1\n",
    "2024-01-04   103     38    1.7M           0\n",
    "2024-01-05   106     45    1.6M           1\n",
    "2024-01-06   107     46    1.8M           0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Construcción de secuencias\n",
    "\n",
    "Con `sequence_length = 5`, generamos una **secuencia de entrada** (`X[0]`) a partir de los primeros 5 días:\n",
    "\n",
    "```python\n",
    "X[0] = [\n",
    "    [100, 30, 1.5M],\n",
    "    [102, 35, 1.6M],\n",
    "    [105, 40, 1.4M],\n",
    "    [103, 38, 1.7M],\n",
    "    [106, 45, 1.6M]\n",
    "]\n",
    "```\n",
    "\n",
    "La **etiqueta** correspondiente (`y[0]`) será el valor de `volatilidad_alta` del **día siguiente** (2024-01-06):\n",
    "\n",
    "```python\n",
    "y[0] = 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cómo se genera el resto del dataset?\n",
    "\n",
    "Este proceso se repite de manera **deslizante** a lo largo del dataset para generar muchas secuencias con sus respectivas etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "### Formato final del conjunto de datos\n",
    "\n",
    "Cada entrada tiene forma:\n",
    "\n",
    "```text\n",
    "(secuencia, características) = (5, 18)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `5` = número de días en la ventana,\n",
    "- `18` = número de características financieras por día.\n",
    "\n",
    "---\n",
    "\n",
    "Este formato es ideal para modelos de series de tiempo como **RNNs**, **LSTMs** o **GRUs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed3e5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral 0.40: F1 = 0.487\n",
      "Umbral 0.41: F1 = 0.479\n",
      "Umbral 0.42: F1 = 0.482\n",
      "Umbral 0.43: F1 = 0.482\n",
      "Umbral 0.44: F1 = 0.480\n",
      "Umbral 0.45: F1 = 0.478\n",
      "Umbral 0.46: F1 = 0.473\n",
      "Umbral 0.47: F1 = 0.477\n",
      "Umbral 0.48: F1 = 0.477\n",
      "Umbral 0.49: F1 = 0.476\n",
      "Umbral 0.50: F1 = 0.471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for thresh in np.arange(0.40, 0.51, 0.01):\n",
    "    y_pred = (y_pred_probs > thresh).astype(int).flatten()\n",
    "    f1 = f1_score(y_test_rnn, y_pred)\n",
    "    print(f\"Umbral {thresh:.2f}: F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "percentiles = [60, 65, 70, 75, 80, 85, 90]\n",
    "\n",
    "for p in percentiles:\n",
    "    labels = processed_full.groupby('tic')['volatility_5d'].transform(lambda x: (x > np.percentile(x, p)).astype(int))\n",
    "    ratio = labels.mean()\n",
    "    print(f\"Percentil {p}: proporción de alta volatilidad = {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f6d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ========================\n",
    "# 1. Preprocesamiento\n",
    "# ========================\n",
    "\n",
    "# Elimina columnas no deseadas\n",
    "df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "# Aplica One-Hot Encoding a 'day' si está presente\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Escalar todas las columnas numéricas excepto 'volatilidad_alta'\n",
    "cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "scaler_rnn = StandardScaler()\n",
    "df_model[features] = scaler_rnn.fit_transform(df_model[features])\n",
    "\n",
    "# ========================\n",
    "# 2. Construcción de Secuencias\n",
    "# ========================\n",
    "\n",
    "def construir_secuencias_por_accion(df, sequence_length=5):\n",
    "    X_seq, y_seq = [], []\n",
    "    tics = df['tic'].unique()\n",
    "    columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    feature_cols = [col for col in df.columns if col not in columnas_excluir]\n",
    "\n",
    "    for tic in tics:\n",
    "        df_tic = df[df['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, feature_cols].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X_seq.append(secuencia)\n",
    "            y_seq.append(etiqueta)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Genera las secuencias\n",
    "X_rnn, y_rnn = construir_secuencias_por_accion(df_model, sequence_length=5)\n",
    "\n",
    "# ========================\n",
    "# 3. División de datos\n",
    "# ========================\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(\n",
    "    X_rnn, y_rnn, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "184b0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo SIN pesos de clase\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6150 - loss: 0.6652 - val_accuracy: 0.6953 - val_loss: 0.6120\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7069 - loss: 0.6095 - val_accuracy: 0.6775 - val_loss: 0.6329\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7217 - loss: 0.5823 - val_accuracy: 0.6716 - val_loss: 0.6271\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6981 - loss: 0.5954 - val_accuracy: 0.6716 - val_loss: 0.6337\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7110 - loss: 0.5889 - val_accuracy: 0.6598 - val_loss: 0.6464\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "📊 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80       238\n",
      "           1       0.38      0.14      0.20       100\n",
      "\n",
      "    accuracy                           0.68       338\n",
      "   macro avg       0.55      0.52      0.50       338\n",
      "weighted avg       0.61      0.68      0.62       338\n",
      "\n",
      "F1-score (clase 1): 0.2044\n",
      "Entrenando modelo con pesos de clase: {0: 0.721627408993576, 1: 1.6280193236714975}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5071 - loss: 0.6997 - val_accuracy: 0.6036 - val_loss: 0.6728\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5530 - loss: 0.6829 - val_accuracy: 0.5947 - val_loss: 0.6995\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6188 - loss: 0.6559 - val_accuracy: 0.6154 - val_loss: 0.7017\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6281 - loss: 0.6492 - val_accuracy: 0.6124 - val_loss: 0.7106\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6564 - loss: 0.6284 - val_accuracy: 0.6243 - val_loss: 0.7162\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "📊 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.30      1.00      0.46       100\n",
      "\n",
      "    accuracy                           0.30       338\n",
      "   macro avg       0.15      0.50      0.23       338\n",
      "weighted avg       0.09      0.30      0.14       338\n",
      "\n",
      "F1-score (clase 1): 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# 1. Construcción del modelo RNN\n",
    "# ========================\n",
    "def crear_modelo(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ========================\n",
    "# 2. Entrenamiento y evaluación\n",
    "# ========================\n",
    "def entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=False, umbral=0.4):\n",
    "    model = crear_modelo((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "    if usar_pesos:\n",
    "        pesos = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(pesos))\n",
    "        print(\"Entrenando modelo con pesos de clase:\", class_weight_dict)\n",
    "    else:\n",
    "        class_weight_dict = None\n",
    "        print(\"Entrenando modelo SIN pesos de clase\")\n",
    "\n",
    "    # Entrenar\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluar\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs > umbral).astype(int).flatten()\n",
    "\n",
    "    print(\"\\n📊 Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    print(f\"F1-score (clase 1): {f1:.4f}\")\n",
    "\n",
    "    return f1, history\n",
    "\n",
    "# ========================\n",
    "# 3. Ejecutar ambas variantes\n",
    "# ========================\n",
    "f1_base, hist_base = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=False)\n",
    "f1_pesos, hist_pesos = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=True)\n",
    "\n",
    "# ========================\n",
    "# 4. Comparar F1-score\n",
    "# ========================\n",
    "plt.bar([\"Sin pesos\", \"Con pesos\"], [f1_base, f1_pesos], color=['skyblue', 'salmon'])\n",
    "plt.title(\"Comparación de F1-score (clase 1)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f01d2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Entrenando modelo sin pesos\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6264 - loss: 0.6573 - val_accuracy: 0.6963 - val_loss: 0.6309\n",
      "Epoch 2/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7080 - loss: 0.6060 - val_accuracy: 0.6656 - val_loss: 0.6310\n",
      "Epoch 3/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7228 - loss: 0.5841 - val_accuracy: 0.6595 - val_loss: 0.6411\n",
      "Epoch 4/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7186 - loss: 0.5685 - val_accuracy: 0.6503 - val_loss: 0.6376\n",
      "Epoch 5/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7304 - loss: 0.5641 - val_accuracy: 0.6534 - val_loss: 0.6692\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "=== Clasification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       226\n",
      "           1       0.44      0.07      0.12       100\n",
      "\n",
      "    accuracy                           0.69       326\n",
      "   macro avg       0.57      0.52      0.47       326\n",
      "weighted avg       0.62      0.69      0.60       326\n",
      "\n",
      "\n",
      ">> Entrenando modelo con pesos de clase\n",
      "Pesos de clase: {0: 0.727069351230425, 1: 1.6009852216748768}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4977 - loss: 0.6994 - val_accuracy: 0.4877 - val_loss: 0.7048\n",
      "Epoch 2/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6051 - loss: 0.6627 - val_accuracy: 0.5460 - val_loss: 0.7008\n",
      "Epoch 3/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6625 - loss: 0.6371 - val_accuracy: 0.5399 - val_loss: 0.7080\n",
      "Epoch 4/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6523 - loss: 0.6220 - val_accuracy: 0.5307 - val_loss: 0.7101\n",
      "Epoch 5/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7041 - loss: 0.6038 - val_accuracy: 0.5215 - val_loss: 0.7614\n",
      "Epoch 6/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6956 - loss: 0.5801 - val_accuracy: 0.5337 - val_loss: 0.7836\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "=== Clasification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.19      0.31       226\n",
      "           1       0.33      0.91      0.49       100\n",
      "\n",
      "    accuracy                           0.41       326\n",
      "   macro avg       0.58      0.55      0.40       326\n",
      "weighted avg       0.68      0.41      0.36       326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# === 1. Preprocesamiento ===\n",
    "def preparar_datos(processed_full, sequence_length=5):\n",
    "    df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "    if 'day' in df_model.columns:\n",
    "        df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "    cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "    scaler = StandardScaler()\n",
    "    df_model[features] = scaler.fit_transform(df_model[features])\n",
    "\n",
    "    X, y = [], []\n",
    "    for tic in df_model['tic'].unique():\n",
    "        df_tic = df_model[df_model['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, features].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X.append(secuencia)\n",
    "            y.append(etiqueta)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === 2. Construcción del modelo ===\n",
    "def crear_modelo(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 3. Entrenamiento y evaluación ===\n",
    "def entrenar_y_evaluar_modelo(X_train, y_train, X_test, y_test, usar_pesos=False):\n",
    "    model = crear_modelo((X_train.shape[1], X_train.shape[2]))\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)]\n",
    "    fit_kwargs = {\n",
    "        \"x\": X_train, \"y\": y_train,\n",
    "        \"epochs\": 30, \"batch_size\": 32,\n",
    "        \"validation_data\": (X_test, y_test),\n",
    "        \"callbacks\": callbacks,\n",
    "        \"verbose\": 1\n",
    "    }\n",
    "\n",
    "    if usar_pesos:\n",
    "        pesos = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        fit_kwargs[\"class_weight\"] = dict(enumerate(pesos))\n",
    "        print(\"Pesos de clase:\", dict(enumerate(pesos)))\n",
    "\n",
    "    model.fit(**fit_kwargs)\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs > 0.4).astype(int)\n",
    "    print(\"=== Clasification Report ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model\n",
    "\n",
    "# === 4. Ejecución ===\n",
    "# Asegúrate de tener cargado 'processed_full' antes de ejecutar esta sección\n",
    "sequence_length = 15\n",
    "X, y = preparar_datos(processed_full, sequence_length)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(\"\\n>> Entrenando modelo sin pesos\")\n",
    "modelo_sin_pesos = entrenar_y_evaluar_modelo(X_train, y_train, X_test, y_test, usar_pesos=False)\n",
    "\n",
    "print(\"\\n>> Entrenando modelo con pesos de clase\")\n",
    "modelo_con_pesos = entrenar_y_evaluar_modelo(X_train, y_train, X_test, y_test, usar_pesos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414cb379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis_maestria)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
