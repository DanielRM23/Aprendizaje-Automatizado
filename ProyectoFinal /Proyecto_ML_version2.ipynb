{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5149c5f5",
   "metadata": {},
   "source": [
    "# **Ajustar Anchura** \n",
    "\n",
    "Esta línea hace que se ajuste la anchura del notebook, por defecto la ajusta a un 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6957203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:92% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:92% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492f5d8",
   "metadata": {},
   "source": [
    "# **Descargar Dependencias**\n",
    "\n",
    "Estos son los elementos que se tienen que descargar para un uso adecuado de todo el notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install swig\n",
    "# !pip install wrds\n",
    "# !pip install pyportfolioopt\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
    "# !pip install yfinance\n",
    "# !pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958c73c",
   "metadata": {},
   "source": [
    "# **Se importan las librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca975cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 10:47:47.701497: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 10:47:47.729624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-30 10:47:47.763204: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-30 10:47:47.773414: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 10:47:47.798952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-30 10:47:49.811325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Fechas y descarga de datos\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.config import INDICATORS\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelado clásico\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Deep learning (Keras)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870083b",
   "metadata": {},
   "source": [
    "# **Se descargan los datos históricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4300a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1752, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Las fechas deben seguir el formato 'año/mes/día' (YYYY-MM-DD)\n",
    "# Estas fechas delimitan el periodo de tiempo del que se descargarán los datos históricos\n",
    "START_DATE = '2024-01-01'   # Fecha de inicio del análisis\n",
    "END_DATE = '2025-03-04'     # Fecha de fin del análisis\n",
    "\n",
    "# Lista de símbolos (tickers) de las acciones que se analizarán\n",
    "# Estos corresponden a empresas cotizadas en bolsa como Moderna, Nvidia, Uber, etc.\n",
    "symbols = [\n",
    "    \"MRNA\",  # Moderna Inc.\n",
    "    \"NVDA\",  # Nvidia Corp.\n",
    "    \"UBER\",  # Uber Technologies Inc.\n",
    "    \"ASML\",  # ASML Holding N.V.\n",
    "    \"AMZN\",  # Amazon.com Inc.\n",
    "    \"AAPL\"   # Apple Inc.\n",
    "]\n",
    "\n",
    "# Usamos el módulo YahooDownloader de FinRL para descargar datos históricos de acciones\n",
    "# Se especifica el rango de fechas y la lista de símbolos (acciones) definidos previamente\n",
    "data = YahooDownloader(\n",
    "    start_date = START_DATE,   # Fecha de inicio del periodo de análisis\n",
    "    end_date = END_DATE,       # Fecha de fin del periodo de análisis\n",
    "    ticker_list = symbols      # Lista de acciones a descargar (AAPL, AMZN, etc.)\n",
    ").fetch_data()                 # Ejecuta la descarga y devuelve un DataFrame con los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ef0da",
   "metadata": {},
   "source": [
    "# **Extracción de Indicadores Técnicos y Reconstrucción de la Estructura Temporal**\n",
    "\n",
    "### 1. Extracción de Indicadores Técnicos\n",
    "\n",
    "Después de descargar los datos históricos de precios para varias acciones, se aplica un proceso de **ingeniería de características** para enriquecer el conjunto de datos con variables útiles para el modelo de aprendizaje automatizado.\n",
    "\n",
    "Para esto, se utiliza el módulo `FeatureEngineer` de la biblioteca FinRL. Este módulo permite calcular automáticamente varios **indicadores técnicos**, que son ampliamente utilizados en el análisis técnico del mercado bursátil. Estos indicadores ayudan a capturar tendencias, momentum y señales de sobrecompra o sobreventa en los precios.\n",
    "\n",
    "Entre los indicadores extraídos se encuentran:\n",
    "\n",
    "- **RSI (Relative Strength Index)**\n",
    "- **MACD (Moving Average Convergence Divergence)**\n",
    "- **Bollinger Bands**\n",
    "- **Medias móviles (SMA, EMA)**\n",
    "- **CCI, DX, y más**\n",
    "\n",
    "Además, se incluyen variables adicionales como:\n",
    "\n",
    "- **VIX**: índice de volatilidad implícita del mercado, útil para medir el \"miedo\" del mercado.\n",
    "- **Turbulence**: una medida del comportamiento anómalo del mercado basada en desviaciones multivariadas.\n",
    "\n",
    "Estos indicadores se calculan para cada acción de forma individual y se agregan como nuevas columnas al DataFrame resultante (`processed`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Reconstrucción de la estructura fecha × acción\n",
    "\n",
    "Una vez que se tienen los indicadores técnicos, se realiza un paso adicional: **reconstruir la estructura completa del conjunto de datos**, garantizando que todas las combinaciones posibles de fechas y acciones estén presentes.\n",
    "\n",
    "#### ¿Por qué se hace esto?\n",
    "\n",
    "En el mundo real, no todas las acciones tienen datos disponibles para todas las fechas (por ejemplo, por días festivos, suspensiones de cotización o errores en la descarga). Para asegurar que el conjunto de datos sea consistente y estructurado (especialmente útil para modelos temporales), se realiza lo siguiente:\n",
    "\n",
    "- Se genera una lista completa de fechas entre la mínima y máxima fecha observada.\n",
    "- Se toma la lista de acciones (tickers) presentes en el conjunto de datos.\n",
    "- Se calcula el **producto cartesiano** de fechas × acciones, creando todas las combinaciones posibles.\n",
    "- Este nuevo DataFrame se fusiona con los datos procesados originales para **rellenar los valores existentes** y dejar explícitos los faltantes.\n",
    "- Finalmente, se filtran las fechas que realmente ocurrieron en el mercado para evitar incluir días como fines de semana o festivos.\n",
    "\n",
    "Este paso garantiza que el conjunto de datos tenga una estructura rectangular y ordenada, lo cual es especialmente útil para la fase de modelado.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901cf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (291, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.290436</td>\n",
       "      <td>187.070083</td>\n",
       "      <td>182.553158</td>\n",
       "      <td>185.789453</td>\n",
       "      <td>82488700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.551971</td>\n",
       "      <td>181.648987</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>184.290436</td>\n",
       "      <td>184.290436</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.910522</td>\n",
       "      <td>184.528677</td>\n",
       "      <td>182.096477</td>\n",
       "      <td>182.880742</td>\n",
       "      <td>58414500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.030960</td>\n",
       "      <td>185.551971</td>\n",
       "      <td>181.648987</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>183.600479</td>\n",
       "      <td>183.600479</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>180.587555</td>\n",
       "      <td>181.758969</td>\n",
       "      <td>179.565044</td>\n",
       "      <td>180.825800</td>\n",
       "      <td>71983600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.111484</td>\n",
       "      <td>186.338868</td>\n",
       "      <td>178.853475</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>182.596171</td>\n",
       "      <td>182.596171</td>\n",
       "      <td>14.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>179.862839</td>\n",
       "      <td>181.431354</td>\n",
       "      <td>178.860187</td>\n",
       "      <td>180.666963</td>\n",
       "      <td>62303300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.171541</td>\n",
       "      <td>186.012792</td>\n",
       "      <td>177.812884</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-77.623378</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>181.912838</td>\n",
       "      <td>181.912838</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.210999</td>\n",
       "      <td>184.250716</td>\n",
       "      <td>180.180517</td>\n",
       "      <td>180.766224</td>\n",
       "      <td>59144500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027541</td>\n",
       "      <td>186.475207</td>\n",
       "      <td>178.269733</td>\n",
       "      <td>51.36103</td>\n",
       "      <td>26.022746</td>\n",
       "      <td>7.073637</td>\n",
       "      <td>182.372470</td>\n",
       "      <td>182.372470</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic       close        high         low        open  \\\n",
       "0   2024-01-02  AAPL  184.290436  187.070083  182.553158  185.789453   \n",
       "6   2024-01-03  AAPL  182.910522  184.528677  182.096477  182.880742   \n",
       "12  2024-01-04  AAPL  180.587555  181.758969  179.565044  180.825800   \n",
       "18  2024-01-05  AAPL  179.862839  181.431354  178.860187  180.666963   \n",
       "36  2024-01-08  AAPL  184.210999  184.250716  180.180517  180.766224   \n",
       "\n",
       "        volume  day      macd     boll_ub     boll_lb    rsi_30      cci_30  \\\n",
       "0   82488700.0  1.0  0.000000  185.551971  181.648987   0.00000  -66.666667   \n",
       "6   58414500.0  2.0 -0.030960  185.551971  181.648987   0.00000  -66.666667   \n",
       "12  71983600.0  3.0 -0.111484  186.338868  178.853475   0.00000 -100.000000   \n",
       "18  62303300.0  4.0 -0.171541  186.012792  177.812884   0.00000  -77.623378   \n",
       "36  59144500.0  0.0 -0.027541  186.475207  178.269733  51.36103   26.022746   \n",
       "\n",
       "         dx_30  close_30_sma  close_60_sma    vix  turbulence  \n",
       "0   100.000000    184.290436    184.290436  13.20         0.0  \n",
       "6   100.000000    183.600479    183.600479  14.04         0.0  \n",
       "12  100.000000    182.596171    182.596171  14.13         0.0  \n",
       "18  100.000000    181.912838    181.912838  13.35         0.0  \n",
       "36    7.073637    182.372470    182.372470  13.08         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un objeto FeatureEngineer para calcular automáticamente indicadores técnicos\n",
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,        # Activamos el cálculo de indicadores técnicos clásicos (RSI, MACD, etc.)\n",
    "    tech_indicator_list=INDICATORS,      # Usamos la lista predefinida de indicadores de FinRL\n",
    "    use_vix=True,                        # Incluye el índice VIX (volatilidad implícita del mercado)\n",
    "    use_turbulence=True,                 # Incluye la medida de turbulencia financiera\n",
    "    user_defined_feature=False           # No se agregan indicadores personalizados por ahora\n",
    ")\n",
    "\n",
    "# Aplicamos el preprocesamiento sobre el DataFrame descargado ('data') para generar nuevas columnas con indicadores\n",
    "processed = fe.preprocess_data(data)\n",
    "\n",
    "# --- Reconstruimos la estructura completa fecha × acción para evitar combinaciones faltantes ---\n",
    "\n",
    "# Obtenemos la lista única de tickers (acciones)\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creamos una lista de fechas entre la mínima y máxima fecha disponibles en el dataset\n",
    "list_date = list(pd.date_range(processed['date'].min(), processed['date'].max()).astype(str))\n",
    "\n",
    "# Generamos todas las combinaciones posibles de (fecha, ticker)\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "# Creamos un nuevo DataFrame con todas las combinaciones posibles (fecha, acción)\n",
    "# Luego hacemos un left join con los datos procesados para rellenar los datos existentes\n",
    "processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"]).merge(\n",
    "    processed, on=[\"date\", \"tic\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Filtramos para conservar solo las fechas que realmente estaban en los datos originales\n",
    "# Esto evita que aparezcan fechas inexistentes (por ejemplo, fines de semana o días festivos)\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Ordenamos los datos primero por 'tic' (símbolo de la acción) y luego por 'date'\n",
    "# Esto es necesario para aplicar el rellenado hacia adelante (forward fill) correctamente dentro de cada acción\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# Rellenamos los valores faltantes con el último valor válido conocido hacia adelante (forward fill)\n",
    "# Esto es útil porque algunos indicadores técnicos no tienen valor en los primeros días y así evitamos NaNs\n",
    "processed_full = processed_full = processed_full.ffill()\n",
    "\n",
    "# Eliminamos cualquier fila que aún tenga valores faltantes después del rellenado\n",
    "# Esto suele ocurrir en los primeros días de cada acción, donde no hay valores previos para propagar\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "\n",
    "#OPCIONAL: Visualizar la data\n",
    "processed_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685eaaab",
   "metadata": {},
   "source": [
    "# **Cálculo y Etiquetado de la Volatilidad**\n",
    "\n",
    "## Parte 1: Cálculo de la Volatilidad de 5 Días\n",
    "\n",
    "La volatilidad es una medida de qué tanto varían los precios de una acción en un periodo de tiempo. En este proyecto, la estimamos como la **desviación estándar de los rendimientos diarios** utilizando una **ventana móvil de 5 días** para cada acción por separado.\n",
    "\n",
    "### ¿Qué se hace?\n",
    "\n",
    "- Se agrupan los datos por acción (`tic`), porque cada empresa tiene su propia dinámica de precios.\n",
    "- Se calcula el **rendimiento diario** como el cambio porcentual del precio de cierre.\n",
    "- Sobre esos rendimientos, se aplica una **ventana móvil de 5 días** y se calcula la **desviación estándar**.\n",
    "- Esta medida representa la **volatilidad reciente** de cada acción y se guarda en una columna nueva llamada `volatility_5d`.\n",
    "\n",
    "### ¿Por qué usamos desviación estándar?\n",
    "\n",
    "La desviación estándar cuantifica la **dispersión**: si los rendimientos varían mucho de un día a otro, su desviación estándar será alta. En finanzas, esta es una forma clásica y aceptada de medir la volatilidad, ya que refleja cuán impredecible ha sido el comportamiento de una acción en días recientes.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 2: Etiquetado de Días con \"Alta Volatilidad\"\n",
    "\n",
    "Para poder entrenar modelos de clasificación, necesitamos transformar la variable continua `volatility_5d` en una etiqueta binaria. Lo hacemos creando una nueva columna `volatilidad_alta`, que indica si un día tiene **volatilidad inusualmente alta** o no.\n",
    "\n",
    "### ¿Cómo se etiqueta?\n",
    "\n",
    "- Nuevamente se agrupan los datos por acción (`tic`), ya que lo que se considera “alto” depende del contexto de cada empresa.\n",
    "- Se calcula el **percentil 70** (también llamado percentil 0.70) de la volatilidad para cada acción.\n",
    "- Este valor actúa como un **umbral relativo**: si un día tiene una volatilidad mayor a este umbral, se considera un evento anómalo o especialmente volátil.\n",
    "- Se asigna:\n",
    "  - `1` → si la volatilidad está por arriba del percentil 70\n",
    "  - `0` → en caso contrario\n",
    "\n",
    "### ¿Por qué usar el percentil 70?\n",
    "\n",
    "El percentil 70 significa que **sólo el 30% de los días más volátiles** serán etiquetados como \"alta volatilidad\". Este valor nos da un **equilibrio natural** entre:\n",
    "- Tener suficientes ejemplos positivos para entrenar modelos robustos.\n",
    "- No etiquetar como “alto” cualquier pequeña variación común.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 3: Exploración de Percentiles\n",
    "\n",
    "Antes de fijar el percentil 70, realizamos una pequeña exploración para entender qué proporción de días serían etiquetados como clase 1 (`volatilidad_alta`) con diferentes percentiles. Esto ayuda a asegurarnos de que no estamos seleccionando ni demasiados ni muy pocos días como \"volátiles\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45a4d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentil 0.60 → Clase 1: 672 de 1686 (39.86%)\n",
      "Percentil 0.65 → Clase 1: 588 de 1686 (34.88%)\n",
      "Percentil 0.70 → Clase 1: 504 de 1686 (29.89%)\n",
      "Percentil 0.75 → Clase 1: 420 de 1686 (24.91%)\n"
     ]
    }
   ],
   "source": [
    "for p in [0.60, 0.65, 0.70, 0.75]:\n",
    "    df_temp = etiquetar_volatilidad(processed_full.copy(), percentil=p)\n",
    "    clase_1 = df_temp['volatilidad_alta'].sum()\n",
    "    total = len(df_temp)\n",
    "    proporcion = clase_1 / total\n",
    "    print(f\"Percentil {p:.2f} → Clase 1: {clase_1} de {total} ({proporcion:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ccb3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>return</th>\n",
       "      <th>volatility_5d</th>\n",
       "      <th>volatilidad_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>193.085999</td>\n",
       "      <td>194.952336</td>\n",
       "      <td>192.927158</td>\n",
       "      <td>193.999308</td>\n",
       "      <td>53631300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.492356</td>\n",
       "      <td>194.524363</td>\n",
       "      <td>...</td>\n",
       "      <td>68.745409</td>\n",
       "      <td>153.905115</td>\n",
       "      <td>46.823961</td>\n",
       "      <td>185.606407</td>\n",
       "      <td>185.606407</td>\n",
       "      <td>13.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003484</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>192.758423</td>\n",
       "      <td>194.843162</td>\n",
       "      <td>191.706131</td>\n",
       "      <td>193.800793</td>\n",
       "      <td>54822100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.612454</td>\n",
       "      <td>195.332753</td>\n",
       "      <td>...</td>\n",
       "      <td>67.708096</td>\n",
       "      <td>122.377973</td>\n",
       "      <td>37.005193</td>\n",
       "      <td>186.027114</td>\n",
       "      <td>186.027114</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>191.021118</td>\n",
       "      <td>193.344103</td>\n",
       "      <td>190.544612</td>\n",
       "      <td>192.857675</td>\n",
       "      <td>44594000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.575098</td>\n",
       "      <td>195.634261</td>\n",
       "      <td>...</td>\n",
       "      <td>62.531405</td>\n",
       "      <td>88.568990</td>\n",
       "      <td>28.281714</td>\n",
       "      <td>186.304559</td>\n",
       "      <td>186.304559</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009013</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>190.336136</td>\n",
       "      <td>190.802720</td>\n",
       "      <td>188.201772</td>\n",
       "      <td>190.614099</td>\n",
       "      <td>47145600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483290</td>\n",
       "      <td>195.770363</td>\n",
       "      <td>...</td>\n",
       "      <td>60.640368</td>\n",
       "      <td>55.741401</td>\n",
       "      <td>12.796156</td>\n",
       "      <td>186.516747</td>\n",
       "      <td>186.516747</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>186.672958</td>\n",
       "      <td>190.405633</td>\n",
       "      <td>186.107110</td>\n",
       "      <td>189.551885</td>\n",
       "      <td>55859400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.155849</td>\n",
       "      <td>195.531637</td>\n",
       "      <td>...</td>\n",
       "      <td>51.949123</td>\n",
       "      <td>22.552436</td>\n",
       "      <td>1.128810</td>\n",
       "      <td>186.524557</td>\n",
       "      <td>186.524557</td>\n",
       "      <td>13.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.419998</td>\n",
       "      <td>78.879997</td>\n",
       "      <td>74.849998</td>\n",
       "      <td>78.650002</td>\n",
       "      <td>24368400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.449048</td>\n",
       "      <td>86.061833</td>\n",
       "      <td>...</td>\n",
       "      <td>56.159591</td>\n",
       "      <td>65.676325</td>\n",
       "      <td>7.593468</td>\n",
       "      <td>71.628999</td>\n",
       "      <td>68.240166</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>4.777466</td>\n",
       "      <td>-0.031309</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>73.529999</td>\n",
       "      <td>76.360001</td>\n",
       "      <td>19559200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.006083</td>\n",
       "      <td>86.140179</td>\n",
       "      <td>...</td>\n",
       "      <td>54.305930</td>\n",
       "      <td>39.701343</td>\n",
       "      <td>12.923284</td>\n",
       "      <td>71.928332</td>\n",
       "      <td>68.265666</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>1.501326</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>UBER</td>\n",
       "      <td>75.870003</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>75.309998</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>10328900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.698164</td>\n",
       "      <td>86.198854</td>\n",
       "      <td>...</td>\n",
       "      <td>55.261977</td>\n",
       "      <td>47.506516</td>\n",
       "      <td>12.293895</td>\n",
       "      <td>72.267332</td>\n",
       "      <td>68.337499</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>6.419847</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>UBER</td>\n",
       "      <td>74.209999</td>\n",
       "      <td>77.690002</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>75.949997</td>\n",
       "      <td>22535900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.293746</td>\n",
       "      <td>85.983300</td>\n",
       "      <td>...</td>\n",
       "      <td>53.184914</td>\n",
       "      <td>35.376200</td>\n",
       "      <td>18.748735</td>\n",
       "      <td>72.579666</td>\n",
       "      <td>68.380666</td>\n",
       "      <td>21.129999</td>\n",
       "      <td>9.438050</td>\n",
       "      <td>-0.021880</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>UBER</td>\n",
       "      <td>76.010002</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>73.580002</td>\n",
       "      <td>74.279999</td>\n",
       "      <td>17752000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.094345</td>\n",
       "      <td>85.739607</td>\n",
       "      <td>...</td>\n",
       "      <td>55.078834</td>\n",
       "      <td>32.740104</td>\n",
       "      <td>19.264791</td>\n",
       "      <td>72.879333</td>\n",
       "      <td>68.448166</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>2.880588</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.024033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1656 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close        high         low        open  \\\n",
       "132   2024-01-24  AAPL  193.085999  194.952336  192.927158  193.999308   \n",
       "138   2024-01-25  AAPL  192.758423  194.843162  191.706131  193.800793   \n",
       "144   2024-01-26  AAPL  191.021118  193.344103  190.544612  192.857675   \n",
       "162   2024-01-29  AAPL  190.336136  190.802720  188.201772  190.614099   \n",
       "168   2024-01-30  AAPL  186.672958  190.405633  186.107110  189.551885   \n",
       "...          ...   ...         ...         ...         ...         ...   \n",
       "2519  2025-02-24  UBER   76.419998   78.879997   74.849998   78.650002   \n",
       "2525  2025-02-25  UBER   74.949997   76.370003   73.529999   76.360001   \n",
       "2531  2025-02-26  UBER   75.870003   76.489998   75.309998   75.330002   \n",
       "2537  2025-02-27  UBER   74.209999   77.690002   73.709999   75.949997   \n",
       "2543  2025-02-28  UBER   76.010002   76.110001   73.580002   74.279999   \n",
       "\n",
       "          volume  day      macd     boll_ub  ...     rsi_30      cci_30  \\\n",
       "132   53631300.0  2.0  1.492356  194.524363  ...  68.745409  153.905115   \n",
       "138   54822100.0  3.0  1.612454  195.332753  ...  67.708096  122.377973   \n",
       "144   44594000.0  4.0  1.575098  195.634261  ...  62.531405   88.568990   \n",
       "162   47145600.0  0.0  1.483290  195.770363  ...  60.640368   55.741401   \n",
       "168   55859400.0  1.0  1.155849  195.531637  ...  51.949123   22.552436   \n",
       "...          ...  ...       ...         ...  ...        ...         ...   \n",
       "2519  24368400.0  0.0  3.449048   86.061833  ...  56.159591   65.676325   \n",
       "2525  19559200.0  1.0  3.006083   86.140179  ...  54.305930   39.701343   \n",
       "2531  10328900.0  2.0  2.698164   86.198854  ...  55.261977   47.506516   \n",
       "2537  22535900.0  3.0  2.293746   85.983300  ...  53.184914   35.376200   \n",
       "2543  17752000.0  4.0  2.094345   85.739607  ...  55.078834   32.740104   \n",
       "\n",
       "          dx_30  close_30_sma  close_60_sma        vix  turbulence    return  \\\n",
       "132   46.823961    185.606407    185.606407  13.140000    0.000000 -0.003484   \n",
       "138   37.005193    186.027114    186.027114  13.450000    0.000000 -0.001697   \n",
       "144   28.281714    186.304559    186.304559  13.260000    0.000000 -0.009013   \n",
       "162   12.796156    186.516747    186.516747  13.600000    0.000000 -0.003586   \n",
       "168    1.128810    186.524557    186.524557  13.310000    0.000000 -0.019246   \n",
       "...         ...           ...           ...        ...         ...       ...   \n",
       "2519   7.593468     71.628999     68.240166  18.980000    4.777466 -0.031309   \n",
       "2525  12.923284     71.928332     68.265666  19.430000    1.501326 -0.019236   \n",
       "2531  12.293895     72.267332     68.337499  19.100000    6.419847  0.012275   \n",
       "2537  18.748735     72.579666     68.380666  21.129999    9.438050 -0.021880   \n",
       "2543  19.264791     72.879333     68.448166  19.629999    2.880588  0.024256   \n",
       "\n",
       "      volatility_5d  volatilidad_alta  \n",
       "132        0.013244                 0  \n",
       "138        0.008342                 0  \n",
       "144        0.008429                 0  \n",
       "162        0.005670                 0  \n",
       "168        0.007165                 0  \n",
       "...             ...               ...  \n",
       "2519       0.023722                 1  \n",
       "2525       0.014634                 0  \n",
       "2531       0.019213                 0  \n",
       "2537       0.017570                 0  \n",
       "2543       0.024033                 1  \n",
       "\n",
       "[1656 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ordenamos por acción y fecha\n",
    "processed_full = processed_full.sort_values(['tic', 'date'])\n",
    "\n",
    "# 2. Calculamos el rendimiento diario por acción\n",
    "processed_full['return'] = processed_full.groupby('tic')['close'].pct_change()\n",
    "\n",
    "# 3. Calculamos la volatilidad como desviación estándar de 5 días sobre los rendimientos\n",
    "processed_full['volatility_5d'] = processed_full.groupby('tic')['return'].rolling(5).std().reset_index(0, drop=True)\n",
    "\n",
    "# 4. Etiquetamos los días con volatilidad alta (top 30% por acción usando percentil 70)\n",
    "def etiquetar_volatilidad(df, column='volatility_5d', percentil=0.70):\n",
    "    umbrales = df.groupby('tic')[column].transform(lambda x: x.quantile(percentil))\n",
    "    df['volatilidad_alta'] = (df[column] > umbrales).astype(int)\n",
    "    return df\n",
    "\n",
    "processed_full = etiquetar_volatilidad(processed_full, percentil=0.70)\n",
    "\n",
    "# 5. Eliminamos filas con valores faltantes\n",
    "processed_full = processed_full.dropna()\n",
    "\n",
    "processed_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc8de3",
   "metadata": {},
   "source": [
    "# **Descripción de las columnas del dataset final (`data_para_modelo.csv`)**\n",
    "\n",
    "A continuación se describen brevemente las columnas del conjunto de datos que se utilizará para entrenar los modelos de clasificación:\n",
    "\n",
    "- **close**: Precio de cierre de la acción en el día correspondiente.\n",
    "- **high**: Precio más alto alcanzado por la acción durante el día.\n",
    "- **low**: Precio más bajo alcanzado por la acción durante el día.\n",
    "- **open**: Precio de apertura de la acción en ese día.\n",
    "- **volume**: Volumen de operaciones (cantidad de acciones intercambiadas en el día).\n",
    "- **day**: Día de la semana representado como número (0 = lunes, 6 = domingo).\n",
    "\n",
    "### Indicadores técnicos (features extraídas automáticamente):\n",
    "- **macd**: Media móvil de convergencia/divergencia, indicador de momentum.\n",
    "- **boll_ub** / **boll_lb**: Bandas de Bollinger superior e inferior, usadas para detectar sobrecompra o sobreventa.\n",
    "- **rsi_30**: Índice de fuerza relativa (RSI) con ventana de 30 días.\n",
    "- **cci_30**: Commodity Channel Index, mide la variación del precio respecto a su media.\n",
    "- **dx_30**: Directional Movement Index, evalúa la fuerza de una tendencia.\n",
    "- **close_30_sma** / **close_60_sma**: Medias móviles simples del precio de cierre en ventanas de 30 y 60 días.\n",
    "\n",
    "### Etiqueta (target):\n",
    "- **volatilidad_alta**: Variable binaria que indica si el día fue clasificado como de alta volatilidad (`1`) o no (`0`), calculado con base en el percentil 75 de la volatilidad histórica por acción.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5050a",
   "metadata": {},
   "source": [
    "# Modelos Clásicos de Clasificación Evaluados\n",
    "\n",
    "Para clasificar los días con alta volatilidad se probaron cinco modelos clásicos de aprendizaje supervisado, cada uno representando un enfoque distinto:\n",
    "\n",
    "- **Random Forest**: Ensamble de árboles, robusto y eficaz con datos tabulares. Resiste bien el sobreajuste.\n",
    "\n",
    "- **Regresión Logística**: Modelo lineal e interpretable, usado como *benchmark* básico.\n",
    "\n",
    "- **XGBoost**: Técnica avanzada de *boosting*, capaz de capturar relaciones no lineales y manejar desbalanceo.\n",
    "\n",
    "- **SVM**: Modelo que busca la mejor frontera entre clases; útil con *kernels* para capturar relaciones complejas.\n",
    "\n",
    "- **KNN**: Clasificador basado en distancia, simple pero útil como contraste frente a modelos más estructurados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "308332f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test, mostrar_roc=True):\n",
    "#     \"\"\"\n",
    "#     Entrena y evalúa un modelo de clasificación.\n",
    "\n",
    "#     Retorna:\n",
    "#         accuracy, f1_score, auc (si aplica, si no retorna None)\n",
    "#     \"\"\"\n",
    "#     # Entrenamiento\n",
    "#     modelo.fit(X_train, y_train)\n",
    "#     y_pred = modelo.predict(X_test)\n",
    "\n",
    "#     # Accuracy\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#     # F1-score para la clase 1 (alta volatilidad)\n",
    "#     f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "#     # AUC (solo si el modelo tiene predict_proba y se solicita)\n",
    "#     auc = None\n",
    "#     if mostrar_roc and hasattr(modelo, \"predict_proba\"):\n",
    "#         y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "#         auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "#     return acc, f1, auc\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test, mostrar_roc=True):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de clasificación en función del F1-score\n",
    "    para la clase positiva (alta volatilidad).\n",
    "\n",
    "    Retorna:\n",
    "        f1_score, auc (si aplica, si no retorna None)\n",
    "    \"\"\"\n",
    "    # Entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # F1-score para la clase 1 (alta volatilidad)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # AUC-ROC (si el modelo lo permite)\n",
    "    auc = None\n",
    "    if mostrar_roc and hasattr(modelo, \"predict_proba\"):\n",
    "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    return f1, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab296b94",
   "metadata": {},
   "source": [
    "# Motivación de los Indicadores Utilizados para el Entrenamiento\n",
    "\n",
    "En este trabajo buscamos predecir si un día determinado tendrá alta volatilidad en el precio de una acción. Para ello, seleccionamos diferentes grupos de variables que capturan distintos aspectos del comportamiento del mercado. A continuación se justifica cada grupo evaluado:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Precios del activo (`open`, `close`, `high`, `low`)\n",
    "\n",
    "Los precios reflejan la información más inmediata del mercado:\n",
    "\n",
    "- `open` y `close` representan el precio inicial y final del día.\n",
    "- `high` y `low` indican los extremos de volatilidad intradía.\n",
    "\n",
    "Estos datos permiten detectar movimientos bruscos en precios que pueden correlacionarse con futuros periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Indicadores técnicos\n",
    "\n",
    "Los indicadores técnicos como `RSI`, `MACD`, `CCI`, `Bollinger Bands`, `DX`, etc., son comúnmente usados en el análisis técnico para detectar:\n",
    "\n",
    "- Tendencias (por ejemplo, `MACD`),\n",
    "- Niveles de sobrecompra o sobreventa (por ejemplo, `RSI`, `CCI`),\n",
    "- Cambios de dirección del mercado.\n",
    "\n",
    "Estos indicadores agregan una capa de interpretación sobre los precios, ayudando a anticipar periodos de alta volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Indicadores de riesgo de mercado (`VIX`, `turbulence`)\n",
    "\n",
    "- `VIX` es un índice que mide la volatilidad implícita esperada del mercado. Es un indicador reconocido de “miedo” en los inversionistas.\n",
    "- `turbulence` mide la inestabilidad o comportamiento anómalo del mercado comparado con su comportamiento histórico.\n",
    "\n",
    "Ambos son indicadores exógenos que pueden influir fuertemente en la volatilidad individual de una acción.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Evaluación de todas las combinaciones\n",
    "\n",
    "Para comprender el aporte predictivo de cada grupo de variables, se evaluaron las siguientes configuraciones:\n",
    "\n",
    "| Combinación de variables     | Descripción                                                                 |\n",
    "|------------------------------|-----------------------------------------------------------------------------|\n",
    "| Todas las variables          | Incluye precios, indicadores técnicos y de riesgo                          |\n",
    "| Solo indicadores técnicos    | MACD, RSI, CCI, Bollinger Bands, DX, medias móviles                        |\n",
    "| Solo precios                 | Precios diarios: `open`, `close`, `high`, `low`                            |\n",
    "| Solo VIX + Turbulence        | Indicadores exógenos de riesgo e inestabilidad del mercado                 |\n",
    "\n",
    "Estas combinaciones se entrenaron y evaluaron utilizando cinco modelos de clasificación distintos para obtener una comparación robusta.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Selección Evolutiva de Características\n",
    "\n",
    "Para optimizar aún más el rendimiento del modelo, se implementó una estrategia basada en un **Algoritmo Genético (GA)** con el fin de seleccionar automáticamente un subconjunto óptimo de características entre todas las disponibles.\n",
    "\n",
    "Esta estrategia permitió:\n",
    "\n",
    "- Explorar de forma inteligente el espacio de combinaciones posibles.\n",
    "- Combinar buenas soluciones parciales mediante operadores de cruce y mutación.\n",
    "- Identificar subconjuntos de variables que maximizan la precisión promedio en múltiples clasificadores (Random Forest, Regresión Logística, XGBoost, SVM y KNN).\n",
    "\n",
    "La selección evolutiva no solo ayudó a reducir la dimensionalidad del problema, sino que también mejoró el desempeño en algunos casos respecto a configuraciones manuales, y permitió establecer una base sólida para el entrenamiento de modelos más complejos como las redes neuronales recurrentes (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91b1b2",
   "metadata": {},
   "source": [
    "### Partición del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0067d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper para aplicar One-Hot a 'day'\n",
    "# =========================\n",
    "def aplicar_one_hot(df, incluir_day=True):\n",
    "    df = df.copy()\n",
    "    if incluir_day and 'day' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['day'], prefix='day')\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Todas las variables (con 'day' en One-Hot)\n",
    "# =========================\n",
    "columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "columnas_modelo = [col for col in processed_full.columns if col not in columnas_excluir]\n",
    "\n",
    "X_todas = processed_full[columnas_modelo].copy()\n",
    "X_todas = aplicar_one_hot(X_todas)  # One-Hot para 'day'\n",
    "y_todas = processed_full['volatilidad_alta']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_todas, y_todas, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_todas = StandardScaler()\n",
    "X_train_scaled = scaler_todas.fit_transform(X_train)\n",
    "X_test_scaled = scaler_todas.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# Indicadores Técnicos (con 'day')\n",
    "# =========================\n",
    "columnas_indicadores = [\n",
    "    \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\",\n",
    "    \"close_30_sma\", \"close_60_sma\", \"day\"  # incluimos explícitamente 'day'\n",
    "]\n",
    "df_indicadores = processed_full[columnas_indicadores + [\"volatilidad_alta\"]]\n",
    "df_indicadores = aplicar_one_hot(df_indicadores)\n",
    "\n",
    "X_indicadores = df_indicadores.drop(columns=['volatilidad_alta'])\n",
    "y_indicadores = df_indicadores['volatilidad_alta']\n",
    "\n",
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split(\n",
    "    X_indicadores, y_indicadores, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_ind = StandardScaler()\n",
    "X_train_ind_scaled = scaler_ind.fit_transform(X_train_ind)\n",
    "X_test_ind_scaled = scaler_ind.transform(X_test_ind)\n",
    "\n",
    "# =========================\n",
    "# Solo Precios (con 'day')\n",
    "# =========================\n",
    "columnas_precios = ['open', 'close', 'high', 'low', 'day']\n",
    "df_precios = processed_full[columnas_precios + ['volatilidad_alta']]\n",
    "df_precios = aplicar_one_hot(df_precios)\n",
    "\n",
    "X_precios = df_precios.drop(columns=['volatilidad_alta'])\n",
    "y_precios = df_precios['volatilidad_alta']\n",
    "\n",
    "X_train_precios, X_test_precios, y_train_precios, y_test_precios = train_test_split(\n",
    "    X_precios, y_precios, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_prec = StandardScaler()\n",
    "X_train_precios_scaled = scaler_prec.fit_transform(X_train_precios)\n",
    "X_test_precios_scaled = scaler_prec.transform(X_test_precios)\n",
    "\n",
    "# =========================\n",
    "# VIX + Turbulence (con 'day')\n",
    "# =========================\n",
    "columnas_vix_turb = ['vix', 'turbulence', 'day']\n",
    "df_vix_turbulence = processed_full[columnas_vix_turb + ['volatilidad_alta']]\n",
    "df_vix_turbulence = aplicar_one_hot(df_vix_turbulence)\n",
    "\n",
    "X_vix_turbulence = df_vix_turbulence.drop(columns=['volatilidad_alta'])\n",
    "y_vix_turbulence = df_vix_turbulence['volatilidad_alta']\n",
    "\n",
    "X_train_vix_turb, X_test_vix_turb, y_train_vix_turb, y_test_vix_turb = train_test_split(\n",
    "    X_vix_turbulence, y_vix_turbulence, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler_vix_turb = StandardScaler()\n",
    "X_train_vix_turb_scaled = scaler_vix_turb.fit_transform(X_train_vix_turb)\n",
    "X_test_vix_turb_scaled = scaler_vix_turb.transform(X_test_vix_turb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca8ea6",
   "metadata": {},
   "source": [
    "### Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2949755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score promedio (Todas las variables): 0.6505\n",
      "F1-score promedio (Indicadores técnicos): 0.2671\n",
      "F1-score promedio (Solo precios): 0.0706\n",
      "F1-score promedio (VIX + Turbulence): 0.2480\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# DEFINICIÓN DE CLASIFICADORES A EVALUAR\n",
    "# ===============================================================\n",
    "\n",
    "# Diccionario con cinco modelos clásicos de clasificación supervisada.\n",
    "# Cada entrada tiene un nombre (para identificación en resultados) y su instancia.\n",
    "clasificadores = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Regresión Logística\": LogisticRegression(max_iter=500),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),  # Se habilita probability para AUC\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# CONJUNTOS DE DATOS A PROBAR\n",
    "# ===============================================================\n",
    "\n",
    "# Lista de diccionarios, cada uno representa una combinación de variables.\n",
    "# Cada combinación contiene sus datos de entrenamiento y prueba (ya escalados).\n",
    "conjuntos = [\n",
    "    {\n",
    "        \"nombre\": \"Todas las variables\",\n",
    "        \"X_train\": X_train_scaled,\n",
    "        \"X_test\": X_test_scaled,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Indicadores técnicos\",\n",
    "        \"X_train\": X_train_ind_scaled,\n",
    "        \"X_test\": X_test_ind_scaled,\n",
    "        \"y_train\": y_train_ind,\n",
    "        \"y_test\": y_test_ind\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Solo precios\",\n",
    "        \"X_train\": X_train_precios_scaled,\n",
    "        \"X_test\": X_test_precios_scaled,\n",
    "        \"y_train\": y_train_precios,\n",
    "        \"y_test\": y_test_precios\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"VIX + Turbulence\",\n",
    "        \"X_train\": X_train_vix_turb_scaled,\n",
    "        \"X_test\": X_test_vix_turb_scaled,\n",
    "        \"y_train\": y_train_vix_turb,\n",
    "        \"y_test\": y_test_vix_turb\n",
    "    }\n",
    "]\n",
    "\n",
    "# ===============================================================\n",
    "# EVALUACIÓN DE CADA MODELO SOBRE CADA CONJUNTO DE VARIABLES\n",
    "# ===============================================================\n",
    "\n",
    "# Lista donde se almacenarán los resultados promedio por combinación\n",
    "resultados = []\n",
    "\n",
    "# Iteramos sobre cada conjunto definido (por nombre y datos)\n",
    "for conjunto in conjuntos:\n",
    "    nombre_combo = conjunto[\"nombre\"]\n",
    "    X_train = conjunto[\"X_train\"]\n",
    "    X_test = conjunto[\"X_test\"]\n",
    "    y_train = conjunto[\"y_train\"]\n",
    "    y_test = conjunto[\"y_test\"]\n",
    "\n",
    "    # Lista para almacenar F1-score de cada modelo en esta combinación\n",
    "    f1_scores = []\n",
    "\n",
    "    # Evaluamos cada modelo con la función definida previamente\n",
    "    for nombre_modelo, modelo in clasificadores.items():\n",
    "        f1, _ = evaluar_modelo(\n",
    "            modelo,\n",
    "            f\"{nombre_modelo} ({nombre_combo})\",\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test\n",
    "        )\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Promediamos los F1-scores de todos los modelos sobre esta combinación\n",
    "    promedio = np.mean(f1_scores)\n",
    "\n",
    "    # Guardamos el resultado\n",
    "    resultados.append({\n",
    "        \"nombre\": nombre_combo,\n",
    "        \"promedio_f1\": promedio\n",
    "    })\n",
    "\n",
    "    # Mostramos el resultado por consola\n",
    "    print(f\"F1-score promedio ({nombre_combo}): {promedio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921b122",
   "metadata": {},
   "source": [
    "# Estrategia Evolutiva\n",
    "\n",
    "\n",
    "Con el objetivo de mejorar la precisión en la clasificación de días con alta volatilidad, se implementó una estrategia basada en un Algoritmo Genético (GA) para seleccionar automáticamente el subconjunto óptimo de características entre todas las disponibles.\n",
    "\n",
    "---\n",
    "\n",
    "### Motivación\n",
    "\n",
    "El número de posibles combinaciones de columnas crece exponencialmente, y probarlas manualmente no es factible. Además, no todas las variables aportan valor predictivo; algunas pueden introducir ruido o redundancia. El algoritmo genético permite:\n",
    "\n",
    "- Explorar inteligentemente el espacio de búsqueda.\n",
    "- Combinar buenas soluciones parciales.\n",
    "- Identificar subconjuntos que maximizan la precisión promedio en múltiples modelos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia Evolutiva\n",
    "\n",
    "#### 1. Codificación de Individuos\n",
    "\n",
    "Cada individuo del algoritmo representa un subconjunto de columnas codificado como un vector binario:\n",
    "\n",
    "- `1`: la columna está incluida.\n",
    "- `0`: la columna está descartada.\n",
    "\n",
    "#### 2. Función de Aptitud (Fitness)\n",
    "\n",
    "Para cada subconjunto (individuo), se evalúa su rendimiento promedio usando cinco clasificadores:\n",
    "\n",
    "- Random Forest\n",
    "- Regresión Logística\n",
    "- XGBoost\n",
    "- SVM\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "El valor de fitness es el promedio de *accuracy* entre estos modelos, evaluados en un conjunto de prueba fijo.\n",
    "\n",
    "#### 3. Parámetros Utilizados\n",
    "\n",
    "| Parámetro             | Valor                         |\n",
    "|-----------------------|-------------------------------|\n",
    "| Tamaño de población   | 10 a 40 individuos            |\n",
    "| Número de generaciones| 5 a 30 generaciones           |\n",
    "| Tasa de mutación      | 0.1 (10%)                     |\n",
    "| Selección             | Mejores 50% por generación    |\n",
    "| Cruce (crossover)     | 1 punto                       |\n",
    "| Mutación              | Cambio de bits aleatorio      |\n",
    "\n",
    "#### 4. Resultados\n",
    "\n",
    "El algoritmo evolutivo fue capaz de:\n",
    "\n",
    "- Identificar subconjuntos pequeños con buen rendimiento.\n",
    "- Superar algunas configuraciones manuales.\n",
    "- Adaptarse al conjunto completo de columnas, descartando automáticamente aquellas menos útiles.\n",
    "\n",
    "---\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- Automatiza la búsqueda del mejor subconjunto de variables.\n",
    "- Considera múltiples modelos simultáneamente.\n",
    "- Reduce el riesgo de *overfitting* por selección manual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be47ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 1: Mejor accuracy = 0.3651\n",
      "Generación 10: Mejor accuracy = 0.4059\n",
      "Generación 20: Mejor accuracy = 0.4162\n",
      "Generación 30: Mejor accuracy = 0.4165\n",
      "Generación 40: Mejor accuracy = 0.4165\n",
      "Generación 50: Mejor accuracy = 0.4165\n",
      "\n",
      " Mejor Accuracy Promedio GA: 0.4164697051572198\n",
      " Columnas Seleccionadas: ['close', 'high', 'macd', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'turbulence', 'day_3.0']\n"
     ]
    }
   ],
   "source": [
    "# 1) Definir df_model\n",
    "df_model = processed_full.drop(columns=['date', 'tic', 'return', 'volatility_5d'])\n",
    "\n",
    "# Aplicar One-Hot Encoding a 'day' si existe\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Asegurar que 'volatilidad_alta' esté al final\n",
    "cols = [c for c in df_model.columns if c != 'volatilidad_alta'] + ['volatilidad_alta']\n",
    "df_model = df_model[cols]\n",
    "\n",
    "# 2) Separar X e y\n",
    "X = df_model.drop(columns=['volatilidad_alta'])\n",
    "y = df_model['volatilidad_alta']\n",
    "\n",
    "# 3) División temporal\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# 4) Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5) Parámetros del GA\n",
    "POP_SIZE = 10\n",
    "N_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "N_FEATURES = X.shape[1]\n",
    "\n",
    "# 6) Creación, mutación y cruce\n",
    "def create_individual():\n",
    "    return np.random.choice([0, 1], size=N_FEATURES)\n",
    "\n",
    "def mutate(ind):\n",
    "    m = ind.copy()\n",
    "    for i in range(N_FEATURES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            m[i] = 1 - m[i]\n",
    "    return m\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    if N_FEATURES < 3:\n",
    "        return p1.copy(), p2.copy()\n",
    "    pt = np.random.randint(1, N_FEATURES-1)\n",
    "    return (\n",
    "        np.concatenate([p1[:pt], p2[pt:]]),\n",
    "        np.concatenate([p2[:pt], p1[pt:]])\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def fitness(ind):\n",
    "    sel = np.where(ind == 1)[0]\n",
    "    \n",
    "    # Evitar soluciones sin variables seleccionadas o con muy pocas\n",
    "    if len(sel) < 3:\n",
    "        return 0\n",
    "    \n",
    "    Xtr, Xte = X_train_scaled[:, sel], X_test_scaled[:, sel]\n",
    "    scores = []\n",
    "    \n",
    "    models = [\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        LogisticRegression(max_iter=500),\n",
    "        XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        SVC(probability=True, random_state=42),\n",
    "        KNeighborsClassifier()\n",
    "    ]\n",
    "    \n",
    "    for m in models:\n",
    "        try:\n",
    "            m.fit(Xtr, y_train)\n",
    "            y_pred = m.predict(Xte)\n",
    "            score = f1_score(y_test, y_pred, pos_label=1)\n",
    "            scores.append(score)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# 8) Inicializar población\n",
    "pop = [create_individual() for _ in range(POP_SIZE)]\n",
    "\n",
    "# 9) Evolución\n",
    "for gen in range(N_GENERATIONS):\n",
    "    fits = [fitness(ind) for ind in pop]\n",
    "    ranked = sorted(zip(pop, fits), key=lambda x: x[1], reverse=True)\n",
    "    survivors = [ind for ind, _ in ranked[:POP_SIZE // 2]]\n",
    "    \n",
    "    # Imprimir cada 10 generaciones\n",
    "    if (gen + 1) % 10 == 0 or gen == 0 or gen == N_GENERATIONS - 1:\n",
    "        print(f\"Generación {gen+1}: Mejor accuracy = {ranked[0][1]:.4f}\")\n",
    "    \n",
    "    next_pop = survivors.copy()\n",
    "    while len(next_pop) < POP_SIZE:\n",
    "        a, b = random.sample(survivors, 2)\n",
    "        c1, c2 = crossover(a, b)\n",
    "        next_pop += [mutate(c1), mutate(c2)]\n",
    "    pop = next_pop[:POP_SIZE]\n",
    "\n",
    "\n",
    "# 10) Mejor solución final\n",
    "final_scores = [fitness(ind) for ind in pop]\n",
    "best_idx = np.argmax(final_scores)\n",
    "best_ind = pop[best_idx]\n",
    "best_acc = final_scores[best_idx]\n",
    "best_features = X.columns[best_ind == 1].tolist()\n",
    "\n",
    "print(\"\\n Mejor Accuracy Promedio GA:\", best_acc)\n",
    "print(\" Columnas Seleccionadas:\", best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7786f",
   "metadata": {},
   "source": [
    "# **RED RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b7eca",
   "metadata": {},
   "source": [
    "## Construcción de Secuencias para RNN\n",
    "\n",
    "Con el objetivo de entrenar una Red Neuronal Recurrente (RNN), transformamos nuestro dataset en una estructura de secuencias temporales. Cada secuencia agrupa **5 días consecutivos** de datos de una misma acción (`tic`) y se utiliza para predecir si el **último día** de la secuencia tiene una **alta volatilidad** (`volatilidad_alta = 1`) o no.\n",
    "\n",
    "### Proceso realizado:\n",
    "\n",
    "- Se generaron las secuencias **por acción**, respetando el orden cronológico de cada una.\n",
    "- Cada secuencia contiene los valores de los indicadores técnicos y precios durante 5 días.\n",
    "- La etiqueta (`y`) asociada a cada secuencia corresponde al valor de `volatilidad_alta` del día inmediatamente **posterior** a la secuencia.\n",
    "- Se excluyeron las columnas `date`, `tic` y `volatilidad_alta` del input `X`, ya que no son características útiles como entrada directa a la red.\n",
    "\n",
    "### Resultados obtenidos:\n",
    "\n",
    "- Total de secuencias generadas: **1686**\n",
    "- Dimensiones de `X_rnn`: `(1686, 5, 18)`\n",
    "  - 1686 ejemplos\n",
    "  - 5 pasos de tiempo por secuencia\n",
    "  - 18 características por paso de tiempo\n",
    "- Dimensiones de `y_rnn`: `(1686,)`\n",
    "  - Cada etiqueta es `0` o `1`, indicando si el día siguiente a la secuencia tuvo alta volatilidad.\n",
    "\n",
    "Este formato es el ideal para alimentar una arquitectura LSTM, GRU o RNN simple en frameworks como PyTorch o TensorFlow/Keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3dfb7",
   "metadata": {},
   "source": [
    "## Ejemplo de cómo se construyen las secuencias para una RNN\n",
    "\n",
    "Cuando usamos una **RNN (Red Neuronal Recurrente)**, no alimentamos datos individuales, sino **secuencias de días consecutivos**. En este caso, usamos una **ventana de 5 días** (`sequence_length = 5`) y queremos predecir si el **día siguiente tendrá alta volatilidad** (`volatilidad_alta = 1`).\n",
    "\n",
    "---\n",
    "\n",
    "### Datos originales (simplificados)\n",
    "\n",
    "```text\n",
    "date        close   RSI   volumen   volatilidad_alta\n",
    "2024-01-01   100     30    1.5M           0\n",
    "2024-01-02   102     35    1.6M           0\n",
    "2024-01-03   105     40    1.4M           1\n",
    "2024-01-04   103     38    1.7M           0\n",
    "2024-01-05   106     45    1.6M           1\n",
    "2024-01-06   107     46    1.8M           0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Construcción de secuencias\n",
    "\n",
    "Con `sequence_length = 5`, generamos una **secuencia de entrada** (`X[0]`) a partir de los primeros 5 días:\n",
    "\n",
    "```python\n",
    "X[0] = [\n",
    "    [100, 30, 1.5M],\n",
    "    [102, 35, 1.6M],\n",
    "    [105, 40, 1.4M],\n",
    "    [103, 38, 1.7M],\n",
    "    [106, 45, 1.6M]\n",
    "]\n",
    "```\n",
    "\n",
    "La **etiqueta** correspondiente (`y[0]`) será el valor de `volatilidad_alta` del **día siguiente** (2024-01-06):\n",
    "\n",
    "```python\n",
    "y[0] = 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cómo se genera el resto del dataset?\n",
    "\n",
    "Este proceso se repite de manera **deslizante** a lo largo del dataset para generar muchas secuencias con sus respectivas etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "### Formato final del conjunto de datos\n",
    "\n",
    "Cada entrada tiene forma:\n",
    "\n",
    "```text\n",
    "(secuencia, características) = (5, 18)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `5` = número de días en la ventana,\n",
    "- `18` = número de características financieras por día.\n",
    "\n",
    "---\n",
    "\n",
    "Este formato es ideal para modelos de series de tiempo como **RNNs**, **LSTMs** o **GRUs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93986d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Preprocesamiento\n",
    "# ========================\n",
    "\n",
    "# Elimina columnas no deseadas\n",
    "df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "# Aplica One-Hot Encoding a 'day' si está presente\n",
    "if 'day' in df_model.columns:\n",
    "    df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "# Escalar todas las columnas numéricas excepto 'volatilidad_alta'\n",
    "cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "scaler_rnn = StandardScaler()\n",
    "df_model[features] = scaler_rnn.fit_transform(df_model[features])\n",
    "\n",
    "# ========================\n",
    "# 2. Construcción de Secuencias\n",
    "# ========================\n",
    "\n",
    "def construir_secuencias_por_accion(df, sequence_length=5):\n",
    "    X_seq, y_seq = [], []\n",
    "    tics = df['tic'].unique()\n",
    "    columnas_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    feature_cols = [col for col in df.columns if col not in columnas_excluir]\n",
    "\n",
    "    for tic in tics:\n",
    "        df_tic = df[df['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, feature_cols].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X_seq.append(secuencia)\n",
    "            y_seq.append(etiqueta)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Genera las secuencias\n",
    "X_rnn, y_rnn = construir_secuencias_por_accion(df_model, sequence_length=5)\n",
    "\n",
    "# ========================\n",
    "# 3. División de datos\n",
    "# ========================\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(\n",
    "    X_rnn, y_rnn, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78298a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Preprocesamiento ===\n",
    "def preparar_datos(processed_full, sequence_length=15):\n",
    "    df_model = processed_full.drop(columns=['return', 'volatility_5d'])\n",
    "\n",
    "    if 'day' in df_model.columns:\n",
    "        df_model = pd.get_dummies(df_model, columns=['day'], prefix='day')\n",
    "\n",
    "    cols_excluir = ['date', 'tic', 'volatilidad_alta']\n",
    "    features = [col for col in df_model.columns if col not in cols_excluir]\n",
    "    scaler = StandardScaler()\n",
    "    df_model[features] = scaler.fit_transform(df_model[features])\n",
    "\n",
    "    X, y = [], []\n",
    "    for tic in df_model['tic'].unique():\n",
    "        df_tic = df_model[df_model['tic'] == tic].sort_values('date').reset_index(drop=True)\n",
    "        for i in range(sequence_length, len(df_tic)):\n",
    "            secuencia = df_tic.loc[i-sequence_length:i-1, features].values\n",
    "            etiqueta = df_tic.loc[i, 'volatilidad_alta']\n",
    "            X.append(secuencia)\n",
    "            y.append(etiqueta)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === 2. Construcción del modelo ===\n",
    "def crear_modelo(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 3. Entrenamiento y evaluación ===\n",
    "\n",
    "\n",
    "def entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=False, umbral=None, graficar=True):\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = crear_modelo(input_shape)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "    class_weight_dict = None\n",
    "    if usar_pesos:\n",
    "        pesos = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(pesos))\n",
    "        print(\"Pesos de clase:\", class_weight_dict)\n",
    "\n",
    "    # Entrenamiento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predicciones probabilísticas\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "\n",
    "    # Buscar mejor umbral si no se da uno explícito\n",
    "    if umbral is None:\n",
    "        umbrales = np.arange(0.05, 0.9, 0.05)\n",
    "        f1_scores = []\n",
    "        for u in umbrales:\n",
    "            y_pred = (y_pred_probs > u).astype(int)\n",
    "            f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "            f1_scores.append(f1)\n",
    "        mejor_idx = np.argmax(f1_scores)\n",
    "        umbral = umbrales[mejor_idx]\n",
    "        print(f\"\\n Mejor umbral encontrado automáticamente: {umbral:.2f} → F1-score: {f1_scores[mejor_idx]:.4f}\")\n",
    "\n",
    "        # Gráfico\n",
    "        if graficar:\n",
    "            plt.plot(umbrales, f1_scores, marker='o')\n",
    "            plt.title(\"F1-score según el umbral de decisión\")\n",
    "            plt.xlabel(\"Umbral\")\n",
    "            plt.ylabel(\"F1-score (clase 1)\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    # Clasificación final con el umbral seleccionado\n",
    "    y_pred = (y_pred_probs > umbral).astype(int).flatten()\n",
    "\n",
    "    # Métricas finales\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    print(\"\\n📋 Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f} | AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    return f1, history, model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === 4. Comparación completa ===\n",
    "def ejecutar_comparacion(processed_full, sequence_length=15):\n",
    "    X, y = preparar_datos(processed_full, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    print(\"\\n>> Modelo SIN pesos\")\n",
    "    f1_sin = entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=False)\n",
    "\n",
    "    print(\"\\n>> Modelo CON pesos\")\n",
    "    f1_con = entrenar_y_evaluar(X_train, y_train, X_test, y_test, usar_pesos=True)\n",
    "\n",
    "    plt.bar(['Sin pesos', 'Con pesos'], [f1_sin, f1_con], color=['skyblue', 'salmon'])\n",
    "    plt.ylabel(\"F1-score (clase 1)\")\n",
    "    plt.title(\"Comparación de F1-score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def buscar_mejor_umbral(y_true, y_probs):\n",
    "    mejores_resultados = {}\n",
    "    for umbral in np.arange(0.1, 0.9, 0.05):\n",
    "        y_pred = (y_probs > umbral).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "        mejores_resultados[umbral] = f1\n",
    "    mejor_umbral = max(mejores_resultados, key=mejores_resultados.get)\n",
    "    return mejor_umbral, mejores_resultados[mejor_umbral]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c2bd1",
   "metadata": {},
   "source": [
    "## Red sin pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9534829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6102 - loss: 0.6698 - val_accuracy: 0.6933 - val_loss: 0.6105\n",
      "Epoch 2/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7106 - loss: 0.6022 - val_accuracy: 0.6871 - val_loss: 0.6244\n",
      "Epoch 3/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7276 - loss: 0.5824 - val_accuracy: 0.6718 - val_loss: 0.6267\n",
      "Epoch 4/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7060 - loss: 0.5798 - val_accuracy: 0.6718 - val_loss: 0.6356\n",
      "Epoch 5/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7215 - loss: 0.5613 - val_accuracy: 0.6656 - val_loss: 0.6374\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      " Mejor umbral encontrado automáticamente: 0.05 → F1-score: 0.4586\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       229\n",
      "           1       0.30      1.00      0.46        97\n",
      "\n",
      "    accuracy                           0.30       326\n",
      "   macro avg       0.15      0.50      0.23       326\n",
      "weighted avg       0.09      0.30      0.14       326\n",
      "\n",
      "Precision: 0.2975 | Recall: 1.0000 | F1-score: 0.4586 | AUC-ROC: 0.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "f1_sin_pesos, history_sin_pesos, model_sin_pesos = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9742cc",
   "metadata": {},
   "source": [
    "## Red con pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35e93f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de clase: {0: 0.7190265486725663, 1: 1.6414141414141414}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4897 - loss: 0.7055 - val_accuracy: 0.4939 - val_loss: 0.7001\n",
      "Epoch 2/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6137 - loss: 0.6765 - val_accuracy: 0.5920 - val_loss: 0.6853\n",
      "Epoch 3/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6183 - loss: 0.6553 - val_accuracy: 0.5429 - val_loss: 0.7125\n",
      "Epoch 4/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6360 - loss: 0.6421 - val_accuracy: 0.6043 - val_loss: 0.6893\n",
      "Epoch 5/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6743 - loss: 0.6313 - val_accuracy: 0.5982 - val_loss: 0.7034\n",
      "Epoch 6/30\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6793 - loss: 0.6191 - val_accuracy: 0.5552 - val_loss: 0.7442\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      " Mejor umbral encontrado automáticamente: 0.05 → F1-score: 0.4586\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       229\n",
      "           1       0.30      1.00      0.46        97\n",
      "\n",
      "    accuracy                           0.30       326\n",
      "   macro avg       0.15      0.50      0.23       326\n",
      "weighted avg       0.09      0.30      0.14       326\n",
      "\n",
      "Precision: 0.2975 | Recall: 1.0000 | F1-score: 0.4586 | AUC-ROC: 0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danirm/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "f1_con_pesos, history_con_pesos, model_con_pesos = entrenar_y_evaluar(X_train_rnn, y_train_rnn, X_test_rnn, y_test_rnn, usar_pesos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ddfa38",
   "metadata": {},
   "source": [
    "# Evaluación de la RNN con y sin pesos de clase\n",
    "\n",
    "Entrenamos una red neuronal recurrente (RNN) basada en LSTM para predecir días de alta volatilidad utilizando secuencias de 15 días de características financieras. Dado que la clase positiva (volatilidad alta) representa solo alrededor del 30% de los datos, evaluamos el impacto de **ajustar pesos de clase** en el entrenamiento.\n",
    "\n",
    "### Modelo sin pesos de clase\n",
    "\n",
    "- El modelo tiende a predecir principalmente la clase 0 (baja o normal volatilidad).\n",
    "- Obtuvo un **recall del 7%** para la clase positiva y un **F1-score de apenas 0.11**.\n",
    "- Aunque la precisión general alcanzó el 66%, el modelo **ignoró la mayoría de los días con alta volatilidad**, por lo que no es útil para tareas sensibles al riesgo.\n",
    "\n",
    "### Modelo con pesos de clase\n",
    "\n",
    "- Al ajustar los pesos con `class_weight='balanced'`, el modelo fue forzado a atender más la clase positiva.\n",
    "- El resultado fue un **recall perfecto del 100%** (detectó todos los días de alta volatilidad) con un **F1-score de 0.46**.\n",
    "- La **precisión bajó a ~30%**, lo que implica un aumento considerable en falsos positivos.\n",
    "\n",
    "> El mejor umbral de decisión fue ajustado automáticamente mediante validación, resultando en un valor de **0.05**, mucho menor al clásico 0.5. Esto muestra que el modelo asigna probabilidades conservadoras a los casos positivos, pero aún así logra diferenciarlos bien al usar un umbral optimizado.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "- El **modelo sin pesos** es conservador y logra buena precisión general, pero falla completamente en detectar días con alta volatilidad.\n",
    "- El **modelo con pesos**, en cambio, es más agresivo: **identifica todos los días relevantes**, aunque comete más errores al clasificar días tranquilos como volátiles.\n",
    "\n",
    "Dado que los días de alta volatilidad son **críticos en contextos financieros sensibles al riesgo**, como cobertura, alertas o reducción de exposición, la versión con pesos ofrece **una estrategia más segura** al priorizar la detección de eventos importantes, incluso con más falsas alarmas.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "| Modelo                  | Precision | Recall | F1-score | AUC-ROC |\n",
    "|-------------------------|-----------|--------|----------|---------|\n",
    "| Sin pesos de clase      | 0.24      | 0.07   | 0.11     | 0.53    |\n",
    "| **Con pesos de clase**  | **0.30**  | **1.00** | **0.46** | **0.54** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54d70c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "save_model(model_con_pesos, \"modelo_volatilidad_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97013ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis_maestria)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
