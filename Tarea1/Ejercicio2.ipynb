{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8107052b-9730-4a9e-b528-2d50fb3df2ae",
   "metadata": {},
   "source": [
    "# PROBLEMA 2: **Clasificación de Spam con Naive Bayes**\n",
    "\n",
    "\n",
    "### Daniel Rojo Mata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28f466-0ab6-47f0-92d3-b86d1f0ad9d5",
   "metadata": {},
   "source": [
    "## **Enunciado del problema**\n",
    "\n",
    "Descarga el conjunto de datos de spam disponible en [este enlace](http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_automatizado/data/spam.csv) y realiza lo siguiente:\n",
    "\n",
    "1. **Exploración de datos:**  \n",
    "   - Reporta el porcentaje de correos etiquetados como *spam* y *no spam* en el conjunto de datos.\n",
    "\n",
    "2. **División del conjunto de datos:**  \n",
    "   - Divide aleatoriamente el conjunto de datos en:\n",
    "     - **60 %** para entrenamiento  \n",
    "     - **20 %** para validación  \n",
    "     - **20 %** para prueba  \n",
    "   - Usa `0` como semilla para el generador de números aleatorios.\n",
    "\n",
    "3. **Entrenamiento de clasificadores:**  \n",
    "   - Entrena **dos clasificadores Naive Bayes** con diferentes distribuciones.\n",
    "\n",
    "4. **Evaluación de modelos:**  \n",
    "   - Usa los clasificadores entrenados para predecir *spam* en los datos de **entrenamiento** y **validación**.  \n",
    "   - Reporta el **porcentaje de predicciones correctas** de cada clasificador.\n",
    "\n",
    "5. **Análisis del desempeño:**  \n",
    "   - Discute el rendimiento de los diferentes clasificadores con base en los resultados obtenidos.\n",
    "\n",
    "6. **Evaluación en el conjunto de prueba:**  \n",
    "   - Reporta el **porcentaje de predicciones correctas** en el subconjunto de **prueba** utilizando el clasificador con mejor rendimiento en la validación.\n",
    "\n",
    "## **Descripción del conjunto de datos**\n",
    "El archivo `spam.csv` contiene **2001 valores por renglón**, distribuidos de la siguiente manera:\n",
    "- Los **primeros 2000 valores** representan el **histograma de palabras** en un correo.\n",
    "- El **último valor (posición 2000)** indica la clase del correo:\n",
    "  - `1` → Es **spam**  \n",
    "  - `0` → No es **spam**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677774f8-fd05-496d-86dc-810ee911367f",
   "metadata": {},
   "source": [
    "# **Solución**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f40d89-dcf0-499a-9537-a91ed4d04fbf",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2c5b1c98-0672-457a-879d-9540badd9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan los cosos necesarios \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c8d38-854e-4826-a401-32205b7b5033",
   "metadata": {},
   "source": [
    "### Clasificador con distribución Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cfcbb429-d934-435a-a0f8-5b0e60122735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesBernoulli:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa los atributos del modelo de Naive Bayes con distribución Bernoulli.\n",
    "        \"\"\"\n",
    "        self.num_clases = None  # Número de clases en el conjunto de datos\n",
    "        self.num_caracteristicas = None  # Número de características en los datos\n",
    "        self.proba_caracteristica_dado_clase = None  # Matriz de probabilidades condicionales P(característica|clase)\n",
    "        self.proba_clase = None  # Vector de probabilidades a priori P(clase)\n",
    "\n",
    "    def fit(self, X_ent, y_ent):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el conjunto de entrenamiento.\n",
    "\n",
    "        Parámetros:\n",
    "            X_ent: Matriz de características del conjunto de entrenamiento\n",
    "            y_ent: Vector de etiquetas de clase del conjunto de entrenamiento\n",
    "        \"\"\"\n",
    "        clases_unicas = np.unique(y_ent)  # Encuentra las clases únicas en el conjunto de entrenamiento\n",
    "        self.num_clases = clases_unicas.size  # Almacena el número total de clases\n",
    "        self.num_caracteristicas = X_ent.shape[-1]  # Obtiene el número de características por muestra\n",
    "        num_muestras = X_ent.shape[0]  # Obtiene el número total de muestras en el conjunto de entrenamiento\n",
    "\n",
    "        # Inicializa la matriz de probabilidades condicionales con ceros\n",
    "        self.proba_caracteristica_dado_clase = np.zeros((self.num_clases, self.num_caracteristicas))  \n",
    "        # Inicializa el vector de probabilidades a priori con ceros\n",
    "        self.proba_clase = np.zeros(self.num_clases)  \n",
    "\n",
    "        for i, clase in enumerate(clases_unicas):  # Itera sobre cada clase\n",
    "            X_clase = X_ent[y_ent == clase]  # Filtra las muestras pertenecientes a la clase actual\n",
    "            cuenta_atributos = np.count_nonzero(X_clase, axis=0)  # Cuenta cuántas veces cada atributo es 1 dentro de la clase\n",
    "                                                                  # axis = 0 indica que se aplica a lo largo de las columnas\n",
    "            num_muestras_clase = X_clase.shape[0]  # Obtiene el número de muestras en la clase actual\n",
    "            \n",
    "            # Calcula P(atributo=1 | clase) dividiendo la cuenta entre el número de muestras de la clase\n",
    "            self.proba_caracteristica_dado_clase[i, :] = cuenta_atributos / num_muestras_clase # [i, :] := modifica toda la fila 'i' de la matriz \n",
    "            \n",
    "            # Calcula P(clase) como la proporción de muestras de la clase en el total de datos\n",
    "            self.proba_clase[i] = num_muestras_clase / num_muestras  \n",
    "    \n",
    "    def calcular_probabilidades_posteriores(self, X):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades posteriores (proporcionales) para cada muestra:\n",
    "            P(clase|datos) ∝ P(datos|clase) * P(clase)\n",
    "        Se omite el denominador P(datos) ya que es constante para todas las clases.\n",
    "\n",
    "        Parámetros: \n",
    "            X: Matriz de características del conjunto de prueba\n",
    "        \n",
    "        return: \n",
    "            Matriz de probabilidades de cada clase para cada muestra\n",
    "        \"\"\"\n",
    "        probabilidades = np.zeros((X.shape[0], self.num_clases))  # Matriz para almacenar las probabilidades calculadas\n",
    "                                                                  # Es de tamaño: NumCaracterísticas x NumClases\n",
    "        \n",
    "        for indice_clase in range(self.num_clases):  # Itera sobre cada clase\n",
    "            # Calcula la verosimilitud P(X|C) usando la distribución de Bernoulli.\n",
    "                # Bajo el supuesto de independencia condicional (Bayes ingenuo), se calcula como:\n",
    "                # P(X|C) = P(x_1|C) * P(x_2|C) * P(x_3|C) * ... * P(x_n|C)\n",
    "            verosimilitud = np.prod(self.bernoulli(X, self.proba_caracteristica_dado_clase[indice_clase, :]), axis=1)  \n",
    "            # Multiplica la verosimilitud por la probabilidad a priori de la clase P(C)\n",
    "            # Esto nos da una cantidad proporcional a la probabilidad posterior P(C|X)\n",
    "            probabilidades[:, indice_clase] = verosimilitud * self.proba_clase[indice_clase]\n",
    "\n",
    "        return probabilidades  # Retorna la matriz de probabilidades posteriores\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice las clases de un conjunto de datos.\n",
    "        \n",
    "        Parámetros:\n",
    "            X: Matriz de características del conjunto de prueba\n",
    "        \n",
    "        return: \n",
    "            Vector con las clases predichas\n",
    "        \"\"\"\n",
    "        return np.argmax(self.calcular_probabilidades_posteriores(X), axis=1)  # Retorna la clase con la mayor probabilidad posterior\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli(x, q):\n",
    "        \"\"\"\n",
    "        Función de masa de probabilidad de la distribución de Bernoulli.\n",
    "        \n",
    "        Parámetros:\n",
    "            x: Valores de la variable aleatoria (0 o 1)\n",
    "            q: Probabilidad del éxito (atributo = 1) en la distribución de Bernoulli\n",
    "        \n",
    "        return: \n",
    "            Probabilidad de cada muestra bajo la distribución de Bernoulli\n",
    "        \"\"\"\n",
    "        epsilon = 1e-9  # Pequeño valor para evitar cálculos con 0 o 1 exactos que puedan generar errores numéricos\n",
    "        q = np.clip(q, epsilon, 1 - epsilon)  # Restringe los valores de q al intervalo (epsilon, 1 - epsilon)\n",
    "        return q**x * (1.0 - q)**(1.0 - x)  # Aplica la fórmula de la distribución de Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2958015-50ea-4a7c-8b42-890f3c1dbf41",
   "metadata": {},
   "source": [
    "### Clasificador con distribución Gaussiana\n",
    "\n",
    "Se utiliza el logaritmo para un mejor trabajo, pues multiplicar probabilidades pequeñas puede dar valores muy bajos, cercanos a cero, lo que puede causar subdesbordamiento numérico en la computadora.\n",
    "\n",
    "El objetivo de usar logaritmo es evitar esto último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b5da8dfc-2cb1-4348-9008-a87b5ef3fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesGaussiano:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa los atributos del modelo de Naive Bayes con distribución Gaussiana.\n",
    "        \"\"\"\n",
    "        self.media = None  # Media de cada característica por clase\n",
    "        self.desviacion = None  # Desviación estándar de cada característica por clase\n",
    "        self.proba_clase = None  # Probabilidad a priori de cada clase\n",
    "        self.clases = None  # Clases únicas en el conjunto de datos\n",
    "        self.epsilon = 1e-6  # Pequeño valor para evitar divisiones por 0 en la varianza\n",
    "\n",
    "    def fit(self, X_ent, y_ent):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el conjunto de entrenamiento.\n",
    "        Calcula los parámetros de la distribución Gaussiana (media y desviación estándar) \n",
    "        para cada característica en cada clase.\n",
    "        \n",
    "        Parámetros:\n",
    "            X_ent: ndarray de forma (num_muestras, num_características), matriz de datos de entrada.\n",
    "            y_ent: ndarray de forma (num_muestras,), vector de etiquetas de clase.\n",
    "        \"\"\"\n",
    "        self.clases = np.unique(y_ent)  # Obtiene las clases únicas en el conjunto de entrenamiento\n",
    "        num_clases = len(self.clases)  # Número total de clases\n",
    "        num_caracteristicas = X_ent.shape[1]  # Número de características en los datos\n",
    "        \n",
    "        # Inicializa matrices para almacenar la media, desviación estándar y probabilidades a priori, resp.\n",
    "        self.media = np.zeros((num_clases, num_caracteristicas))\n",
    "        self.desviacion = np.zeros((num_clases, num_caracteristicas))\n",
    "        self.proba_clase = np.zeros(num_clases)\n",
    "        \n",
    "        # Itera sobre cada clase para calcular sus parámetros estadísticos\n",
    "        for i, clase in enumerate(self.clases):\n",
    "            X_clase = X_ent[y_ent == clase]  # Filtra las muestras que pertenecen a la clase actual\n",
    "            self.media[i, :] = X_clase.mean(axis=0)  # Calcula la media de cada característica\n",
    "            self.desviacion[i, :] = np.maximum(X_clase.std(axis=0), self.epsilon)  # Evita sigma = 0\n",
    "            self.proba_clase[i] = len(X_clase) / len(X_ent)  # Calcula la probabilidad a priori de la clase\n",
    "\n",
    "    def gaussian_log(self, x, mu, sigma):\n",
    "        \"\"\"\n",
    "        Calcula la densidad de probabilidad de una distribución Gaussiana para cada característica.\n",
    "\n",
    "        Parámetros:\n",
    "            x: ndarray de forma (num_muestras, num_características), valores de entrada.\n",
    "            mu: ndarray de forma (num_características,), media de la distribución Gaussiana.\n",
    "            sigma: ndarray de forma (num_características,), desviación estándar de la distribución Gaussiana.\n",
    "\n",
    "        return:\n",
    "            Log-probabilidad de cada característica bajo la distribución Gaussiana correspondiente.\n",
    "        \"\"\"\n",
    "        sigma = np.maximum(sigma, self.epsilon)  # Asegura que sigma no sea 0 para evitar errores numéricos\n",
    "        coef = -0.5 * np.log(2 * np.pi * sigma**2)  # Cálculo del coeficiente de normalización en logaritmo\n",
    "        exponente = -((x - mu) ** 2) / (2 * sigma ** 2)  # Cálculo de la parte exponencial de la función Gaussiana\n",
    "        return coef + exponente  # Retorna la suma de log-probabilidades para estabilidad numérica\n",
    "\n",
    "    def calcular_probabilidades_posteriores(self, X):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades logarítmicas de cada clase para cada muestra.\n",
    "\n",
    "        Parámetros:\n",
    "            X: ndarray de forma (num_muestras, num_características), datos de entrada.\n",
    "\n",
    "        return:\n",
    "            log_probabilidades: ndarray de forma (num_muestras, num_clases),\n",
    "                                matriz de log-probabilidades de cada muestra perteneciendo a cada clase.\n",
    "        \"\"\"\n",
    "        num_muestras = X.shape[0]  # Número total de muestras\n",
    "        num_clases = len(self.clases)  # Número total de clases\n",
    "        log_probabilidades = np.zeros((num_muestras, num_clases))  # Inicializa matriz de log-probabilidades\n",
    "        \n",
    "        # Itera sobre cada clase para calcular la log-probabilidad de que una muestra pertenezca a ella\n",
    "        for i in range(num_clases):\n",
    "            log_prob_verosimilitud = self.gaussian_log(X, self.media[i, :], self.desviacion[i, :])  \n",
    "            log_prob_verosimilitud = np.sum(log_prob_verosimilitud, axis=1)  # Suma las log-probabilidades de cada característica\n",
    "            \n",
    "            # Aplica la fórmula de la probabilidad posterior en logaritmo:\n",
    "            # log P(C|X) = log P(X|C) + log P(C), sin dividir por P(X) ya que no afecta la clasificación\n",
    "            log_probabilidades[:, i] = log_prob_verosimilitud + np.log(self.proba_clase[i]) \n",
    "        \n",
    "        return log_probabilidades  # Retorna la matriz de log-probabilidades para cada muestra y clase\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice la clase de cada muestra en X.\n",
    "\n",
    "        Parámetros:\n",
    "            X: ndarray de forma (num_muestras, num_características), datos de entrada.\n",
    "\n",
    "        return:\n",
    "            Un vector con las clases predichas para cada muestra.\n",
    "        \"\"\"\n",
    "        log_probabilidades = self.calcular_probabilidades_posteriores(X)  # Calcula log-probabilidades para cada clase\n",
    "        return self.clases[np.argmax(log_probabilidades, axis=1)]  # Retorna la clase con mayor log-probabilidad para cada muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15694d3a-5262-452f-b794-17645b36bd19",
   "metadata": {},
   "source": [
    "### Procesamiento de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7d2e65e-4192-49c0-afbc-2adbedd05fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"spam.csv\"\n",
    "data = pd.read_csv(archivo, \n",
    "                   header=None,\n",
    "                   sep=None,\n",
    "                   engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "968b16f7-d1c5-42ce-9bd2-e52c3eb939e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa las características y la etiqueta\n",
    "X = data.iloc[:, :-1].to_numpy()  # Todas las columnas excepto la última\n",
    "y = data.iloc[:, -1].to_numpy()   # La última columna (etiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375ace0-4f6d-4734-85f7-27b939401080",
   "metadata": {},
   "source": [
    "### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bcd9e00d-9c1e-4463-9cf0-72f7ca2bb6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (3103, 2000)\n",
      "Tamaño del conjunto de validación: (1034, 2000)\n",
      "Tamaño del conjunto de prueba: (1035, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en conjunto de entrenamiento (60%) y el resto (40%)\n",
    "X_ent, X_temp, y_ent, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Dividir el conjunto temporal en validación (20%) y prueba (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Ver las dimensiones de los conjuntos anteriores\n",
    "print(f'Tamaño del conjunto de entrenamiento: {X_ent.shape}')\n",
    "print(f'Tamaño del conjunto de validación: {X_val.shape}')\n",
    "print(f'Tamaño del conjunto de prueba: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a49ec-d25c-4661-91d9-bada810da372",
   "metadata": {},
   "source": [
    "## Resultados con Clasificador Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bd55cab6-aadd-4b8b-b46d-cc62660bf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en entrenamiento: 92.78%\n",
      "Precisión en validación: 91.01%\n",
      "Precisión en prueba: 91.50%\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de NaiveBayesBernoulli\n",
    "nb_bernoulli = NaiveBayesBernoulli()\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "nb_bernoulli.fit(X_ent, y_ent)\n",
    "\n",
    "# Predecir para los conjuntos de datos\n",
    "predicciones_ent = nb_bernoulli.predict(X_ent)\n",
    "predicciones_val = nb_bernoulli.predict(X_val)\n",
    "predicciones_test = nb_bernoulli.predict(X_test)\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy_ent_bernoulli = accuracy_score(y_ent, predicciones_ent) * 100\n",
    "accuracy_val_bernoulli = accuracy_score(y_val, predicciones_val) * 100\n",
    "accuracy_test_bernoulli = accuracy_score(y_test, predicciones_test) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Precisión en entrenamiento: {accuracy_ent_bernoulli:.2f}%\")\n",
    "print(f\"Precisión en validación: {accuracy_val_bernoulli:.2f}%\")\n",
    "print(f\"Precisión en prueba: {accuracy_test_bernoulli:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c8690-c6fb-4d63-b70a-3cda74f7956b",
   "metadata": {},
   "source": [
    "## Resultados con Clasificador Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "930acdeb-74ac-4b53-9bcd-5977371b7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en entrenamiento: 93.81%\n",
      "Precisión en validación: 93.04%\n",
      "Precisión en prueba: 92.46%\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de NaiveBayesGaussiano\n",
    "nb_gauss = NaiveBayesGaussiano()\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "nb_gauss.fit(X_ent, y_ent)\n",
    "\n",
    "# Predecir para los conjuntos de datos\n",
    "predicciones_ent = nb_gauss.predict(X_ent)\n",
    "predicciones_val = nb_gauss.predict(X_val)\n",
    "predicciones_test = nb_gauss.predict(X_test)\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy_ent_gaussiano = accuracy_score(y_ent, predicciones_ent) * 100\n",
    "accuracy_val_gaussiano = accuracy_score(y_val, predicciones_val) * 100\n",
    "accuracy_test_gaussiano = accuracy_score(y_test, predicciones_test) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Precisión en entrenamiento: {accuracy_ent:.2f}%\")\n",
    "print(f\"Precisión en validación: {accuracy_val:.2f}%\")\n",
    "print(f\"Precisión en prueba: {accuracy_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb66748-ada6-4c59-8c21-718dc5fb18df",
   "metadata": {},
   "source": [
    "## Resultados Con SckitLearn y Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ead2e5cd-397a-46bc-9b8a-8cd22c505a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en entrenamiento: 91.11%\n",
      "Precisión en validación: 91.10%\n",
      "Precisión en prueba: 90.63%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir los datos en entrenamiento (60%), validación (20%) y prueba (20%)\n",
    "X_ent, X_temp, y_ent, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Crear una instancia del clasificador Naive Bayes Bernoulli\n",
    "nb_classifier = BernoulliNB()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "nb_classifier.fit(X_ent, y_ent)\n",
    "\n",
    "# Predecir para los conjuntos de entrenamiento, validación y prueba\n",
    "predicciones_ent = nb_classifier.predict(X_ent)\n",
    "predicciones_val = nb_classifier.predict(X_val)\n",
    "predicciones_test = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy_ent = accuracy_score(y_ent, predicciones_ent) * 100\n",
    "accuracy_val = accuracy_score(y_val, predicciones_val) * 100\n",
    "accuracy_test = accuracy_score(y_test, predicciones_test) * 100\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Precisión en entrenamiento: {accuracy_ent:.2f}%\")\n",
    "print(f\"Precisión en validación: {accuracy_val:.2f}%\")\n",
    "print(f\"Precisión en prueba: {accuracy_test:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9389ad-254e-4238-a802-6ff18c8a3acc",
   "metadata": {},
   "source": [
    "## Resultados con ScikitLearn y Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "720342f5-62eb-4410-9a02-a1b5a54493b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en entrenamiento: 93.84%\n",
      "Precisión en validación: 93.04%\n",
      "Precisión en prueba: 92.46%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir los datos en entrenamiento (60%), validación (20%) y prueba (20%)\n",
    "X_ent, X_temp, y_ent, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Crear una instancia del clasificador Naive Bayes Gaussiano\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "nb_classifier.fit(X_ent, y_ent)\n",
    "\n",
    "# Predecir para los conjuntos de entrenamiento, validación y prueba\n",
    "predicciones_ent = nb_classifier.predict(X_ent)\n",
    "predicciones_val = nb_classifier.predict(X_val)\n",
    "predicciones_test = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy_ent = accuracy_score(y_ent, predicciones_ent) * 100\n",
    "accuracy_val = accuracy_score(y_val, predicciones_val) * 100\n",
    "accuracy_test = accuracy_score(y_test, predicciones_test) * 100\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Precisión en entrenamiento: {accuracy_ent:.2f}%\")\n",
    "print(f\"Precisión en validación: {accuracy_val:.2f}%\")\n",
    "print(f\"Precisión en prueba: {accuracy_test:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e972e-4eb8-4608-8900-57afdb4791a3",
   "metadata": {},
   "source": [
    "## Reporte de Spam y No Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c8c2c200-a3b2-440f-81fa-612c24a45e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de correos spam: 29.00%\n",
      "Porcentaje de correos no spam: 71.00%\n"
     ]
    }
   ],
   "source": [
    "spam_ratio = np.mean(y) * 100  # Asumiendo que spam = 1 y no spam = 0\n",
    "print(f\"Porcentaje de correos spam: {spam_ratio:.2f}%\")\n",
    "print(f\"Porcentaje de correos no spam: {100 - spam_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886bcd5-553f-4072-86f1-99601cb42ce8",
   "metadata": {},
   "source": [
    "## Mejor Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca083891-bc19-4eea-812b-e167d07f4bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor clasificador en validación es: Naive Bayes Gaussiano\n",
      "Precisión en prueba con Naive Bayes Gaussiano: 92.46%\n"
     ]
    }
   ],
   "source": [
    "# Se hace el comparativo con ambos clasificadores\n",
    "# Se compara el \"accuracy\"\n",
    "\n",
    "if accuracy_val_gaussiano > accuracy_val_bernoulli:\n",
    "    mejor_clasificador = \"Naive Bayes Gaussiano\"\n",
    "    mejor_modelo = nb_gauss\n",
    "else:\n",
    "    mejor_clasificador = \"Naive Bayes Bernoulli\"\n",
    "    mejor_modelo = nb_bernoulli\n",
    "print(f\"El mejor clasificador en validación es: {mejor_clasificador}\")\n",
    "\n",
    "# Imprime el mejor resultado (no considerando los realizados por ScikitLearn) \n",
    "predicciones_test_mejor = mejor_modelo.predict(X_test)\n",
    "accuracy_test_mejor = accuracy_score(y_test, predicciones_test_mejor) * 100\n",
    "print(f\"Precisión en prueba con {mejor_clasificador}: {accuracy_test_mejor:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef6446-c1f9-4e71-8233-a6a79c3efd31",
   "metadata": {},
   "source": [
    "## Discusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364be5-4ca1-4830-8bc9-100a73789239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
