{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16a15d-4a13-4165-a8fc-906b81f1d492",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9abf61-0256-4184-b116-f4cb478efc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"aves.csv\" #nombre del archivo\n",
    "data = pd.read_csv(archivo, #Nombre del archivo\n",
    "                   index_col=0, #Quito la columna indexada por 0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36150df7-bdd8-4763-a530-abcfccbbb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # Se visualizan los primeros 5 elementos de la data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305ae71-b05e-4193-89fc-b5a340403211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # Se ontiene información relevante del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f1d6c-d0a2-4f9d-8d30-d9489573ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x1\"].value_counts()# Cuenta cuántas veces aparece cada valor único en la columna \"x1\" \n",
    "                        # y devuelve una Serie ordenada de mayor a menor frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce6a11-f0b9-4da8-a542-20bf534ed38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() #Resumen de características de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4e8a7-8522-4503-822d-3fdf0ef41be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data.hist(bins=50, figsize=(20,15)) # Se visualiza la data numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1b4a0-1676-4f4d-b4a1-5448380eff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.iloc[:,:-1].corr(method = \"pearson\")\n",
    "cmap = sns.diverging_palette(250,354,80,60,center='dark',as_cmap=True)\n",
    "sns.heatmap(corr, vmax=1, vmin = -0.5, cmap=cmap, square=True, linewidths=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae0156-8523-4c8e-b853-72ae8a2d8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_train_test(data, test_radio):\n",
    "#     '''\n",
    "#     data: Datos con los cuales se está trabajando\n",
    "#     test_radio: Porcentaje de la data que se quiere para el test\n",
    "#     '''\n",
    "#     shuffle_indices = np.random.permutation(len(data)) #Nos da une permutación de elementos\n",
    "#     test_set_size = int(len(data)*test_radio) # Porcentaje de datos que obtengo de la data\n",
    "#     test_indices = shuffle_indices[:test_set_size]\n",
    "#     train_indices = shuffle_indices[test_set_size:]\n",
    "#     return data.iloc[train_indices], data.iloc[test_indices] # Devuelve las filas con estos índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161be35-98d7-45f7-99fc-42a3026f33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2b15a-4b03-44c3-8091-5f579a6e5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior(dataFrame, Class):\n",
    "    classes = sorted(list(dataFrame[Class].unique()))  # Clases presentes en la data\n",
    "    denominador = len(dataFrame)\n",
    "    prior = []\n",
    "    for i in classes:\n",
    "        numerador = len(dataFrame[dataFrame[Class] == i])  # Número de filas que cumplen la condición\n",
    "        prior.append(numerador / denominador)  # Probabilidad a priori\n",
    "    return prior\n",
    "\n",
    "def verosimilitud_gaussiana(dataFrame, caracteristica, valor_caracteristica, clase, label):\n",
    "    dataFrame = dataFrame[dataFrame[clase] == label]  # Filtramos los datos de la clase deseada\n",
    "    mean = dataFrame[caracteristica].mean()  # Media de la característica\n",
    "    std = dataFrame[caracteristica].std()  # Desviación estándar\n",
    "\n",
    "    if std == 0:  # Para evitar divisiones por cero\n",
    "        return 1 if valor_caracteristica == mean else 0\n",
    "\n",
    "    proba_x_dado_y = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-((valor_caracteristica - mean) ** 2) / (2 * std ** 2))\n",
    "    return proba_x_dado_y\n",
    "\n",
    "def clasificador_ingenuo_bayesiano(dataFrame, X, Y):\n",
    "    '''\n",
    "    X: Lista o array de vectores de características\n",
    "    Y: Nombre de la columna de la clase\n",
    "    '''\n",
    "    # Suponemos que todas las columnas excepto Y son características\n",
    "    # Alternativamente, se podría pasar explícitamente la lista de características.\n",
    "    caracteristicas = [col for col in dataFrame.columns if col != Y]\n",
    "    prior = calculate_prior(dataFrame, Y)\n",
    "\n",
    "    labels = sorted(list(dataFrame[Y].unique()))\n",
    "    Y_pred = []\n",
    "    \n",
    "    for x in X:\n",
    "        # Inicializar verosimilitud para cada clase\n",
    "        verosimilitud = [1.0] * len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(caracteristicas)):\n",
    "                verosimilitud[j] *= verosimilitud_gaussiana(dataFrame, \n",
    "                                                             caracteristicas[i], \n",
    "                                                             x[i], \n",
    "                                                             Y, \n",
    "                                                             labels[j])\n",
    "        # Calcular probabilidad posterior para cada clase\n",
    "        post_prob = [verosimilitud[j] * prior[j] for j in range(len(labels))]\n",
    "        \n",
    "        # Se selecciona la clase con mayor probabilidad\n",
    "        pred_class_index = np.argmax(post_prob)\n",
    "        Y_pred.append(labels[pred_class_index])\n",
    "        \n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa18b5-c8c9-46e8-89b4-62a1e39c5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:,:-1].values\n",
    "Y_test = test.iloc[:, -1].values\n",
    "Y_predict = clasificador_ingenuo_bayesiano(data, X = X_test, Y = \"x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704cce78-3b2c-4a67-b9f3-e477c394b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_predict))\n",
    "print(f1_score(Y_test, Y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800b1d3-5245-4c96-b5a8-168b10f06cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNB:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estima parámetros por máxima verosimilitud con suavizado de Laplace.\n",
    "        \"\"\"\n",
    "        self.clases = np.unique(y)\n",
    "        self.n_clases = self.clases.size\n",
    "        self.n_atr = X.shape[1]\n",
    "        n = X.shape[0]\n",
    "\n",
    "        self.qa = np.zeros((self.n_clases, self.n_atr))\n",
    "        self.qc = np.zeros(self.n_clases)\n",
    "\n",
    "        for i, c in enumerate(self.clases):\n",
    "            Xc = X[np.where(y == c)]\n",
    "            nc = Xc.shape[0]\n",
    "\n",
    "            cuentas = np.count_nonzero(Xc, axis=0)\n",
    "            self.qa[i, :] = (cuentas + 1) / (nc + 2)  # Suavizado de Laplace\n",
    "            self.qc[i] = nc / n\n",
    "\n",
    "    def bernoulli_pmf(self, x, p):\n",
    "        \"\"\"\n",
    "        Función de masa de probabilidad de la distribución Bernoulli.\n",
    "        \"\"\"\n",
    "        return p**x * (1 - p)**(1 - x)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad a posteriori para cada clase.\n",
    "        \"\"\"\n",
    "        prop = np.zeros((X.shape[0], self.n_clases))\n",
    "        for i in range(self.n_clases):\n",
    "            prob_cond = self.bernoulli_pmf(X, self.qa[i, :])\n",
    "            prop[:, i] = np.prod(prob_cond, axis=1) * self.qc[i]  # Multiplicamos las probabilidades\n",
    "        return prop\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice las clases del conjunto de datos.\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "X_ent, X_nuevos, y_ent, y_nuevos = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ejemplo de uso\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_ent, y_ent)\n",
    "\n",
    "y_bnb = bnb.predict(X_nuevos)\n",
    "p_bnb = bnb.predict_proba(X_nuevos)\n",
    "\n",
    "print(y_bnb)\n",
    "print(p_bnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30067f99-0bd6-448a-a798-5ec468987952",
   "metadata": {},
   "source": [
    "# Nuevo intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad22e605-2c1a-467d-a356-e0264f4fd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0252a40d-51e5-402b-a0c6-82c2cc704072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             x1         x2    y\n",
       "0     7.606876  11.421913  0.0\n",
       "1     8.300079  12.352260  0.0\n",
       "2     6.833771  10.770320  0.0\n",
       "3     7.349341  10.903545  0.0\n",
       "4     7.442586  11.730364  0.0\n",
       "...        ...        ...  ...\n",
       "1995  8.580453  11.368367  1.0\n",
       "1996  6.815484   8.230757  1.0\n",
       "1997  7.183152   9.043539  1.0\n",
       "1998  7.928611  10.058593  1.0\n",
       "1999  9.009942  11.374089  1.0\n",
       "\n",
       "[2000 rows x 3 columns]>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7bedb77-2fbf-4d66-bf19-5511febecb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.606876</td>\n",
       "      <td>11.421913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300079</td>\n",
       "      <td>12.352260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.833771</td>\n",
       "      <td>10.770320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.349341</td>\n",
       "      <td>10.903545</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.442586</td>\n",
       "      <td>11.730364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8.580453</td>\n",
       "      <td>11.368367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>6.815484</td>\n",
       "      <td>8.230757</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7.183152</td>\n",
       "      <td>9.043539</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>7.928611</td>\n",
       "      <td>10.058593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>9.009942</td>\n",
       "      <td>11.374089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1         x2    y\n",
       "0     7.606876  11.421913  0.0\n",
       "1     8.300079  12.352260  0.0\n",
       "2     6.833771  10.770320  0.0\n",
       "3     7.349341  10.903545  0.0\n",
       "4     7.442586  11.730364  0.0\n",
       "...        ...        ...  ...\n",
       "1995  8.580453  11.368367  1.0\n",
       "1996  6.815484   8.230757  1.0\n",
       "1997  7.183152   9.043539  1.0\n",
       "1998  7.928611  10.058593  1.0\n",
       "1999  9.009942  11.374089  1.0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "685745c2-8515-46a1-bc20-a2df76d78e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.60687595, 11.42191282,  0.        ],\n",
       "       [ 8.30007867, 12.35226012,  0.        ],\n",
       "       [ 6.83377131, 10.7703199 ,  0.        ],\n",
       "       ...,\n",
       "       [ 7.18315177,  9.0435393 ,  1.        ],\n",
       "       [ 7.92861062, 10.05859259,  1.        ],\n",
       "       [ 9.00994167, 11.37408856,  1.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43f87dcc-7339-4361-997f-80d60971f657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc8e67f0-239c-41cc-953b-812d7d407374",
   "metadata": {},
   "outputs": [],
   "source": [
    "clases_unicas = np.unique(y_ent) # Clases únicas en el conjunto de entrenamiento\n",
    "num_clases = clases_unicas.size # Número total de clases\n",
    "num_caracteristicas = X_ent.shape[-1] # Número de características por muestra\n",
    "num_muestras = X_ent.shape[0] # Número total de muestras en el conjunto de entrenamiento\n",
    "\n",
    "prob_atributo_dado_clase = np.zeros((num_clases, num_caracteristicas)) # Parámetros condicionales: probabilidad de que cada atributo sea 1 para cada clase.\n",
    "prob_clase = np.zeros(num_clases) # Probabilidades a priori: probabilidad de ocurrencia de cada clase.\n",
    "\n",
    "for i, clase in enumerate(clases_unicas):\n",
    "    # Filtra ejemplos de la clase actual\n",
    "    X_clase = X_ent[y_ent == clase] # Filtra los valores en X_ent que cumplen y == clase \n",
    "    cuenta_atributos = np.count_nonzero(X_clase, axis=0) # Cuenta las veces que cada atributo es 1 en la clase actual, porque es BERNOULLI\n",
    "                                                         # axis = 0 indica que se aplica a lo largo de las columnas\n",
    "    num_muestras_clase = X_clase.shape[0] # Número de muestras en la clase actual\n",
    "    prob_atributo_dado_clase[i, :] = cuenta_atributos / num_muestras_clase # Calcula la probabilidad de cada atributo dado la clase: P(atributo = 1 | clase)\n",
    "                                                                            # [i, :] := modifica toda la fila 'i' de la matriz \n",
    "    prob_clase[i] = num_muestras_clase / num_muestras # Calcula la probabilidad a priori de la clase: P(clase)\n",
    "    \n",
    "def calcular_probabilidades_posteriores(self, X):\n",
    "    \"\"\"\n",
    "    Calcula las probabilidades posteriores (proporcionales) para cada muestra:\n",
    "    \n",
    "    P(clase|datos) ∝ P(datos|clase) * P(clase)\n",
    "    \n",
    "    Se omite el denominador P(datos) ya que es constante para todas las clases.\n",
    "    \"\"\"\n",
    "    # Inicializa la matriz de probabilidades con ceros:\n",
    "    probabilidades = np.zeros((X.shape[0], self.n_clases)) # Cada fila corresponde a una muestra y cada columna a una clase.\n",
    "    \n",
    "    # Se itera sobre cada clase:\n",
    "    # 1.- calcula la verosimilitud: P(X|C)\n",
    "    # 2.- la multiplica por la probabilidad a priori: P(C)\n",
    "    for indice_clase in range(self.n_clases):\n",
    "        verosimilitud = np.prod(bernoulli(X, self.qa[indice_clase, :]), axis=1) #Aquí usamos la distribución de Bernoulli para modelar cada atributo independientemente.\n",
    "        probabilidades[:, indice_clase] = verosimilitud * self.qc[indice_clase]\n",
    "    \n",
    "    return probabilidades\n",
    "\n",
    "def predict(self, X):\n",
    "    \"\"\"\n",
    "    Predice clases de conjunto de datos\n",
    "    \"\"\"\n",
    "    return np.argmax(self.calcular_probabilidades_posteriores(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b95eb08b-341c-42ba-8bfe-3ad795e5a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [0 0 0 ... 0 0 0]\n",
      "Probabilidades: [[9.07965052e+152 9.07965052e+152]\n",
      " [3.71551828e+167 3.71551828e+167]\n",
      " [1.36707114e+140 1.36707114e+140]\n",
      " ...\n",
      " [5.48516630e+127 5.48516630e+127]\n",
      " [3.83529801e+143 3.83529801e+143]\n",
      " [1.42969142e+165 1.42969142e+165]]\n"
     ]
    }
   ],
   "source": [
    "class BernoulliNB:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estima parámetros por máxima verosimilitud.\n",
    "        \"\"\"\n",
    "        self.clases = np.unique(y)\n",
    "        self.n_clases = self.clases.size\n",
    "        self.n_atr = X.shape[-1]\n",
    "        n = X.shape[0]\n",
    "\n",
    "        self.qa = np.zeros((self.n_clases, self.n_atr))\n",
    "        self.qc = np.zeros((self.n_clases))\n",
    "        for i, c in enumerate(self.clases):\n",
    "            Xc = X[y == c]\n",
    "            nc = Xc.shape[0]\n",
    "            cuentas = np.count_nonzero(Xc, axis=0)\n",
    "            self.qa[i, :] = cuentas / nc\n",
    "            self.qc[i] = nc / n\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad a posteriori (proporcional) para cada clase.\n",
    "        \"\"\"\n",
    "        prop = np.zeros((X.shape[0], self.n_clases))\n",
    "        for i in range(self.n_clases):\n",
    "            prop[:, i] = np.prod(bernoulli(X, self.qa[i, :]), axis=1) * self.qc[i]\n",
    "        return prop\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice las clases para el conjunto de datos X.\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def bernoulli(x, q, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Función que calcula la probabilidad usando la distribución Bernoulli.\n",
    "    - x: Valores (0 o 1) de las características.\n",
    "    - q: Probabilidad de éxito (P(x=1)).\n",
    "    Se utiliza clip para evitar problemas numéricos.\n",
    "    \"\"\"\n",
    "    q = np.clip(q, epsilon, 1.0 - epsilon)\n",
    "    return q**x * (1.0 - q)**(1.0 - x)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "archivo = \"aves.csv\"\n",
    "data = pd.read_csv(archivo, index_col=0)\n",
    "data_numpy = data.to_numpy()\n",
    "\n",
    "# Separar las características (todas menos la última) y la etiqueta (la última columna)\n",
    "X_ent = data_numpy[:, :-1]\n",
    "y_ent = data_numpy[:, -1]\n",
    "\n",
    "# Ejemplo: definir datos nuevos para predecir.\n",
    "# Si no tienes un conjunto separado, puedes usar el mismo X_ent o crear otro arreglo.\n",
    "X_nuevos = X_ent.copy()  # Aquí se usa el mismo conjunto para la predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69bbc10e-3079-4fb2-8ae6-a6053e2643c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayesBernoulli:\n",
    "    def __init__(self):\n",
    "        self.num_clases = None\n",
    "        self.num_caracteristicas = None\n",
    "        self.proba_caracteristica_dado_clase = None\n",
    "        self.proba_clase = None\n",
    "\n",
    "    def fit(self, X_ent, y_ent):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el conjunto de entrenamiento.\n",
    "        \"\"\"\n",
    "        clases_unicas = np.unique(y_ent)  # Clases únicas en el conjunto de entrenamiento\n",
    "        self.num_clases = clases_unicas.size  # Número total de clases\n",
    "        self.num_caracteristicas = X_ent.shape[-1]  # Número de características por muestra\n",
    "        num_muestras = X_ent.shape[0]  # Número total de muestras en el conjunto de entrenamiento\n",
    "\n",
    "        self.proba_caracteristica_dado_clase = np.zeros((self.num_clases, self.num_caracteristicas))  # Parámetros condicionales: probabilidad de que cada atributo sea 1 para cada clase.\n",
    "        self.proba_clase = np.zeros(self.num_clases)  # Probabilidades a priori: probabilidad de ocurrencia de cada clase.\n",
    "\n",
    "        for i, clase in enumerate(clases_unicas):\n",
    "            # Filtra ejemplos de la clase actual\n",
    "            X_clase = X_ent[y_ent == clase]  # Filtra los valores en X_ent que cumplen y == clase \n",
    "            cuenta_atributos = np.count_nonzero(X_clase, axis=0)  # Cuenta las veces que cada atributo es 1 en la clase actual, porque es BERNOULLI\n",
    "                                                                 # axis = 0 indica que se aplica a lo largo de las columnas\n",
    "            num_muestras_clase = X_clase.shape[0]  # Número de muestras en la clase actual\n",
    "            self.proba_caracteristica_dado_clase[i, :] = cuenta_atributos / num_muestras_clase  # Calcula la probabilidad de cada atributo dado la clase: P(atributo = 1 | clase)\n",
    "                                                                                         # [i, :] := modifica toda la fila 'i' de la matriz \n",
    "            self.proba_clase[i] = num_muestras_clase / num_muestras  # Calcula la probabilidad a priori de la clase: P(clase)\n",
    "    \n",
    "    def calcular_probabilidades_posteriores(self, X):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades posteriores (proporcionales) para cada muestra:\n",
    "        \n",
    "        P(clase|datos) ∝ P(datos|clase) * P(clase)\n",
    "        \n",
    "        Se omite el denominador P(datos) ya que es constante para todas las clases.\n",
    "        \"\"\"\n",
    "        # Inicializa la matriz de probabilidades con ceros:\n",
    "        probabilidades = np.zeros((X.shape[0], self.num_clases))  # Cada fila corresponde a una muestra y cada columna a una clase.\n",
    "        \n",
    "        # Se itera sobre cada clase:\n",
    "        # 1.- calcula la verosimilitud: P(X|C)\n",
    "        # 2.- la multiplica por la probabilidad a priori: P(C)\n",
    "        for indice_clase in range(self.num_clases):\n",
    "            verosimilitud = np.prod(self.bernoulli(X, self.proba_caracteristica_dado_clase[indice_clase, :]), axis=1)  # Aquí usamos la distribución de Bernoulli para modelar cada atributo independientemente.\n",
    "            probabilidades[:, indice_clase] = verosimilitud * self.proba_clase[indice_clase]\n",
    "        \n",
    "        return probabilidades\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice clases de conjunto de datos\n",
    "        \"\"\"\n",
    "        return np.argmax(self.calcular_probabilidades_posteriores(X), axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli(x, q):\n",
    "      \"\"\"\n",
    "      Distribución de bernoulli\n",
    "      -x: Matriz o vector de valores que toma la variable (0 o 1).\n",
    "      -q: Vector de probabilidades asociadas a cada atributo o experimento.\n",
    "      return: Si x = 1 el resultado es q.\n",
    "              Si x = 0 el resultado es 1−q.\n",
    "      \"\"\"\n",
    "      return q**x * (1.0 - q)**(1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc0da34d-ce9b-41fd-ac50-0b90e7f1d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [0 0 1 ... 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.206919, 0.040095],\n",
       "       [0.208581, 0.040905],\n",
       "       [0.042081, 0.207405],\n",
       "       ...,\n",
       "       [0.042081, 0.207405],\n",
       "       [0.042081, 0.207405],\n",
       "       [0.208581, 0.040905]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la data\n",
    "archivo = \"aves.csv\"\n",
    "data = pd.read_csv(archivo, index_col=0)\n",
    "data_numpy = data.to_numpy()\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X_ent = data_numpy[:, :-1]\n",
    "y_ent = data_numpy[:, -1]\n",
    "\n",
    "# Aplicar un umbral para convertir las características en binarias.\n",
    "# Usaremos la media de cada columna como umbral:\n",
    "umbral = np.mean(X_ent, axis=0)\n",
    "X_binaria = (X_ent >= umbral).astype(int)\n",
    "\n",
    "# Instanciar y entrenar el clasificador\n",
    "nbb = NaiveBayesBernoulli()\n",
    "nbb.fit(X_binaria, y_ent)\n",
    "\n",
    "# Realizar predicciones utilizando el mismo conjunto (puedes usar otro conjunto si lo deseas)\n",
    "y_pred = nbb.predict(X_binaria)\n",
    "print(\"Predicciones:\", y_pred)\n",
    "\n",
    "# Opcional: Calcular y mostrar las probabilidades a posteriori\n",
    "probabilidades = nbb.calcular_probabilidades_posteriores(X_binaria)\n",
    "probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54503c-5b4b-4723-b5f1-1c9a071a5972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
