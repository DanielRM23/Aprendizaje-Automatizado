{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8107052b-9730-4a9e-b528-2d50fb3df2ae",
   "metadata": {},
   "source": [
    "# PROBLEMA 2: **Claificador de Sapm**\n",
    "\n",
    "\n",
    "### Entrega: Daniel Rojo Mata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28f466-0ab6-47f0-92d3-b86d1f0ad9d5",
   "metadata": {},
   "source": [
    "## **Enunciado del problema**\n",
    "\n",
    "Descarga el conjunto de datos de spam disponible en [este enlace](http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_automatizado/data/spam.csv) y realiza lo siguiente:\n",
    "\n",
    "1. **Exploración de datos:**  \n",
    "   - Reporta el porcentaje de correos etiquetados como *spam* y *no spam* en el conjunto de datos.\n",
    "\n",
    "2. **División del conjunto de datos:**  \n",
    "   - Divide aleatoriamente el conjunto de datos en:\n",
    "     - **60 %** para entrenamiento  \n",
    "     - **20 %** para validación  \n",
    "     - **20 %** para prueba  \n",
    "   - Usa `0` como semilla para el generador de números aleatorios.\n",
    "\n",
    "3. **Entrenamiento de clasificadores:**  \n",
    "   - Entrena **dos clasificadores Naive Bayes** con diferentes distribuciones.\n",
    "\n",
    "4. **Evaluación de modelos:**  \n",
    "   - Usa los clasificadores entrenados para predecir *spam* en los datos de **entrenamiento** y **validación**.  \n",
    "   - Reporta el **porcentaje de predicciones correctas** de cada clasificador.\n",
    "\n",
    "5. **Análisis del desempeño:**  \n",
    "   - Discute el rendimiento de los diferentes clasificadores con base en los resultados obtenidos.\n",
    "\n",
    "6. **Evaluación en el conjunto de prueba:**  \n",
    "   - Reporta el **porcentaje de predicciones correctas** en el subconjunto de **prueba** utilizando el clasificador con mejor rendimiento en la validación.\n",
    "\n",
    "## **Descripción del conjunto de datos**\n",
    "El archivo `spam.csv` contiene **2001 valores por renglón**, distribuidos de la siguiente manera:\n",
    "- Los **primeros 2000 valores** representan el **histograma de palabras** en un correo.\n",
    "- El **último valor (posición 2000)** indica la clase del correo:\n",
    "  - `1` → Es **spam**  \n",
    "  - `0` → No es **spam**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677774f8-fd05-496d-86dc-810ee911367f",
   "metadata": {},
   "source": [
    "# **SOLUCIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f40d89-dcf0-499a-9537-a91ed4d04fbf",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b1c98-0672-457a-879d-9540badd9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan los cosos necesarios \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c8d38-854e-4826-a401-32205b7b5033",
   "metadata": {},
   "source": [
    "## Clasificador con distribución Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbb429-d934-435a-a0f8-5b0e60122735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesBernoulli:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa los atributos del modelo de Naive Bayes con distribución Bernoulli.\n",
    "        \"\"\"\n",
    "        self.num_clases = None  # Número de clases en el conjunto de datos\n",
    "        self.num_caracteristicas = None  # Número de características en los datos\n",
    "        self.proba_caracteristica_dado_clase = None  # Matriz de probabilidades condicionales P(característica|clase)\n",
    "        self.proba_clase = None  # Vector de probabilidades a priori P(clase)\n",
    "\n",
    "    def fit(self, X_ent, y_ent):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el conjunto de entrenamiento.\n",
    "\n",
    "        Parámetros:\n",
    "            X_ent: Matriz de características del conjunto de entrenamiento\n",
    "            y_ent: Vector de etiquetas de clase del conjunto de entrenamiento\n",
    "        \"\"\"\n",
    "        clases_unicas = np.unique(y_ent)  # Encuentra las clases únicas en el conjunto de entrenamiento\n",
    "        self.num_clases = clases_unicas.size  # Almacena el número total de clases\n",
    "        self.num_caracteristicas = X_ent.shape[-1]  # Obtiene el número de características por muestra\n",
    "        num_muestras = X_ent.shape[0]  # Obtiene el número total de muestras en el conjunto de entrenamiento\n",
    "\n",
    "        # Inicializa la matriz de probabilidades condicionales con ceros\n",
    "        self.proba_caracteristica_dado_clase = np.zeros((self.num_clases, self.num_caracteristicas))  \n",
    "        # Inicializa el vector de probabilidades a priori con ceros\n",
    "        self.proba_clase = np.zeros(self.num_clases)  \n",
    "\n",
    "        for i, clase in enumerate(clases_unicas):  # Itera sobre cada clase\n",
    "            X_clase = X_ent[y_ent == clase]  # Filtra las muestras pertenecientes a la clase actual\n",
    "            cuenta_atributos = np.count_nonzero(X_clase, axis=0)  # Cuenta cuántas veces cada atributo es 1 dentro de la clase\n",
    "                                                                  # axis = 0 indica que se aplica a lo largo de las columnas\n",
    "            num_muestras_clase = X_clase.shape[0]  # Obtiene el número de muestras en la clase actual\n",
    "            \n",
    "            # Calcula P(atributo=1 | clase) dividiendo la cuenta entre el número de muestras de la clase\n",
    "            self.proba_caracteristica_dado_clase[i, :] = cuenta_atributos / num_muestras_clase # [i, :] := modifica toda la fila 'i' de la matriz \n",
    "            \n",
    "            # Calcula P(clase) como la proporción de muestras de la clase en el total de datos\n",
    "            self.proba_clase[i] = num_muestras_clase / num_muestras  \n",
    "    \n",
    "    def calcular_probabilidades_posteriores(self, X):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades posteriores (proporcionales) para cada muestra:\n",
    "            P(clase|datos) ∝ P(datos|clase) * P(clase)\n",
    "        Se omite el denominador P(datos) ya que es constante para todas las clases.\n",
    "\n",
    "        Parámetros: \n",
    "            X: Matriz de características del conjunto de prueba\n",
    "        \n",
    "        return: \n",
    "            Matriz de probabilidades de cada clase para cada muestra\n",
    "        \"\"\"\n",
    "        probabilidades = np.zeros((X.shape[0], self.num_clases))  # Matriz para almacenar las probabilidades calculadas\n",
    "                                                                  # Es de tamaño: NumCaracterísticas x NumClases\n",
    "        \n",
    "        for indice_clase in range(self.num_clases):  # Itera sobre cada clase\n",
    "            # Calcula la verosimilitud P(X|C) usando la distribución de Bernoulli.\n",
    "                # Bajo el supuesto de independencia condicional (Bayes ingenuo), se calcula como:\n",
    "                # P(X|C) = P(x_1|C) * P(x_2|C) * P(x_3|C) * ... * P(x_n|C)\n",
    "            verosimilitud = np.prod(self.bernoulli(X, self.proba_caracteristica_dado_clase[indice_clase, :]), axis=1)  \n",
    "            # Multiplica la verosimilitud por la probabilidad a priori de la clase P(C)\n",
    "            # Esto nos da una cantidad proporcional a la probabilidad posterior P(C|X)\n",
    "            probabilidades[:, indice_clase] = verosimilitud * self.proba_clase[indice_clase]\n",
    "\n",
    "        return probabilidades  # Retorna la matriz de probabilidades posteriores\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice las clases de un conjunto de datos.\n",
    "        \n",
    "        Parámetros:\n",
    "            X: Matriz de características del conjunto de prueba\n",
    "        \n",
    "        return: \n",
    "            Vector con las clases predichas\n",
    "        \"\"\"\n",
    "        return np.argmax(self.calcular_probabilidades_posteriores(X), axis=1)  # Retorna la clase con la mayor probabilidad posterior\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli(x, q):\n",
    "        \"\"\"\n",
    "        Función de masa de probabilidad de la distribución de Bernoulli.\n",
    "        \n",
    "        Parámetros:\n",
    "            x: Valores de la variable aleatoria (0 o 1)\n",
    "            q: Probabilidad del éxito (atributo = 1) en la distribución de Bernoulli\n",
    "        \n",
    "        return: \n",
    "            Probabilidad de cada muestra bajo la distribución de Bernoulli\n",
    "        \"\"\"\n",
    "        epsilon = 1e-9  # Pequeño valor para evitar cálculos con 0 o 1 exactos que puedan generar errores numéricos\n",
    "        q = np.clip(q, epsilon, 1 - epsilon)  # Restringe los valores de q al intervalo (epsilon, 1 - epsilon)\n",
    "        return q**x * (1.0 - q)**(1.0 - x)  # Aplica la fórmula de la distribución de Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2958015-50ea-4a7c-8b42-890f3c1dbf41",
   "metadata": {},
   "source": [
    "## Clasificador con distribución Gaussiana\n",
    "\n",
    "Se utiliza el logaritmo para un mejor trabajo, pues multiplicar probabilidades pequeñas puede dar valores muy bajos, cercanos a cero, lo que puede causar subdesbordamiento numérico en la computadora.\n",
    "\n",
    "El objetivo de usar logaritmo es evitar esto último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da8dfc-2cb1-4348-9008-a87b5ef3fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesGaussiano:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa los atributos del modelo de Naive Bayes con distribución Gaussiana.\n",
    "        \"\"\"\n",
    "        self.media = None  # Media de cada característica por clase\n",
    "        self.desviacion = None  # Desviación estándar de cada característica por clase\n",
    "        self.proba_clase = None  # Probabilidad a priori de cada clase\n",
    "        self.clases = None  # Clases únicas en el conjunto de datos\n",
    "        self.epsilon = 1e-6  # Pequeño valor para evitar divisiones por 0 en la varianza\n",
    "\n",
    "    def fit(self, X_ent, y_ent):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el conjunto de entrenamiento.\n",
    "        Calcula los parámetros de la distribución Gaussiana (media y desviación estándar) \n",
    "        para cada característica en cada clase.\n",
    "        \n",
    "        Parámetros:\n",
    "            X_ent: ndarray de forma (num_muestras, num_características), matriz de datos de entrada.\n",
    "            y_ent: ndarray de forma (num_muestras,), vector de etiquetas de clase.\n",
    "        \"\"\"\n",
    "        self.clases = np.unique(y_ent)  # Obtiene las clases únicas en el conjunto de entrenamiento\n",
    "        num_clases = len(self.clases)  # Número total de clases\n",
    "        num_caracteristicas = X_ent.shape[1]  # Número de características en los datos\n",
    "        \n",
    "        # Inicializa matrices para almacenar la media, desviación estándar y probabilidades a priori, resp.\n",
    "        self.media = np.zeros((num_clases, num_caracteristicas))\n",
    "        self.desviacion = np.zeros((num_clases, num_caracteristicas))\n",
    "        self.proba_clase = np.zeros(num_clases)\n",
    "        \n",
    "        # Itera sobre cada clase para calcular sus parámetros estadísticos\n",
    "        for i, clase in enumerate(self.clases):\n",
    "            X_clase = X_ent[y_ent == clase]  # Filtra las muestras que pertenecen a la clase actual\n",
    "            self.media[i, :] = X_clase.mean(axis=0)  # Calcula la media de cada característica\n",
    "            self.desviacion[i, :] = np.maximum(X_clase.std(axis=0), self.epsilon)  # Evita sigma = 0\n",
    "            self.proba_clase[i] = len(X_clase) / len(X_ent)  # Calcula la probabilidad a priori de la clase\n",
    "\n",
    "    def gaussian_log(self, x, mu, sigma):\n",
    "        \"\"\"\n",
    "        Calcula la densidad de probabilidad de una distribución Gaussiana para cada característica.\n",
    "\n",
    "        Parámetros:\n",
    "            x: ndarray de forma (num_muestras, num_características), valores de entrada.\n",
    "            mu: ndarray de forma (num_características,), media de la distribución Gaussiana.\n",
    "            sigma: ndarray de forma (num_características,), desviación estándar de la distribución Gaussiana.\n",
    "\n",
    "        return:\n",
    "            Log-probabilidad de cada característica bajo la distribución Gaussiana correspondiente.\n",
    "        \"\"\"\n",
    "        sigma = np.maximum(sigma, self.epsilon)  # Asegura que sigma no sea 0 para evitar errores numéricos\n",
    "        coef = -0.5 * np.log(2 * np.pi * sigma**2)  # Cálculo del coeficiente de normalización en logaritmo\n",
    "        exponente = -((x - mu) ** 2) / (2 * sigma ** 2)  # Cálculo de la parte exponencial de la función Gaussiana\n",
    "        return coef + exponente  # Retorna la suma de log-probabilidades para estabilidad numérica\n",
    "\n",
    "    def calcular_probabilidades_posteriores(self, X):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades logarítmicas de cada clase para cada muestra.\n",
    "\n",
    "        Parámetros:\n",
    "            X: ndarray de forma (num_muestras, num_características), datos de entrada.\n",
    "\n",
    "        return:\n",
    "            log_probabilidades: ndarray de forma (num_muestras, num_clases),\n",
    "                                matriz de log-probabilidades de cada muestra perteneciendo a cada clase.\n",
    "        \"\"\"\n",
    "        num_muestras = X.shape[0]  # Número total de muestras\n",
    "        num_clases = len(self.clases)  # Número total de clases\n",
    "        log_probabilidades = np.zeros((num_muestras, num_clases))  # Inicializa matriz de log-probabilidades\n",
    "        \n",
    "        # Itera sobre cada clase para calcular la log-probabilidad de que una muestra pertenezca a ella\n",
    "        for i in range(num_clases):\n",
    "            log_prob_verosimilitud = self.gaussian_log(X, self.media[i, :], self.desviacion[i, :])  \n",
    "            log_prob_verosimilitud = np.sum(log_prob_verosimilitud, axis=1)  # Suma las log-probabilidades de cada característica\n",
    "            \n",
    "            # Aplica la fórmula de la probabilidad posterior en logaritmo:\n",
    "            # log P(C|X) = log P(X|C) + log P(C), sin dividir por P(X) ya que no afecta la clasificación\n",
    "            log_probabilidades[:, i] = log_prob_verosimilitud + np.log(self.proba_clase[i]) \n",
    "        \n",
    "        return log_probabilidades  # Retorna la matriz de log-probabilidades para cada muestra y clase\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice la clase de cada muestra en X.\n",
    "\n",
    "        Parámetros:\n",
    "            X: ndarray de forma (num_muestras, num_características), datos de entrada.\n",
    "\n",
    "        return:\n",
    "            Un vector con las clases predichas para cada muestra.\n",
    "        \"\"\"\n",
    "        log_probabilidades = self.calcular_probabilidades_posteriores(X)  # Calcula log-probabilidades para cada clase\n",
    "        return self.clases[np.argmax(log_probabilidades, axis=1)]  # Retorna la clase con mayor log-probabilidad para cada muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15694d3a-5262-452f-b794-17645b36bd19",
   "metadata": {},
   "source": [
    "## Procesamiento de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2e65e-4192-49c0-afbc-2adbedd05fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"spam.csv\"\n",
    "data = pd.read_csv(archivo, \n",
    "                   header=None,\n",
    "                   sep=None,\n",
    "                   engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b51a521-12a5-46bc-9672-91e52808ac1d",
   "metadata": {},
   "source": [
    "## Función para cálculo de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864307f2-5b37-4ebb-ad1a-4e9561c68efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar los clasificadores\n",
    "def entrenar_y_evaluar(clasificador, X_ent, y_ent, X_val, y_val, X_test, y_test):\n",
    "    # Entrenar el clasificador\n",
    "    clasificador.fit(X_ent, y_ent)\n",
    "    \n",
    "    # Predecir para los conjuntos de entrenamiento, validación y prueba\n",
    "    predicciones_ent = clasificador.predict(X_ent)\n",
    "    predicciones_val = clasificador.predict(X_val)\n",
    "    predicciones_test = clasificador.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión (accuracy)\n",
    "    accuracy_ent = accuracy_score(y_ent, predicciones_ent) * 100\n",
    "    accuracy_val = accuracy_score(y_val, predicciones_val) * 100\n",
    "    accuracy_test = accuracy_score(y_test, predicciones_test) * 100\n",
    "    \n",
    "    return accuracy_ent, accuracy_val, accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46606dfc-9f74-4754-b343-5d1893fc1896",
   "metadata": {},
   "source": [
    "## División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b16f7-d1c5-42ce-9bd2-e52c3eb939e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa las características y la etiqueta\n",
    "X = data.iloc[:, :-1].to_numpy()  # Todas las columnas excepto la última\n",
    "y = data.iloc[:, -1].to_numpy()   # La última columna (etiqueta)\n",
    "\n",
    "# Dividir los datos en entrenamiento (60%), validación (20%) y prueba (20%)\n",
    "X_ent, X_temp, y_ent, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec4c38-ec81-4deb-9204-590a7d19d5e1",
   "metadata": {},
   "source": [
    "## Clasificadores Bernoulli y Gaussiano (incluidos los de sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b7278-cd0e-4235-934c-e02ecea7c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancias de los clasificadores hechos a manita y con sklearn\n",
    "clasificadores = {\n",
    "    \"Naive Bayes Bernoulli (sklearn)\": BernoulliNB(),\n",
    "    \"Naive Bayes Gaussiano (sklearn)\": GaussianNB(),\n",
    "    \"Naive Bayes Bernoulli (a manita)\": NaiveBayesBernoulli(),\n",
    "    \"Naive Bayes Gaussiano (a manita)\": NaiveBayesGaussiano(),\n",
    "}\n",
    "\n",
    "# Evaluar cada clasificador y mostrar resultados\n",
    "for nombre, clasificador in clasificadores.items():\n",
    "    print(f\"Resultados con {nombre}:\")\n",
    "    accuracy_ent, accuracy_val, accuracy_test = entrenar_y_evaluar(clasificador, X_ent, y_ent, X_val, y_val, X_test, y_test)\n",
    "    print(f\"Precisión en entrenamiento: {accuracy_ent:.3f}%\")\n",
    "    print(f\"Precisión en validación: {accuracy_val:.3f}%\")\n",
    "    print(f\"Precisión en prueba: {accuracy_test:.3f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e972e-4eb8-4608-8900-57afdb4791a3",
   "metadata": {},
   "source": [
    "## Reporte de Spam y No Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2c200-a3b2-440f-81fa-612c24a45e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_ratio = np.mean(y) * 100  # Asumiendo que spam = 1 y no spam = 0\n",
    "print(f\"Porcentaje de correos spam: {spam_ratio:.2f}%\")\n",
    "print(f\"Porcentaje de correos no spam: {100 - spam_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886bcd5-553f-4072-86f1-99601cb42ce8",
   "metadata": {},
   "source": [
    "## Mejor Clasificador\n",
    "\n",
    "Se hace el comparativo de todos los clasificadores, incluídos los de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca083891-bc19-4eea-812b-e167d07f4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, seleccionar el mejor clasificador con base en la precisión en validación\n",
    "# Seleccionamos el clasificador que tuvo el mejor desempeño en validación\n",
    "mejor_clasificador = max(clasificadores.items(),\n",
    "                         key=lambda x: entrenar_y_evaluar(x[1],\n",
    "                                                          X_ent,\n",
    "                                                          y_ent,\n",
    "                                                          X_val,\n",
    "                                                          y_val,\n",
    "                                                          X_test,\n",
    "                                                          y_test)[1])\n",
    "\n",
    "print(f\"El clasificador con mejor rendimiento en el conjunto de validación es: {mejor_clasificador[0]}\")\n",
    "# Evaluamos su desempeño en el conjunto de prueba\n",
    "accuracy_mejor_test = entrenar_y_evaluar(mejor_clasificador[1], X_ent, y_ent, X_val, y_val, X_test, y_test)[2]\n",
    "print(f\"Precisión en prueba para el mejor clasificador: {accuracy_mejor_test:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d6ddb-0aad-470d-a405-6d3caa84f6f8",
   "metadata": {},
   "source": [
    "# **DISCUSIÓN**\n",
    "\n",
    "### Sobre el Desempeño de los Clasificadores\n",
    "\n",
    "1. **Mejor Desempeño del Clasificador Gaussiano**:\n",
    "El clasificador **Naive Bayes Gaussiano** es el que presenta el mejor desempeño en validación (**93.04%**) y prueba (**92.46%**). Esto sugiere que este modelo es el más efectivo para los datos, posiblemente debido a que las características siguen una distribución más cercana a la normal, que es una suposición clave del modelo.\n",
    "\n",
    "2. **Poca Variabilidad Entre los Modelos**:\n",
    "Los resultados muestran que las variantes de Naive Bayes (Bernoulli y Gaussiano, tanto de `sklearn` como \"a manita\") tienen un desempeño similar, con diferencias mínimas. Esto indica que la implementación \"a manita\" está funcionando correctamente y produce resultados comparables a la versión de `sklearn`.\n",
    "\n",
    "3. **Posible Sobreajuste del Modelo Gaussiano**:\n",
    "El modelo Gaussiano presenta una precisión ligeramente superior en el conjunto de entrenamiento (**93.81%**) en comparación con validación (**93.04%**) y prueba (**92.46%**). Esto podría ser un indicio de sobreajuste, aunque la diferencia no es significativa, lo que sugiere que la generalización sigue siendo adecuada.\n",
    "\n",
    "4. **Consistencia Entre Modelos**:\n",
    "Los modelos **Bernoulli** tienen un desempeño ligeramente inferior (alrededor del **91%** en validación), indicando que este tipo de modelo puede ser menos adecuado para este conjunto de datos.\n",
    "\n",
    "5. **Comparación de Precisión**:\n",
    "Aunque todos los modelos muestran buen desempeño, el **Naive Bayes Gaussiano** tiene una ligera ventaja en precisión, lo que podría ser relevante para minimizar los falsos positivos o negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834ad8b-be61-498f-aa4c-091456535ee8",
   "metadata": {},
   "source": [
    "# **CONCLUSIÓN**\n",
    "\n",
    "El Naive Bayes Gaussiano es el modelo con mejor desempeño, alcanzando 93.04% en validación y 92.46% en prueba, lo que sugiere que se ajusta bien a los datos.\n",
    "\n",
    "Las diferencias entre los modelos (Gaussiano y Bernoulli) son mínimas, lo que confirma que la implementación \"a manita\" (usando numpy) es correcta.\n",
    "\n",
    "En general, todos los modelos ofrecen un buen desempeño, pero el Naive Bayes Gaussiano es la mejor opción para este problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
